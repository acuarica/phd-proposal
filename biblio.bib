
@inproceedings{mastrangelo_jnif:_2014,
	address = {New York, NY, USA},
	series = {{PPPJ} '14},
	title = {{JNIF}: {Java} {Native} {Instrumentation} {Framework}},
	isbn = {978-1-4503-2926-2},
	shorttitle = {{JNIF}},
	url = {http://doi.acm.org/10.1145/2647508.2647516},
	doi = {10.1145/2647508.2647516},
	abstract = {The development of instrumentation-based dynamic analyses for Java bytecode is enabled by various bytecode rewriting frameworks. Those frameworks are all implemented in Java. This complicates their use for developing full-coverage analyses that not only observe application code, but that also observe the execution of the complete Java class library. Moreover, it makes it hard to avoid perturbation due to the Java code of the instrumentation tool interfering with the Java code of the observed program. So far, workarounds for these problems required either statically instrumenting the runtime library or running a separate JVM as an instrumentation server. This paper solves this problem. It introduces JNIF, the first complete bytecode rewriting framework implemented in native code. JNIF can be used in a JVMTI agent to create isolated, full-coverage, in-process dynamic instrumentation tools. JNIF is written in C++ and has an object-oriented design familiar to users of Java-based rewriting libraries. JNIF is able to decode, analyze, edit, and encode Java class files. This includes the generation of stack maps required by split-time verifiers of modern JVMs. Our performance evaluation shows that JNIF is often faster than the most performant competitive approach based on ASM.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2014 {International} {Conference} on {Principles} and {Practices} of {Programming} on the {Java} {Platform}: {Virtual} {Machines}, {Languages}, and {Tools}},
	publisher = {ACM},
	author = {Mastrangelo, Luis and Hauswirth, Matthias},
	year = {2014},
	keywords = {bytecode instrumentation, Java, program analysis},
	pages = {194--199},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/8IXP8DSD/Mastrangelo and Hauswirth - 2014 - JNIF Java Native Instrumentation Framework.pdf:application/pdf}
}

@inproceedings{coelho_unveiling_2015,
	address = {Piscataway, NJ, USA},
	series = {{MSR} '15},
	title = {Unveiling {Exception} {Handling} {Bug} {Hazards} in {Android} {Based} on {GitHub} and {Google} {Code} {Issues}},
	isbn = {978-0-7695-5594-2},
	url = {http://dl.acm.org/citation.cfm?id=2820518.2820536},
	abstract = {This paper reports on a study mining the exception stack traces included in 159,048 issues reported on Android projects hosted in GitHub (482 projects) and Google Code (157 projects). The goal of this study is to investigate whether stack trace information can reveal bug hazards related to exception handling code that may lead to a decrease in application robustness. Overall 6,005 exception stack traces were extracted, and subjected to source code and bytecode analysis. The outcomes of this study include the identification of the following bug hazards: (i) unexpected cross-type exception wrappings (for instance, trying to handle an instance of OutOfMemoryError "hidden" in a checked exception) which can make the exception-related code more complex and negatively impact the application robustness; (ii) undocumented runtime exceptions thrown by both the Android platform and third party libraries; and (iii) undocumented checked exceptions thrown by the Android Platform. Such undocumented exceptions make it difficult, and most of the times infeasible for the client code to protect against "unforeseen" situations that may happen while calling third-party code. This study provides further insights on such bug hazards and the robustness threats they impose to Android apps as well as to other systems based on the Java exception model.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 12th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Coelho, Roberta and Almeida, Lucas and Gousios, Georgios and van Deursen, Arie},
	year = {2015},
	pages = {134--145},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/TGLYE77G/Coelho et al. - 2015 - Unveiling Exception Handling Bug Hazards in Androi.pdf:application/pdf}
}

@article{knuth_empirical_1971,
	title = {An empirical study of {FORTRAN} programs},
	volume = {1},
	issn = {1097-024X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.4380010203/abstract},
	doi = {10.1002/spe.4380010203},
	abstract = {A sample of programs, written in FORTRAN by a wide variety of people for a wide variety of applications, was chosen {\textquoteleft}at random{\textquoteright} in an attempt to discover quantitatively {\textquoteleft}what programmers really do{\textquoteright}. Statistical results of this survey are presented here, together with some of their apparent implications for future work in compiler design. The principal conclusion which may be drawn is the importance of a program {\textquoteleft}profile{\textquoteright}, namely a table of frequency counts which record how often each statement is performed in a typical run; there are strong indications that profile-keeping should become a standard practice in all computer systems, for casual users as well as system programmers. This paper is the report of a three month study undertaken by the author and about a dozen students and representatives of the software industry during the summer of 1970. It is hoped that a reader who studies this report will obtain a fairly clear conception of how FORTRAN is being used, and what compilers can do about it.},
	language = {en},
	number = {2},
	urldate = {2017-11-11},
	journal = {Software: Practice and Experience},
	author = {Knuth, Donald E.},
	month = apr,
	year = {1971},
	keywords = {Compiler, Efficiency, FORTRAN, Optimization},
	pages = {105--133},
	file = {empirical-fortran.pdf:/Volumes/Data/work/zotero/storage/VDMLM4DI/empirical-fortran.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/WPWCCP4B/abstract.html:text/html}
}

@article{fletcher_appropriate_1972,
	title = {On the {Appropriate} {Language} for {System} {Programming}},
	volume = {7},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/953360.953361},
	doi = {10.1145/953360.953361},
	number = {7},
	urldate = {2017-11-11},
	journal = {SIGPLAN Not.},
	author = {Fletcher, J. G. and Badger, C. S. and Boer, G. L. and Marshall, G. G.},
	month = jul,
	year = {1972},
	keywords = {implementation, language, system},
	pages = {28--30},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/Q34Z72E7/Fletcher et al. - 1972 - On the Appropriate Language for System Programming.pdf:application/pdf}
}

@inproceedings{kildall_unified_1973,
	address = {New York, NY, USA},
	series = {{POPL} '73},
	title = {A {Unified} {Approach} to {Global} {Program} {Optimization}},
	url = {http://doi.acm.org/10.1145/512927.512945},
	doi = {10.1145/512927.512945},
	abstract = {A technique is presented for global analysis of program structure in order to perform compile time optimization of object code generated for expressions. The global expression optimization presented includes constant propagation, common subexpression elimination, elimination of redundant register load operations, and live expression analysis. A general purpose program flow analysis algorithm is developed which depends upon the existence of an "optimizing function." The algorithm is defined formally using a directed graph model of program flow structure, and is shown to be correct. Several optimizing functions are defined which, when used in conjunction with the flow analysis algorithm, provide the various forms of code optimization. The flow analysis algorithm is sufficiently general that additional functions can easily be defined for other forms of global code optimization.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 1st {Annual} {ACM} {SIGACT}-{SIGPLAN} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Kildall, Gary A.},
	year = {1973},
	pages = {194--206},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/ELKWJNV8/Kildall - 1973 - A Unified Approach to Global Program Optimization.pdf:application/pdf}
}

@inproceedings{frailey_should_1975,
	address = {New York, NY, USA},
	series = {{ACM} '75},
	title = {Should {High} {Level} {Languages} {Be} {Used} to {Write} {Systems} {Software}?},
	url = {http://doi.acm.org/10.1145/800181.810317},
	doi = {10.1145/800181.810317},
	abstract = {Most of us write our programs in whatever language is most convenient for the problem at hand. Often this means, not so much that the language is well suited to the problem, but simply that it's the best suited of the choices available. Particularly with microprocessors and many minicomputers, we don't have a very wide choice of available software. Perhaps we have only an assembler or only a Basic interpreter. Those who have a choice, or who are responsible for developing compilers and other basic systems software, must determine how much money to spend and where to spend it, becoming embroiled in such questions as what high level languages, if any, should be used or how important it is to develop a good assembler versus a good high level language compiler for our systems work.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 1975 {Annual} {Conference}},
	publisher = {ACM},
	author = {Frailey, Dennis J.},
	year = {1975},
	pages = {205--},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/K22D4IMH/Frailey - 1975 - Should High Level Languages Be Used to Write Syste.pdf:application/pdf}
}

@inproceedings{fletcher_no!_1975,
	address = {New York, NY, USA},
	series = {{ACM} '75},
	title = {No! {High} {Level} {Languages} {Should} {Not} {Be} {Used} to {Write} {Systems} {Software}},
	url = {http://doi.acm.org/10.1145/800181.810319},
	doi = {10.1145/800181.810319},
	abstract = {The views expressed here derive from the experience of the author and his colleagues in designing and implementing the Octopus computer network at the Lawrence Livermore Laboratory. This network serves five major time-shared computers (CDC 7600's and STAR-100's), connecting them to over 800 interactive terminals, about 200 television monitor displays, printers that operate at up to 18,000 lines/minute, and more than a trillion bits of storage. The software for the network has been written entirely in assembly language (for PDP-8's, 10's, and 11's, MODCOMP II's, and TI 980's) and from scratch, basing none of it on manufacturers' or other commercial software. The same persons who create the design also do the programming and debugging. In most cases one or two persons program a computer; four persons were used on the largest system (the PDP-10's). Our experience does not accord with much of what we read in the computing literature, leading us to conclude that it is written by persons unaware the real problems of systems work. We have had little or no trouble with deadlocks, security loopholes, and other logical flaws that are belabored at length in the literature. Most of our effort has gone into devising ways for the system to survive in the presence of intermittent and random failures of hardware components and for it to maintain high data transfer rates among multiply-interconnected devices and computers of varying speeds, matters that are seldom discussed in the literature at all. It is certainly not the case that the difficulties encountered with operating systems are the same as those encountered with other large programs, such as compilers.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 1975 {Annual} {Conference}},
	publisher = {ACM},
	author = {Fletcher, John G.},
	year = {1975},
	pages = {209--211},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/WRJQZAFW/Fletcher - 1975 - No! High Level Languages Should Not Be Used to Wri.pdf:application/pdf}
}

@inproceedings{horning_yes!_1975,
	address = {New York, NY, USA},
	series = {{ACM} '75},
	title = {Yes! {High} {Level} {Languages} {Should} {Be} {Used} to {Write} {Systems} {Software}},
	url = {http://doi.acm.org/10.1145/800181.810318},
	doi = {10.1145/800181.810318},
	abstract = {It has frequently been remarked that it is easier recognize {\textquotedblleft}high level{\textquotedblright} languages than to define the concept. For the purposes of this debate, however, I think that we agree that a language is high level to the extent that it discourages (forbids) the specification of machine details (register numbers, absolute addresses, op codes, word-packing, etc.) as a routine part of program composition and low level to the extent that it encourages (requires) such specification. (Note that, by this definition, assembly languages occupy a position intermediate between machine languages and compiled languages.) Thus, I take the point at issue to be: {\textquotedblleft}To what extent is it desirable for the system programmer to specify machine details?{\textquotedblright}},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 1975 {Annual} {Conference}},
	publisher = {ACM},
	author = {Horning, James J.},
	year = {1975},
	pages = {206--208},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/AYFN2GJM/Horning - 1975 - Yes! High Level Languages Should Be Used to Write .pdf:application/pdf}
}

@article{hammond_basic_1977,
	title = {{BASIC} - an evaluation of processing methods and a study of some programs},
	volume = {7},
	issn = {1097-024X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.4380070605/abstract},
	doi = {10.1002/spe.4380070605},
	abstract = {The relative merits of compiling and interpreting BASIC are examined, and these methods are compared with the technique called throw-away compiling. The comparison reveals that a throw-away compiler has much to recommend it, and some reasons for its superior performance are explained. The BASIC programs used for the performance tests are analysed, both statically and dynamically, and certain features are picked out for comment.},
	language = {en},
	number = {6},
	urldate = {2017-11-11},
	journal = {Software: Practice and Experience},
	author = {Hammond, John},
	month = nov,
	year = {1977},
	keywords = {Compiler, Efficiency, BASIC, Interpreter, Throw-away compiler},
	pages = {697--711},
	file = {Snapshot:/Volumes/Data/work/zotero/storage/MH8LMVNV/abstract.html:text/html}
}

@article{lamport_time_1978,
	title = {Time, {Clocks}, and the {Ordering} of {Events} in a {Distributed} {System}},
	volume = {21},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/359545.359563},
	doi = {10.1145/359545.359563},
	abstract = {The concept of one event happening before another in a distributed system is examined, and is shown to define a partial ordering of the events. A distributed algorithm is given for synchronizing a system of logical clocks which can be used to totally order the events. The use of the total ordering is illustrated with a method for solving synchronization problems. The algorithm is then specialized for synchronizing physical clocks, and a bound is derived on how far out of synchrony the clocks can become.},
	number = {7},
	urldate = {2017-11-11},
	journal = {Commun. ACM},
	author = {Lamport, Leslie},
	month = jul,
	year = {1978},
	keywords = {clock synchronization, computer networks, distributed systems, multiprocess systems},
	pages = {558--565},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/NRN7SRHY/Lamport - 1978 - Time, Clocks, and the Ordering of Events in a Dist.pdf:application/pdf}
}

@article{herlihy_wait-free_1991,
	title = {Wait-free {Synchronization}},
	volume = {13},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/114005.102808},
	doi = {10.1145/114005.102808},
	abstract = {A wait-free implementation of a concurrent data object is one that guarantees that any process can complete any operation in a finite number of steps, regardless of the execution speeds of the other processes. The problem of constructing a wait-free implementation of one data object from another lies at the heart of much recent work in concurrent algorithms, concurrent data structures, and multiprocessor architectures. First, we introduce a simple and general technique, based on reduction to a concensus protocol, for proving statements of the form, {\textquotedblleft}there is no wait-free implementation of X by Y.{\textquotedblright} We derive a hierarchy of objects such that no object at one level has a wait-free implementation in terms of objects at lower levels. In particular, we show that    atomic read/write registers, which have been the focus of much recent attention, are at the bottom of the hierarchy: thay cannot be used to construct wait-free implementations of many simple and familiar data types. Moreover, classical synchronization primitives such astest\&set and fetch\&add, while more powerful than read and write, are also computationally weak, as are the standard message-passing primitives. Second, nevertheless, we show that there do exist simple universal objects from which one can construct a wait-free implementation of any sequential object.},
	number = {1},
	urldate = {2017-11-11},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Herlihy, Maurice},
	month = jan,
	year = {1991},
	keywords = {linearization, wait-free synchronization},
	pages = {124--149},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/7ZNQEGFS/Herlihy - 1991 - Wait-free Synchronization.pdf:application/pdf}
}

@article{liskov_behavioral_1994,
	title = {A {Behavioral} {Notion} of {Subtyping}},
	volume = {16},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/197320.197383},
	doi = {10.1145/197320.197383},
	abstract = {The use of hierarchy is an important component of object-oriented design. Hierarchy allows the use of type families, in which higher level supertypes capture the behavior that all of their subtypes have in common. For this methodology to be effective, it is necessary to have a clear understanding of how subtypes and supertypes are related. This paper takes the position that the relationship should ensure that any property proved about supertype objects also holds for its subtype objects. It presents two ways of defining the subtype relation, each of which meets this criterion, and each of which is easy for programmers to use. The subtype relation is based on the specifications of the sub- and supertypes; the paper presents a way of specifying types that makes it convenient to define  the subtype relation. The paper also discusses the ramifications of this notion of subtyping on the design of type families.},
	number = {6},
	urldate = {2017-11-11},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Liskov, Barbara H. and Wing, Jeannette M.},
	month = nov,
	year = {1994},
	keywords = {formal specifications, Larch, subtyping},
	pages = {1811--1841},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/CTJTTACC/Liskov and Wing - 1994 - A Behavioral Notion of Subtyping.pdf:application/pdf}
}

@article{bershad_spinextensible_1995,
	title = {{SPIN}{\textemdash}an {Extensible} {Microkernel} for {Application}-specific {Operating} {System} {Services}},
	volume = {29},
	issn = {0163-5980},
	url = {http://doi.acm.org/10.1145/202453.202472},
	doi = {10.1145/202453.202472},
	abstract = {Application domains such as multimedia, databases, and parallel computing, require operating system services with high performance and high functionality. Existing operating systems provide fixed interfaces and implementations to system services and resources. This makes them inappropriate for applications whose resource demands and usage patterns are poorly matched by the services provided. The SPIN operating system enables system services to be defined in an application-specific fashion through an extensible microkernel. It offers applications fine-grained control over a machine's logical and physical resources through run-time adaptation of the system to application requirements.},
	number = {1},
	urldate = {2017-11-11},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Bershad, Brian N. and Chambers, Craig and Eggers, Susan and Maeda, Chris and McNamee, Dylan and Pardyak, Przemys{\textbackslash}law and Savage, Stefan and Sirer, Emin G{\"u}n},
	month = jan,
	year = {1995},
	pages = {74--77},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/TVGKU4UV/Bershad et al. - 1995 - SPIN{\textemdash}an Extensible Microkernel for Application-spe.pdf:application/pdf}
}

@inproceedings{necula_proof-carrying_1997,
	address = {New York, NY, USA},
	series = {{POPL} '97},
	title = {Proof-carrying {Code}},
	isbn = {978-0-89791-853-4},
	url = {http://doi.acm.org/10.1145/263699.263712},
	doi = {10.1145/263699.263712},
	abstract = {This paper describes proof-carrying code (PCC), a mechanism by which a host system can determine with certainty that it is safe to execute a program supplied (possibly in binary form) by an untrusted source. For this to be possible, the untrusted code producer must supply with the code a safety proof that attests to the code's adherence to a previously defined safety policy. The host can then easily and quickly validate the proof without using cryptography and without consulting any external agents.In order to gain preliminary experience with PCC, we have performed several case studies. We show in this paper how proof-carrying code might be used to develop safe assembly-language extensions of ML programs. In the context of this case study, we present and prove the adequacy of concrete representations for the safety policy, the safety proofs, and the proof validation. Finally, we briefly discuss how we use proof-carrying code to develop network packet filters that are faster than similar filters developed using other techniques and are formally guaranteed to be safe with respect to a given operating system safety policy.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 24th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Necula, George C.},
	year = {1997},
	pages = {106--119},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/JFCFZE54/Necula - 1997 - Proof-carrying Code.pdf:application/pdf}
}

@article{ritchie_systems_1997,
	title = {Systems programming in {Java}},
	volume = {17},
	issn = {0272-1732},
	doi = {10.1109/40.591652},
	abstract = {The Java programming language has been widely accepted as a general purpose language for developing portable applications, toolkits, and applets. With so much activity in industry and academia in these user-level areas, is it surprising that Java is also an equally capable systems programming language? This article describes our experiences at JavaSoft with using Java as a systems-level programming language during the development of JavaOS. The author discusses the motivations for using Java and shows code examples to demonstrate various system-level primitives, including an Ethernet device driver},
	number = {3},
	journal = {IEEE Micro},
	author = {Ritchie, S.},
	month = may,
	year = {1997},
	keywords = {Java, Debugging, Ethernet networks, general purpose language, high level languages, Java programming language, JavaOS, JavaSoft, Mice, Object oriented modeling, Operating systems, operating systems (computers), portable applications, Programming profession, Protection, Protocols, Runtime, system-level primitives, systems analysis, systems programming},
	pages = {30--35},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/BZU7XIFI/591652.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/NI5IITLU/Ritchie - 1997 - Systems programming in Java.pdf:application/pdf}
}

@inproceedings{vallee-rai_soot_1999,
	address = {Mississauga, Ontario, Canada},
	series = {{CASCON} '99},
	title = {Soot - a {Java} {Bytecode} {Optimization} {Framework}},
	url = {http://dl.acm.org/citation.cfm?id=781995.782008},
	abstract = {This paper presents Soot, a framework for optimizing Java bytecode. The framework is implemented in Java and supports three intermediate representations for representing Java bytecode: Baf, a streamlined representation of bytecode which is simple to manipulate; Jimple, a typed 3-address intermediate representation suitable for optimization; and Grimp, an aggregated version of Jimple suitable for decompilation. We describe the motivation for each representation, and the salient points in translating from one representation to another.In order to demonstrate the usefulness of the framework, we have implemented intraprocedural and whole program optimizations. To show that whole program bytecode optimization can give performance improvements, we provide experimental results for 12 large benchmarks, including 8 SPECjvm98 benchmarks running on JDK 1.2 for GNU/Linuxtm. These results show up to 8\% improvement when the optimized bytecode is run using the interpreter and up to 21\% when run using the JIT compiler.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 1999 {Conference} of the {Centre} for {Advanced} {Studies} on {Collaborative} {Research}},
	publisher = {IBM Press},
	author = {Vall{\'e}e-Rai, Raja and Co, Phong and Gagnon, Etienne and Hendren, Laurie and Lam, Patrick and Sundaresan, Vijay},
	year = {1999},
	pages = {13--},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/DXB3947K/Vall{\'e}e-Rai et al. - 1999 - Soot - a Java Bytecode Optimization Framework.pdf:application/pdf}
}

@inproceedings{siebert_eliminating_2000,
	address = {New York, NY, USA},
	series = {{CASES} '00},
	title = {Eliminating {External} {Fragmentation} in a {Non}-moving {Garbage} {Collector} for {Java}},
	isbn = {978-1-58113-338-7},
	url = {http://doi.acm.org/10.1145/354880.354883},
	doi = {10.1145/354880.354883},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2000 {International} {Conference} on {Compilers}, {Architecture}, and {Synthesis} for {Embedded} {Systems}},
	publisher = {ACM},
	author = {Siebert, Fridtjof},
	year = {2000},
	pages = {9--17},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/FBLQV5QS/Siebert - 2000 - Eliminating External Fragmentation in a Non-moving.pdf:application/pdf}
}

@inproceedings{lea_java_2000,
	address = {New York, NY, USA},
	series = {{JAVA} '00},
	title = {A {Java} {Fork}/{Join} {Framework}},
	isbn = {978-1-58113-288-5},
	url = {http://doi.acm.org/10.1145/337449.337465},
	doi = {10.1145/337449.337465},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {ACM} 2000 {Conference} on {Java} {Grande}},
	publisher = {ACM},
	author = {Lea, Doug},
	year = {2000},
	pages = {36--43},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/GFMTENEJ/Lea - 2000 - A Java ForkJoin Framework.pdf:application/pdf}
}

@inproceedings{moonen_generating_2001,
	title = {Generating robust parsers using island grammars},
	doi = {10.1109/WCRE.2001.957806},
	abstract = {Source model extraction, the automated extraction of information from system artifacts, is a common phase in reverse engineering tools. One of the major challenges of this phase is creating extractors that can deal with irregularities in the artifacts that are typical for the reverse engineering domain (for example, syntactic errors, incomplete source code, language dialects and embedded languages). The paper proposes a solution in the form of island grammars, a special kind of grammar that combines the detailed specification possibilities of grammars with the liberal behavior of lexical approaches. We show how island grammars can be used to generate robust parsers that combine the accuracy of syntactical analysis with the speed, flexibility and tolerance usually only found in lexical analysis. We conclude with a discussion of the development of MANGROVE, a generator for source model extractors based on island grammars and describe its application to a number of case studies},
	booktitle = {Proceedings {Eighth} {Working} {Conference} on {Reverse} {Engineering}},
	author = {Moonen, L.},
	year = {2001},
	keywords = {program analysis, Application software, automated information extraction, case studies, computational linguistics, Computer languages, Data mining, detailed specification, embedded languages, fuzzy parsing, grammars, incomplete source code, island grammars, language dialects, lexical approaches, Libraries, Maintenance engineering, MANGROVE, Mars, parser generation, partial parsing, program compilers, reverse engineering, Reverse engineering, reverse engineering domain, reverse engineering tools, robust parser generation, robust parsers, Robustness, Software maintenance, source model extraction, source model extractors, syntactic errors, syntactical analysis, system artifacts, Transaction databases},
	pages = {13--22},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/B8PQQ46Q/957806.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/4H8D6X2H/Moonen - 2001 - Generating robust parsers using island grammars.pdf:application/pdf}
}

@inproceedings{leroy_java_2001,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Java {Bytecode} {Verification}: {An} {Overview}},
	isbn = {978-3-540-42345-4 978-3-540-44585-2},
	shorttitle = {Java {Bytecode} {Verification}},
	url = {https://link.springer.com/chapter/10.1007/3-540-44585-4_26},
	doi = {10.1007/3-540-44585-4_26},
	abstract = {Bytecode verification is a crucial security component for Java applets, on the Web and on embedded devices such as smart cards. This paper describes the main bytecode verification algorithms and surveys the variety of formal methods that have been applied to bytecode verification in order to establish its correctness.},
	language = {en},
	urldate = {2017-11-11},
	booktitle = {Computer {Aided} {Verification}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Leroy, Xavier},
	month = jul,
	year = {2001},
	pages = {265--285},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/NDKZZIJ2/Leroy - 2001 - Java Bytecode Verification An Overview.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/Y296DJRG/10.html:text/html}
}

@inproceedings{bruneton_asm:_2002,
	title = {{ASM}: {A} code manipulation tool to implement adaptable systems},
	shorttitle = {{ASM}},
	abstract = {ABSTRACT. ASM is a Java class manipulation tool designed to dynamically generate and manipulate Java classes, which are useful techniques to implement adaptable systems. ASM is based on a new approach, compared to equivalent existing tools, which consists in using the \&quot;visitor\&quot; design pattern without explicitly representing the visited tree with objects. This new approach gives much better performances than those of existing tools, for most of practical needs. R{\'E}SUM{\'E}. ASM est un outil de manipulation de classes Java con{\c c}u pour la g{\'e}n{\'e}ration et la manipulation dynamiques de code, qui sont des techniques tr{\`e}s utiles pour la r{\'e}alisation de syst{\`e}mes adaptables. ASM est bas{\'e} sur une approche originale, par rapport aux outils existants {\'e}quivalents, qui consiste {\`a} utiliser le patron de conception {\guillemotleft} visiteur {\guillemotright} sans repr{\'e}senter explicitement l{\textquoteright}arborescence visit{\'e}e sous forme d{\textquoteright}objets. Cette nouvelle approche permet d{\textquoteright}obtenir des performances bien sup{\'e}rieures {\`a} celles des outils existants, pour la plupart des besoins courants.},
	booktitle = {In {Adaptable} and extensible component systems},
	author = {Bruneton, Eric and Lenglet, Romain and Coupaye, Thierry},
	year = {2002},
	file = {Citeseer - Full Text PDF:/Volumes/Data/work/zotero/storage/X2Q7NC9L/Bruneton et al. - 2002 - ASM A code manipulation tool to implement adaptab.pdf:application/pdf;Citeseer - Snapshot:/Volumes/Data/work/zotero/storage/KL9Z4HDH/summary.html:text/html}
}

@book{jim_cyclone:_nodate,
	title = {Cyclone: {A} safe dialect of {C}},
	shorttitle = {Cyclone},
	abstract = {Cyclone is a safe dialect of C. It has been designed from the ground up to prevent the buffer overflows, format string attacks, and memory management errors that are common in C programs, while retaining C's syntax and semantics. This paper examines safety violations enabled by C's design, and shows how Cyclone avoids them, without giving up C's hallmark control over low-level details such as data representation and memory management.},
	author = {Jim, Trevor and Morrisett, Greg and Grossman, Dan and Hicks, Michael and Cheney, James and Wang, Yanling},
	file = {Citeseer - Full Text PDF:/Volumes/Data/work/zotero/storage/7E5RTS32/Jim et al. - Cyclone A safe dialect of C.pdf:application/pdf;Citeseer - Snapshot:/Volumes/Data/work/zotero/storage/BIBZRDU6/summary.html:text/html}
}

@article{barnett_verification_2003,
	title = {Verification of {Object}-{Oriented} {Programs} {With} {Invariants}},
	volume = {3, No. 6},
	url = {https://www.microsoft.com/en-us/research/publication/verification-of-object-oriented-programs-with-invariants-2/},
	abstract = {An object invariant defines what it means for an object{\textquoteright}s data to be in a consistent state. Object invariants are central to the design and correctness of object-oriented programs. This paper defines a programming methodology for using object invariants. The methodology, which enriches a program{\textquoteright}s state space to express when each object invariant holds, deals {\textellipsis}},
	urldate = {2017-11-11},
	journal = {Journal of Object Technology, Special issue: ECOOP 2003 workshop on FTfJP},
	author = {Barnett, Mike and DeLine, Rob and Fahndrich, Manuel and Leino, Rustan and Schulte, Wolfram},
	month = jul,
	year = {2003},
	file = {article2.pdf:/Volumes/Data/work/zotero/storage/7Z5SLUBY/article2.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/YLL6KZ28/verification-of-object-oriented-programs-with-invariants-2.html:text/html}
}

@inproceedings{nystrom_polyglot:_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Polyglot: {An} {Extensible} {Compiler} {Framework} for {Java}},
	isbn = {978-3-540-00904-7 978-3-540-36579-2},
	shorttitle = {Polyglot},
	url = {https://link.springer.com/chapter/10.1007/3-540-36579-6_11},
	doi = {10.1007/3-540-36579-6_11},
	abstract = {Polyglot is an extensible compiler framework that supports the easy creation of compilers for languages similar to Java, while avoiding code duplication. The Polyglot framework is useful for domain-specific languages, exploration of language design, and for simplified versions of Java for pedagogical use. We have used Polyglot to implement several major and minor modifications to Java; the cost of implementing language extensions scales well with the degree to which the language differs from Java. This paper focuses on the design choices in Polyglot that are important for making the framework usable and highly extensible. Polyglot source code is available.},
	language = {en},
	urldate = {2017-11-11},
	booktitle = {Compiler {Construction}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Nystrom, Nathaniel and Clarkson, Michael R. and Myers, Andrew C.},
	month = apr,
	year = {2003},
	pages = {138--152},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/7R2QK48C/Nystrom et al. - 2003 - Polyglot An Extensible Compiler Framework for Jav.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/SAJRSBBV/10.html:text/html}
}

@inproceedings{chen_heap_2003,
	address = {New York, NY, USA},
	series = {{OOPSLA} '03},
	title = {Heap {Compression} for {Memory}-constrained {Java} {Environments}},
	isbn = {978-1-58113-712-5},
	url = {http://doi.acm.org/10.1145/949305.949330},
	doi = {10.1145/949305.949330},
	abstract = {Java is becoming the main software platform for consumer and embedded devices such as mobile phones, PDAs, TV set-top boxes, and in-vehicle systems. Since many of these systems are memory constrained, it is extremely important to keep the memory footprint of Java applications under control.The goal of this work is to enable the execution of Java applications using a smaller heap footprint than that possible using current embedded JVMs. We propose a set of memory management strategies to reduce heap footprint of embedded Java applications that execute under severe memory constraints. Our first contribution is a new garbage collector, referred to as the Mark-Compact-Compress (MCC) collector, that allows an application to run with a heap smaller than its footprint. An important characteristic of this collector is that it compresses objects when heap compaction is not sufficient for creating space for the current allocation request. In addition to employing compression, we also consider a heap management strategy and associated garbage collector, called MCL (Mark-Compact-Lazy Allocate), based on lazy allocation of object portions. This new collector operates like the conventional Mark-Compact (MC) collector, but takes advantage of the observation that many Java applications create large objects, of which only a small portion is actually used. In addition, we also combine MCC and MCL, and present MCCL (Mark-Compact-Compress-Lazy Al-locate), which outperforms both MCC and MCL.We have implemented these collectors using KVM, and performed extensive experiments using a set of ten embedded Java applications. We have found our new garbage collection strategies to be useful in two main aspects. First, they reduce the minimum heap size necessary to execute an application without out-of-memory exception. Second, our strategies reduce the heap occupancy. That is, at a given time, they reduce the heap memory requirement of the application being executed. We have also conducted experiments with a more aggressive object compression strategy and discussed its main advantages.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 18th {Annual} {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programing}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Chen, G. and Kandemir, M. and Vijaykrishnan, N. and Irwin, M. J. and Mathiske, B. and Wolczko, M.},
	year = {2003},
	keywords = {garbage collection, heap, Java virtual machine, memory compression},
	pages = {282--301},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/WHRRN5EQ/Chen et al. - 2003 - Heap Compression for Memory-constrained Java Envir.pdf:application/pdf}
}

@inproceedings{bacon_real-time_2003,
	address = {New York, NY, USA},
	series = {{POPL} '03},
	title = {A {Real}-time {Garbage} {Collector} with {Low} {Overhead} and {Consistent} {Utilization}},
	isbn = {978-1-58113-628-9},
	url = {http://doi.acm.org/10.1145/604131.604155},
	doi = {10.1145/604131.604155},
	abstract = {Now that the use of garbage collection in languages like Java is becoming widely accepted due to the safety and software engineering benefits it provides, there is significant interest in applying garbage collection to hard real-time systems. Past approaches have generally suffered from one of two major flaws: either they were not provably real-time, or they imposed large space overheads to meet the real-time bounds. We present a mostly non-moving, dynamically defragmenting collector that overcomes both of these limitations: by avoiding copying in most cases, space requirements are kept low; and by fully incrementalizing the collector we are able to meet real-time bounds. We implemented our algorithm in the Jikes RVM and show that at real-time resolution we are able to obtain mutator utilization rates of 45\% with only 1.6--2.5 times the actual space required by the application, a factor of 4 improvement in utilization over the best previously published results. Defragmentation causes no more than 4\% of the traced data to be copied.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 30th {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Bacon, David F. and Cheng, Perry and Rajan, V. T.},
	year = {2003},
	keywords = {defragmentation, read barrier, real-time scheduling, utilization},
	pages = {285--298},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/I37SF3CL/Bacon et al. - 2003 - A Real-time Garbage Collector with Low Overhead an.pdf:application/pdf}
}

@article{leroy_java_2003,
	title = {Java {Bytecode} {Verification}: {Algorithms} and {Formalizations}},
	volume = {30},
	issn = {0168-7433, 1573-0670},
	shorttitle = {Java {Bytecode} {Verification}},
	url = {https://link.springer.com/article/10.1023/A:1025055424017},
	doi = {10.1023/A:1025055424017},
	abstract = {Bytecode verification is a crucial security component for Java applets, on the Web and on embedded devices such as smart cards. This paper reviews the various bytecode verification algorithms that have been proposed, recasts them in a common framework of dataflow analysis, and surveys the use of proof assistants to specify bytecode verification and prove its correctness.},
	language = {en},
	number = {3-4},
	urldate = {2017-11-11},
	journal = {Journal of Automated Reasoning},
	author = {Leroy, Xavier},
	month = may,
	year = {2003},
	pages = {235--269},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/BDMRQBEU/Leroy - 2003 - Java Bytecode Verification Algorithms and Formali.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/AVBMVBXU/10.html:text/html}
}

@article{hunt_singularity_2004,
	title = {Singularity {Design} {Motivation}},
	url = {https://www.microsoft.com/en-us/research/publication/singularity-design-motivation/},
	abstract = {Singularity is a cross-discipline research project in Microsoft Research building a managed code operating system. This technical report describes the motivation and priorities for Singularity. Other technical reports describe the abstractions and implementations of Singularity features.},
	urldate = {2017-11-11},
	journal = {Microsoft Research},
	author = {Hunt, Galen and Larus, Jim},
	month = nov,
	year = {2004},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/V4FM6DPL/Hunt and Larus - 2004 - Singularity Design Motivation.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/9CHFMXKS/singularity-design-motivation.html:text/html}
}

@inproceedings{barnett_spec_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {The {Spec}\# {Programming} {System}: {An} {Overview}},
	isbn = {978-3-540-24287-1 978-3-540-30569-9},
	shorttitle = {The {Spec}\# {Programming} {System}},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-30569-9_3},
	doi = {10.1007/978-3-540-30569-9_3},
	abstract = {The Spec\# programming system is a new attempt at a more cost effective way to develop and maintain high-quality software. This paper describes the goals and architecture of the Spec\# programming system, consisting of the object-oriented Spec\# programming language, the Spec\# compiler, and the Boogie static program verifier. The language includes constructs for writing specifications that capture programmer intentions about how methods and data are to be used, the compiler emits run-time checks to enforce these specifications, and the verifier can check the consistency between a program and its specifications.},
	language = {en},
	urldate = {2017-11-11},
	booktitle = {Construction and {Analysis} of {Safe}, {Secure}, and {Interoperable} {Smart} {Devices}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Barnett, Mike and Leino, K. Rustan M. and Schulte, Wolfram},
	month = mar,
	year = {2004},
	pages = {49--69},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/5FZ9KSD7/Barnett et al. - 2004 - The Spec# Programming System An Overview.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/CB4CFN9F/10.html:text/html}
}

@inproceedings{lisitsa_towards_2005,
	title = {Towards verification via supercompilation},
	volume = {2},
	doi = {10.1109/COMPSAC.2005.159},
	abstract = {Supercompilation, or supervised compilation is a technique for program specialization, optimization and, more generally, program transformation. We present an idea to use supercompilation for verification of parameterized programs and protocols, present a case study and report on our initial experiments.},
	booktitle = {29th {Annual} {International} {Computer} {Software} and {Applications} {Conference} ({COMPSAC}'05)},
	author = {Lisitsa, A. and Nemytykh, A.},
	month = jul,
	year = {2005},
	keywords = {Protocols, Computer languages, program compilers, Computer applications, Computer science, Concrete, formal verification, History, Power system modeling, program optimization, program specialization, program transformation, Resource description framework, Software testing, supercompilation, System testing},
	pages = {9--10 Vol. 1},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/Z4WLQ6QE/1508067.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/XPALV5Q5/Lisitsa and Nemytykh - 2005 - Towards verification via supercompilation.pdf:application/pdf}
}

@inproceedings{hallgren_principled_2005,
	address = {New York, NY, USA},
	series = {{ICFP} '05},
	title = {A {Principled} {Approach} to {Operating} {System} {Construction} in {Haskell}},
	isbn = {978-1-59593-064-4},
	url = {http://doi.acm.org/10.1145/1086365.1086380},
	doi = {10.1145/1086365.1086380},
	abstract = {We describe a monadic interface to low-level hardware features that is a suitable basis for building operating systems in Haskell. The interface includes primitives for controlling memory management hardware, user-mode process execution, and low-level device I/O. The interface enforces memory safety in nearly all circumstances. Its behavior is specified in part by formal assertions written in a programming logic called P-Logic. The interface has been implemented on bare IA32 hardware using the Glasgow Haskell Compiler (GHC) runtime system. We show how a variety of simple O/S kernels can be constructed on top of the interface, including a simple separation kernel and a demonstration system in which the kernel, window system, and all device drivers are written in Haskell.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {Tenth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Hallgren, Thomas and Jones, Mark P. and Leslie, Rebekah and Tolmach, Andrew},
	year = {2005},
	keywords = {hardware interface, Haskell, monads, operating systems, programming logic, verification},
	pages = {116--128},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/NHIE7IWP/Hallgren et al. - 2005 - A Principled Approach to Operating System Construc.pdf:application/pdf}
}

@article{alpern_jikes_2005,
	title = {The {Jikes} {Research} {Virtual} {Machine} project: {Building} an open-source research community},
	volume = {44},
	issn = {0018-8670},
	shorttitle = {The {Jikes} {Research} {Virtual} {Machine} project},
	doi = {10.1147/sj.442.0399},
	abstract = {This paper describes the evolution of the Jikes{\texttrademark} Research Virtual Machine project from an IBM internal research project, called Jalape{\~n}o, into an open-source project. After summarizing the original goals of the project, we discuss the motivation for releasing it as an open-source project and the activities performed to ensure the success of the project. Throughout, we highlight the unique challenges of developing and maintaining an open-source project designed specifically to support a research community.},
	number = {2},
	journal = {IBM Systems Journal},
	author = {Alpern, B. and Augart, S. and Blackburn, S. M. and Butrico, M. and Cocchi, A. and Cheng, P. and Dolby, J. and Fink, S. and Grove, D. and Hind, M. and McKinley, K. S. and Mergen, M. and Moss, J. E. B. and Ngo, T. and Sarkar, V. and Trapp, M.},
	year = {2005},
	pages = {399--417},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/QPE9ZXNA/5386722.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/EYDPZ64K/Alpern et al. - 2005 - The Jikes Research Virtual Machine project Buildi.pdf:application/pdf}
}

@article{hunt_overview_2005,
	title = {An {Overview} of the {Singularity} {Project}},
	url = {https://www.microsoft.com/en-us/research/publication/an-overview-of-the-singularity-project/},
	abstract = {Singularity is a research project in Microsoft Research that started with the question: what would a software platform look like if it was designed from scratch with the primary goal of dependability? Singularity is working to answer this question by building on advances in programming languages and tools to develop a new system architecture and {\textellipsis}},
	urldate = {2017-11-11},
	journal = {Microsoft Research},
	author = {Hunt, Galen and Abadi, Martin and Barham, Paul and Fahndrich, Manuel and Hawblitzel, Chris and Hodson, Orion and Levi, Steven and Wobber, Ted and Zill, Brian and Larus, Jim},
	month = oct,
	year = {2005},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/964VBIY4/Hunt et al. - 2005 - An Overview of the Singularity Project.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/HKNJXFFK/an-overview-of-the-singularity-project.html:text/html}
}

@inproceedings{hindman_atomicity_2006,
	address = {New York, NY, USA},
	series = {{MSPC} '06},
	title = {Atomicity via {Source}-to-source {Translation}},
	isbn = {978-1-59593-578-6},
	url = {http://doi.acm.org/10.1145/1178597.1178611},
	doi = {10.1145/1178597.1178611},
	abstract = {We present an implementation and evaluation of atomicity (also known as software transactions) for a dialect of Java. Our implementation is fundamentally different from prior work in three respects: (1) It is entirely a source-to-source translation, producing Java source code that can be compiled by any Java compiler and run on any Java Virtual Machine. (2) It can enforce "strong" atomicity without assuming special hardware or a uniprocessor. (3) The implementation uses locks rather than optimistic concurrency, but it cannot deadlock and requires inter-thread communication only when there is data contention.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2006 {Workshop} on {Memory} {System} {Performance} and {Correctness}},
	publisher = {ACM},
	author = {Hindman, Benjamin and Grossman, Dan},
	year = {2006},
	keywords = {Java, atomicity, concurrent programming, transactional memory},
	pages = {82--91},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/CD9LTTAT/Hindman and Grossman - 2006 - Atomicity via Source-to-source Translation.pdf:application/pdf}
}

@inproceedings{yamauchi_writing_2006,
	address = {New York, NY, USA},
	series = {{PLOS} '06},
	title = {Writing {Solaris} {Device} {Drivers} in {Java}},
	isbn = {978-1-59593-577-9},
	url = {http://doi.acm.org/10.1145/1215995.1215998},
	doi = {10.1145/1215995.1215998},
	abstract = {Operating system kernels have been traditionally written in C for flexibility and efficiency. They, however, often suffer from bugs and security vulnerabilities because C is inherently error-prone and unsafe. While there have been attempts to experimentally construct a complete operating system in a type safe language such as Java for higher safety and reliability, such type safe operating systems are not mainstream as yet. In this paper, we present an experimental implementation of the Java Virtual Machine that runs inside the kernel of the Solaris operating system. Our approach is to extend the existing operating system, rather than creating a new operating system from scratch, in order to reap the benefits of a type safe language in the kernel without expensive development and transition cost for a new operating system architecture. We implemented our system by porting an existing small, portable JVM, Squawk, into the Solaris kernel. Our first application of this system is to allow device drivers to be written in Java. A simple device driver was ported from C to Java. Characteristics of the Java device driver and our device driver interface are described.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 3rd {Workshop} on {Programming} {Languages} and {Operating} {Systems}: {Linguistic} {Support} for {Modern} {Operating} {Systems}},
	publisher = {ACM},
	author = {Yamauchi, Hiroshi and Wolczko, Mario},
	year = {2006},
	keywords = {operating systems, device drivers, type-safe languages},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/LPT7G8NB/Yamauchi and Wolczko - 2006 - Writing Solaris Device Drivers in Java.pdf:application/pdf}
}

@article{cachopo_versioned_2006,
	series = {Special issue on synchronization and concurrency in object-oriented languages},
	title = {Versioned boxes as the basis for memory transactions},
	volume = {63},
	issn = {0167-6423},
	url = {http://www.sciencedirect.com/science/article/pii/S0167642306001171},
	doi = {10.1016/j.scico.2006.05.009},
	abstract = {In this paper, we propose the use of Versioned Boxes, which keep a history of values, as the basis for language-level memory transactions. Unlike previous work on software transactional memory, in our proposal read-only transactions never conflict with any other concurrent transaction. This may improve significantly the concurrency on applications which have longer transactions and a high read/write ratio. Furthermore, we discuss how we can reduce transaction conflicts by delaying computations and re-executing only parts of a transaction in case of a conflict. We propose two language-level abstractions to support these strategies: the per-transaction boxes and the restartable transactions. Finally, we lay out the basis for a more generic model, which better supports fine-grained restartable transactions. The goal of this new model is to generalize the previous two abstractions to reduce conflicts.},
	number = {2},
	urldate = {2017-11-11},
	journal = {Science of Computer Programming},
	author = {Cachopo, Jo{\~a}o and Rito-Silva, Ant{\'o}nio},
	month = dec,
	year = {2006},
	keywords = {Conflict reduction, Multi-version concurrency control, Software transactional memory, Transactions},
	pages = {172--185},
	file = {ScienceDirect Full Text PDF:/Volumes/Data/work/zotero/storage/77L9QTGT/Cachopo and Rito-Silva - 2006 - Versioned boxes as the basis for memory transactio.pdf:application/pdf;ScienceDirect Snapshot:/Volumes/Data/work/zotero/storage/HLH3QHIB/S0167642306001171.html:text/html}
}

@article{fahndrich_language_2006,
	title = {Language {Support} for {Fast} and {Reliable} {Message}-based {Communication} in {Singularity} {OS}},
	url = {https://www.microsoft.com/en-us/research/publication/language-support-for-fast-and-reliable-message-based-communication-in-singularity-os/},
	abstract = {Message-based communication offers the potential benefits of providing stronger specification and cleaner separation between components. Compared with shared-memory interactions, message passing has the potential disadvantages of more expensive data exchange (no direct sharing) and more complicated programming. In this paper we report on the language, verification, and run-time system features that make messages practical as {\textellipsis}},
	urldate = {2017-11-11},
	journal = {Microsoft Research},
	author = {Fahndrich, Manuel and Aiken, Mark and Hawblitzel, Chris and Hodson, Orion and Hunt, Galen and Larus, Jim and Levi, Steven},
	month = apr,
	year = {2006},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/UKFJ96R8/Fahndrich et al. - 2006 - Language Support for Fast and Reliable Message-bas.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/B3NEXJB9/language-support-for-fast-and-reliable-message-based-communication-in-singularity-os.html:text/html}
}

@article{collberg_empirical_2007,
	title = {An empirical study of {Java} bytecode programs},
	volume = {37},
	issn = {1097-024X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.776/abstract},
	doi = {10.1002/spe.776},
	abstract = {We present a study of the static structure of real Java bytecode programs. A total of 1132 Java jar-files were collected from the Internet and analyzed. In addition to simple counts (number of methods per class, number of bytecode instructions per method, etc.), structural metrics such as the complexity of control-flow and inheritance graphs were computed. We believe this study will be valuable in the design of future programming languages and virtual machine instruction sets, as well as in the efficient implementation of compilers and other language processors. Copyright {\textcopyright} 2006 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {6},
	urldate = {2017-11-11},
	journal = {Software: Practice and Experience},
	author = {Collberg, Christian and Myles, Ginger and Stepp, Michael},
	month = may,
	year = {2007},
	keywords = {Java, bytecode, measure, software complexity metrics},
	pages = {581--641},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/P2N3ATDN/Collberg et al. - 2007 - An empirical study of Java bytecode programs.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/S9IRIET3/abstract.html:text/html}
}

@inproceedings{gay_safe_2007,
	address = {New York, NY, USA},
	series = {{ISMM} '07},
	title = {Safe {Manual} {Memory} {Management}},
	isbn = {978-1-59593-893-0},
	url = {http://doi.acm.org/10.1145/1296907.1296911},
	doi = {10.1145/1296907.1296911},
	abstract = {We present HeapSafe, a tool that uses reference counting to dynamically verify the soundness of manual memory management of C programs. HeapSafe relies on asimple extension to the usual malloc/free memory management API: delayed free scopes during which otherwise dangling references can exist. Porting programs for use with HeapSafe typically requires little effort (on average 0.6\% oflines change), adds an average 11\% time overhead (84\% in the worst case), and increases space usage by an average of 13\%. These results are based on portingover half a million lines of C code, including perl where we found sixpreviously unknown bugs.Many existing C programs continue to use unchecked manual memorymanagement. One reason is that programmers fear that moving to garbage collection is too big a risk. We believe that HeapSafe is a practical way toprovide safe memory management for such programs. Since HeapSafe checks existing memory management rather than changing it, programmers need not worrythat HeapSafe will introduce new bugs; and, since HeapSafe does not managememory itself, programmers can choose to deploy their programs without HeapSafe if performance is critical (a simple header file allows HeapSafe programs to compile and run with a regular C compiler). In contrast, we foundthat garbage collection, although faster, had much higher space overhead, and occasionally caused a space-usage explosion that made the program unusable.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 6th {International} {Symposium} on {Memory} {Management}},
	publisher = {ACM},
	author = {Gay, David and Ennals, Rob and Brewer, Eric},
	year = {2007},
	keywords = {C, memory management, reference counting, safety},
	pages = {2--14},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/HZI238P2/Gay et al. - 2007 - Safe Manual Memory Management.pdf:application/pdf}
}

@inproceedings{kinneer_sofya:_2007,
	title = {Sofya: {Supporting} {Rapid} {Development} of {Dynamic} {Program} {Analyses} for {Java}},
	shorttitle = {Sofya},
	doi = {10.1109/ICSECOMPANION.2007.68},
	abstract = {Dynamic analysis is an increasingly important means of supporting software validation and maintenance. To date, developers of dynamic analyses have used low-level instrumentation and debug interfaces to realize their analyses. Many dynamic analyses, however, share multiple common high-level requirements, e.g., capture of program data state as well as events, and efficient and accurate event capture in the presence of threading. We present SOFYA - an infra-structure designed to provide high-level, efficient, concurrency-aw are support for building analyses that reason about rich observations of program data and events. It provides a layered, modular architecture, which has been successfully used to rapidly develop and evaluate a variety of demanding dynamic program analyses. In this paper, we describe the SOFYA framework, the challenges it addresses, and survey several such analyses.},
	booktitle = {29th {International} {Conference} on {Software} {Engineering} - {Companion}, 2007. {ICSE} 2007 {Companion}},
	author = {Kinneer, A. and Dwyer, M. B. and Rothermel, G.},
	month = may,
	year = {2007},
	keywords = {Java, Software maintenance, Computer science, Buildings, Concurrent computing, debug interfaces, dynamic program analyses, Instruments, modular architecture, Monitoring, Payloads, Performance analysis, program data observations, program diagnostics, program verification, software maintenance, software validation, SOFYA framework, Yarn},
	pages = {51--52},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/ISXRMTMN/4222676.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/V6JL39T3/Kinneer et al. - 2007 - Sofya Supporting Rapid Development of Dynamic Pro.pdf:application/pdf}
}

@book{kuleshov_using_2007,
	title = {Using the {ASM} framework to implement common {Java} bytecode transformation patterns},
	author = {Kuleshov, Eugene},
	year = {2007},
	file = {Citeseer - Full Text PDF:/Volumes/Data/work/zotero/storage/8ECNLPNX/Kuleshov - 2007 - Using the ASM framework to implement common Java b.pdf:application/pdf;Citeseer - Snapshot:/Volumes/Data/work/zotero/storage/AS2T2AXP/summary.html:text/html}
}

@inproceedings{mitchell_supercompiler_2007,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Supercompiler} for {Core} {Haskell}},
	isbn = {978-3-540-85372-5 978-3-540-85373-2},
	url = {https://link.springer.com/chapter/10.1007/978-3-540-85373-2_9},
	doi = {10.1007/978-3-540-85373-2_9},
	abstract = {Haskell is a functional language, with features such as higher order functions and lazy evaluation, which allow succinct programs. These high-level features present many challenges for optimising compilers. We report practical experiments using novel variants of supercompilation, with special attention to let bindings and the generalisation technique.},
	language = {en},
	urldate = {2017-11-11},
	booktitle = {Implementation and {Application} of {Functional} {Languages}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Mitchell, Neil and Runciman, Colin},
	month = sep,
	year = {2007},
	pages = {147--164},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/3T9SUZ5H/Mitchell and Runciman - 2007 - A Supercompiler for Core Haskell.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/JYRJPCMS/10.html:text/html}
}

@inproceedings{binder_reengineering_2007,
	title = {Reengineering {Standard} {Java} {Runtime} {Systems} through {Dynamic} {Bytecode} {Instrumentation}},
	doi = {10.1109/SCAM.2007.20},
	abstract = {Java bytecode instrumentation is a widely used technique, especially for profiling purposes. In order to ensure the instrumentation of all classes in the system, including dynamically generated or downloaded code, instrumentation has to be performed at runtime. The standard JDK offers some mechanisms for dynamic instrumentation, which however either require the use of native code or impose severe restrictions on the instrumentation of certain core classes of the JDK. These limitations prevent several instrumentation techniques that are important for efficient, calling context-sensitive profiling. In this paper we present a generic bytecode instrumentation framework that goes beyond these restrictions and enables the customized, dynamic instrumentation of all classes in pure Java. Our framework addresses important issues, such as bootstrapping an instrumented JDK, as well as avoiding measurement perturbations due to dynamic instrumentation or execution of instrumentation code. We validated and evaluated our framework using an instrumentation for exact profiling which generates complete calling context trees of various platform-independent dynamic metrics.},
	booktitle = {Seventh {IEEE} {International} {Working} {Conference} on {Source} {Code} {Analysis} and {Manipulation} ({SCAM} 2007)},
	author = {Binder, W. and Hulaas, J. and Moret, P.},
	month = sep,
	year = {2007},
	keywords = {Java, Runtime, Libraries, Instruments, Performance analysis, aspect-oriented programming, bootstrapping, Code standards, Communication standards, computer bootstrapping, context-sensitive profiling, dynamic bytecode instrumentation, dynamic metrics, Dynamic programming, Informatics, Java dynamic bytecode instrumentation, JVM, Manipulator dynamics, profiling, program transformations, software libraries, standard Java runtime system reengineering, systems re-engineering, virtual machines},
	pages = {91--100},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/XBF7PL7V/4362901.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/LQNG6DB6/Binder et al. - 2007 - Reengineering Standard Java Runtime Systems throug.pdf:application/pdf}
}

@article{erren_ten_2007,
	title = {Ten {Simple} {Rules} for {Doing} {Your} {Best} {Research}, {According} to {Hamming}},
	volume = {3},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030213},
	doi = {10.1371/journal.pcbi.0030213},
	number = {10},
	urldate = {2017-11-11},
	journal = {PLOS Computational Biology},
	author = {Erren, Thomas C. and Cullen, Paul and Erren, Michael and Bourne, Philip E.},
	month = oct,
	year = {2007},
	keywords = {Computer and information sciences, Creativity, Distillation, Fathers, Information theory, Physicists, Scientists, Telecommunications},
	pages = {e213},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/RFK49KQ7/Erren et al. - 2007 - Ten Simple Rules for Doing Your Best Research, Acc.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/UPHAN9SH/article.html:text/html}
}

@article{lhotak_evaluating_2008,
	title = {Evaluating the {Benefits} of {Context}-sensitive {Points}-to {Analysis} {Using} a {BDD}-based {Implementation}},
	volume = {18},
	issn = {1049-331X},
	url = {http://doi.acm.org/10.1145/1391984.1391987},
	doi = {10.1145/1391984.1391987},
	abstract = {We present Paddle, a framework of BDD-based context-sensitive points-to and call graph analyses for Java, as well as client analyses that use their results. Paddle supports several variations of context-sensitive analyses, including call site strings and object sensitivity, and context-sensitively specializes both pointer variables and the heap abstraction. We empirically evaluate the precision of these context-sensitive analyses on significant Java programs. We find that that object-sensitive analyses are more precise than comparable variations of the other approaches, and that specializing the heap abstraction improves precision more than extending the length of context strings.},
	number = {1},
	urldate = {2017-11-11},
	journal = {ACM Trans. Softw. Eng. Methodol.},
	author = {Lhot{\'a}k, Ond{\v r}ej and Hendren, Laurie},
	month = oct,
	year = {2008},
	keywords = {Java, binary decision diagrams, call graph construction, cast safety analysis, context sensitivity, Interprocedural program analysis, points-to analysis},
	pages = {3:1--3:53},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/96WDZGXD/Lhot{\'a}k and Hendren - 2008 - Evaluating the Benefits of Context-sensitive Point.pdf:application/pdf}
}

@inproceedings{holkner_evaluating_2009,
	address = {Darlinghurst, Australia, Australia},
	series = {{ACSC} '09},
	title = {Evaluating the {Dynamic} {Behaviour} of {Python} {Applications}},
	isbn = {978-1-920682-72-9},
	url = {http://dl.acm.org/citation.cfm?id=1862659.1862665},
	abstract = {The Python programming language is typical among dynamic languages in that programs written in it are not susceptible to static analysis. This makes efficient static program compilation difficult, as well as limiting the amount of early error detection that can be performed. Prior research in this area tends to make assumptions about the nature of programs written in Python, restricting the expressiveness of the language. One may question why programmers are drawn to these languages at all, if only to use them in a static-friendly style. In this paper we present our results after measuring the dynamic behaviour of 24 production-stage open source Python programs. The programs tested included arcade games, GUI applications and non-interactive batch programs. We found that while most dynamic activity occurs during program startup, dynamic activity after startup cannot be discounted entirely.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {Thirty}-{Second} {Australasian} {Conference} on {Computer} {Science} - {Volume} 91},
	publisher = {Australian Computer Society, Inc.},
	author = {Holkner, Alex and Harland, James},
	year = {2009},
	keywords = {dynamic languages, Python and compilers},
	pages = {19--28},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/EGCHB39A/Holkner and Harland - 2009 - Evaluating the Dynamic Behaviour of Python Applica.pdf:application/pdf}
}

@inproceedings{frampton_demystifying_2009,
	address = {New York, NY, USA},
	series = {{VEE} '09},
	title = {Demystifying {Magic}: {High}-level {Low}-level {Programming}},
	isbn = {978-1-60558-375-4},
	shorttitle = {Demystifying {Magic}},
	url = {http://doi.acm.org/10.1145/1508293.1508305},
	doi = {10.1145/1508293.1508305},
	abstract = {The power of high-level languages lies in their abstraction over hardware and software complexity, leading to greater security, better reliability, and lower development costs. However, opaque abstractions are often show-stoppers for systems programmers, forcing them to either break the abstraction, or more often, simply give up and use a different language. This paper addresses the challenge of opening up a high-level language to allow practical low-level programming without forsaking integrity or performance. The contribution of this paper is three-fold: 1) we draw together common threads in a diverse literature, 2) we identify a framework for extending high-level languages for low-level programming, and 3) we show the power of this approach through concrete case studies. Our framework leverages just three core ideas: extending semantics via intrinsic methods, extending types via unboxing and architectural-width primitives, and controlling semantics via scoped semantic regimes. We develop these ideas through the context of a rich literature and substantial practical experience. We show that they provide the power necessary to implement substantial artifacts such as a high-performance virtual machine, while preserving the software engineering benefits of the host language. The time has come for high-level low-level programming to be taken more seriously: 1) more projects now use high-level languages for systems programming, 2) increasing architectural heterogeneity and parallelism heighten the need for abstraction, and 3) a new generation of high-level languages are under development and ripe to be influenced.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2009 {ACM} {SIGPLAN}/{SIGOPS} {International} {Conference} on {Virtual} {Execution} {Environments}},
	publisher = {ACM},
	author = {Frampton, Daniel and Blackburn, Stephen M. and Cheng, Perry and Garner, Robin J. and Grove, David and Moss, J. Eliot B. and Salishev, Sergey I.},
	year = {2009},
	keywords = {systems programming, debugging, intrinsics, jikes rvm, magic, mmtk, virtualization, vmmagic},
	pages = {81--90},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/HFNEJJ25/Frampton et al. - 2009 - Demystifying Magic High-level Low-level Programmi.pdf:application/pdf}
}

@inproceedings{che_rodinia:_2009,
	title = {Rodinia: {A} benchmark suite for heterogeneous computing},
	shorttitle = {Rodinia},
	doi = {10.1109/IISWC.2009.5306797},
	abstract = {This paper presents and characterizes Rodinia, a benchmark suite for heterogeneous computing. To help architects study emerging platforms such as GPUs (Graphics Processing Units), Rodinia includes applications and kernels which target multi-core CPU and GPU platforms. The choice of applications is inspired by Berkeley's dwarf taxonomy. Our characterization shows that the Rodinia benchmarks cover a wide range of parallel communication patterns, synchronization techniques and power consumption, and has led to some important architectural insight, such as the growing importance of memory-bandwidth limitations and the consequent importance of data layout.},
	booktitle = {2009 {IEEE} {International} {Symposium} on {Workload} {Characterization} ({IISWC})},
	author = {Che, S. and Boyer, M. and Meng, J. and Tarjan, D. and Sheaffer, J. W. and Lee, S. H. and Skadron, K.},
	month = oct,
	year = {2009},
	keywords = {Application software, Yarn, Benchmark testing, Berkeleys dwarf taxonomy, Central Processing Unit, Computer architecture, data layout, Energy consumption, heterogeneous computing, Kernel, memory-bandwidth limitation, Microprocessors, multicore CPU platform, multicore GPU platform, Multicore processing, parallel communication pattern, Parallel processing, parallel program, parallel programming, power consumption, Rodinia-a benchmark suite, synchronization technique},
	pages = {44--54},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/G6CVUCGG/5306797.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/5VHPSFJX/Che et al. - 2009 - Rodinia A benchmark suite for heterogeneous compu.pdf:application/pdf}
}

@inproceedings{qi_masked_2009,
	address = {New York, NY, USA},
	series = {{POPL} '09},
	title = {Masked {Types} for {Sound} {Object} {Initialization}},
	isbn = {978-1-60558-379-2},
	url = {http://doi.acm.org/10.1145/1480881.1480890},
	doi = {10.1145/1480881.1480890},
	abstract = {This paper presents a type-based solution to the long-standing problem of object initialization. Constructors, the conventional mechanism for object initialization, have semantics that are surprising to programmers and that lead to bugs. They also contribute to the problem of null-pointer exceptions, which make software less reliable. Masked types are a new type-state mechanism that explicitly tracks the initialization state of objects and prevents reading from uninitialized fields. In the resulting language, constructors are ordinary methods that operate on uninitialized objects, and no special default value (null) is needed in the language. Initialization of cyclic data structures is achieved with the use of conditionally masked types. Masked types are modular and compatible with data abstraction. The type system is presented in a simplified object calculus and is proved to soundly prevent reading from uninitialized fields. Masked types have been implemented as an extension to Java, in which compilation simply erases extra type information. Experience using the extended language suggests that masked types work well on real code.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 36th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Qi, Xin and Myers, Andrew C.},
	year = {2009},
	keywords = {conditional masks, cyclic data structures, data abstraction, invariants, null pointer exceptions},
	pages = {53--65},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/GDDXXPWT/Qi and Myers - 2009 - Masked Types for Sound Object Initialization.pdf:application/pdf}
}

@inproceedings{bloom_thorn:_2009,
	address = {New York, NY, USA},
	series = {{OOPSLA} '09},
	title = {Thorn: {Robust}, {Concurrent}, {Extensible} {Scripting} on the {JVM}},
	isbn = {978-1-60558-766-0},
	shorttitle = {Thorn},
	url = {http://doi.acm.org/10.1145/1640089.1640098},
	doi = {10.1145/1640089.1640098},
	abstract = {Scripting languages enjoy great popularity due to their support for rapid and exploratory development. They typically have lightweight syntax, weak data privacy, dynamic typing, powerful aggregate data types, and allow execution of the completed parts of incomplete programs. The price of these features comes later in the software life cycle. Scripts are hard to evolve and compose, and often slow. An additional weakness of most scripting languages is lack of support for concurrency - though concurrency is required for scalability and interacting with remote services. This paper reports on the design and implementation of Thorn, a novel programming language targeting the JVM. Our principal contributions are a careful selection of features that support the evolution of scripts into industrial grade programs - e.g., an expressive module system, an optional type annotation facility for declarations, and support for concurrency based on message passing between lightweight, isolated processes. On the implementation side, Thorn has been designed to accommodate the evolution of the language itself through a compiler plugin mechanism and target the Java virtual machine.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 24th {ACM} {SIGPLAN} {Conference} on {Object} {Oriented} {Programming} {Systems} {Languages} and {Applications}},
	publisher = {ACM},
	author = {Bloom, Bard and Field, John and Nystrom, Nathaniel and {\"O}stlund, Johan and Richards, Gregor and Strni{\v s}a, Rok and Vitek, Jan and Wrigstad, Tobias},
	year = {2009},
	keywords = {actors, pattern matching, scripting},
	pages = {117--136},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/G36L8MEC/Bloom et al. - 2009 - Thorn Robust, Concurrent, Extensible Scripting on.pdf:application/pdf}
}

@article{phadtare_scientific_2009,
	title = {Scientific writing: a randomized controlled trial comparing standard and on-line instruction},
	volume = {9},
	issn = {1472-6920},
	shorttitle = {Scientific writing},
	url = {https://doi.org/10.1186/1472-6920-9-27},
	doi = {10.1186/1472-6920-9-27},
	abstract = {Writing plays a central role in the communication of scientific ideas and is therefore a key aspect in researcher education, ultimately determining the success and long-term sustainability of their careers. Despite the growing popularity of e-learning, we are not aware of any existing study comparing on-line vs. traditional classroom-based methods for teaching scientific writing.},
	urldate = {2017-11-11},
	journal = {BMC Medical Education},
	author = {Phadtare, Amruta and Bahmani, Anu and Shah, Anand and Pietrobon, Ricardo},
	month = may,
	year = {2009},
	pages = {27},
	annote = {Pages 27 in PDF},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/QXBXNY93/Phadtare et al. - 2009 - Scientific writing a randomized controlled trial .pdf:application/pdf}
}

@inproceedings{auerbach_lime:_2010,
	address = {New York, NY, USA},
	series = {{OOPSLA} '10},
	title = {Lime: {A} {Java}-compatible and {Synthesizable} {Language} for {Heterogeneous} {Architectures}},
	isbn = {978-1-4503-0203-6},
	shorttitle = {Lime},
	url = {http://doi.acm.org/10.1145/1869459.1869469},
	doi = {10.1145/1869459.1869469},
	abstract = {The halt in clock frequency scaling has forced architects and language designers to look elsewhere for continued improvements in performance. We believe that extracting maximum performance will require compilation to highly heterogeneous architectures that include reconfigurable hardware. We present a new language, Lime, which is designed to be executable across a broad range of architectures, from FPGAs to conventional CPUs. We present the language as a whole, focusing on its novel features for limiting side-effects and integration of the streaming paradigm into an object- oriented language. We conclude with some initial results demonstrating applications running either on a CPU or co- executing on a CPU and an FPGA.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {ACM} {International} {Conference} on {Object} {Oriented} {Programming} {Systems} {Languages} and {Applications}},
	publisher = {ACM},
	author = {Auerbach, Joshua and Bacon, David F. and Cheng, Perry and Rabbah, Rodric},
	year = {2010},
	keywords = {fpga, functional programming, high level synthesis, object oriented, reconfigurable architecture, streaming, value type},
	pages = {89--108},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/QNDPVMS6/Auerbach et al. - 2010 - Lime A Java-compatible and Synthesizable Language.pdf:application/pdf}
}

@inproceedings{posnett_thex:_2010,
	title = {{THEX}: {Mining} metapatterns from java},
	shorttitle = {{THEX}},
	doi = {10.1109/MSR.2010.5463349},
	abstract = {Design patterns are codified solutions to common object-oriented design (OOD) problems in software development. One of the proclaimed benefits of the use of design patterns is that they decouple functionality and enable different parts of a system to change frequently without undue disruption throughout the system. These OOD patterns have received a wealth of attention in the research community since their introduction; however, identifying them in source code is a difficult problem. In contrast, metapatterns have similar effects on software design by enabling portions of the system to be extended or modified easily, but are purely structural in nature, and thus easier to detect. Our long-term goal is to evaluate the effects of different OOD patterns on coordination in software teams as well as outcomes such as developer productivity and software quality. we present THEX, a metapattern detector that scales to large codebases and works on any Java bytecode. We evaluate THEX by examining its performance on codebases with known design patterns (and therefore metapatterns) and find that it performs quite well, with recall of over 90\%.},
	booktitle = {2010 7th {IEEE} {Working} {Conference} on {Mining} {Software} {Repositories} ({MSR} 2010)},
	author = {Posnett, D. and Bird, C. and Devanbu, P.},
	month = may,
	year = {2010},
	keywords = {Java, Object oriented modeling, Computer science, Birds, data mining, design patterns, Detectors, developer productivity, Java bytecode, metapattern detector, metapattern mining, object-oriented design, object-oriented programming, Productivity, Programming, software design, Software design, software development, software development management, Software performance, software quality, Software quality, software team coordination, source code, team working, THEX},
	pages = {122--125},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/NK9GS3HR/5463349.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/F4PA2HXC/Posnett et al. - 2010 - THEX Mining metapatterns from java.pdf:application/pdf}
}

@inproceedings{mitchell_rethinking_2010,
	address = {New York, NY, USA},
	series = {{ICFP} '10},
	title = {Rethinking {Supercompilation}},
	isbn = {978-1-60558-794-3},
	url = {http://doi.acm.org/10.1145/1863543.1863588},
	doi = {10.1145/1863543.1863588},
	abstract = {Supercompilation is a program optimisation technique that is particularly effective at eliminating unnecessary overheads. We have designed a new supercompiler, making many novel choices, including different termination criteria and handling of let bindings. The result is a supercompiler that focuses on simplicity, compiles programs quickly and optimises programs well. We have benchmarked our supercompiler, with some programs running more than twice as fast than when compiled with GHC.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Mitchell, Neil},
	year = {2010},
	keywords = {supercompilation, haskell, optimisation},
	pages = {309--320},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/4Z6QI4LW/Mitchell - 2010 - Rethinking Supercompilation.pdf:application/pdf}
}

@inproceedings{bolingbroke_supercompilation_2010,
	address = {New York, NY, USA},
	series = {Haskell '10},
	title = {Supercompilation by {Evaluation}},
	isbn = {978-1-4503-0252-4},
	url = {http://doi.acm.org/10.1145/1863523.1863540},
	doi = {10.1145/1863523.1863540},
	abstract = {This paper shows how call-by-need supercompilation can be recast to be based explicitly on an evaluator, contrasting with standard presentations which are specified as algorithms that mix evaluation rules with reductions that are unique to supercompilation. Building on standard operational-semantics technology for call-by-need languages, we show how to extend the supercompilation algorithm to deal with recursive let expressions.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {Third} {ACM} {Haskell} {Symposium} on {Haskell}},
	publisher = {ACM},
	author = {Bolingbroke, Maximilian and Peyton Jones, Simon},
	year = {2010},
	keywords = {supercompilation, haskell, optimisation, deforestation, specialisation},
	pages = {135--146},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/P88II97P/Bolingbroke and Peyton Jones - 2010 - Supercompilation by Evaluation.pdf:application/pdf}
}

@inproceedings{grechanik_empirical_2010,
	address = {New York, NY, USA},
	series = {{ESEM} '10},
	title = {An {Empirical} {Investigation} into a {Large}-scale {Java} {Open} {Source} {Code} {Repository}},
	isbn = {978-1-4503-0039-1},
	url = {http://doi.acm.org/10.1145/1852786.1852801},
	doi = {10.1145/1852786.1852801},
	abstract = {Getting insight into different aspects of source code artifacts is increasingly important -- yet there is little empirical research using large bodies of source code, and subsequently there are not much statistically significant evidence of common patterns and facts of how programmers write source code. We pose 32 research questions, explain rationale behind them, and obtain facts from 2,080 randomly chosen Java applications from Sourceforge. Among these facts we find that most methods have one or zero arguments or they do not return any values, few methods are overridden, most inheritance hierarchies have the depth of one, close to 50\% of classes are not explicitly inherited from any classes, and the number of methods is strongly correlated with the number of fields in a class.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2010 {ACM}-{IEEE} {International} {Symposium} on {Empirical} {Software} {Engineering} and {Measurement}},
	publisher = {ACM},
	author = {Grechanik, Mark and McMillan, Collin and DeFerrari, Luca and Comi, Marco and Crespi, Stefano and Poshyvanyk, Denys and Fu, Chen and Xie, Qing and Ghezzi, Carlo},
	year = {2010},
	keywords = {empirical study, large-scale software, mining software repositories, open source, patterns, practice, software repository},
	pages = {11:1--11:10},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/NV6YI8WT/Grechanik et al. - 2010 - An Empirical Investigation into a Large-scale Java.pdf:application/pdf}
}

@inproceedings{flanagan_fasttrack:_2009,
	address = {New York, NY, USA},
	series = {{PLDI} '09},
	title = {{FastTrack}: {Efficient} and {Precise} {Dynamic} {Race} {Detection}},
	isbn = {978-1-60558-392-1},
	shorttitle = {{FastTrack}},
	url = {http://doi.acm.org/10.1145/1542476.1542490},
	doi = {10.1145/1542476.1542490},
	abstract = {{\textbackslash}begin\{abstract\} Multithreaded programs are notoriously prone to race conditions. Prior work on dynamic race detectors includes fast but imprecise race detectors that report false alarms, as well as slow but precise race detectors that never report false alarms. The latter typically use expensive vector clock operations that require time linear in the number of program threads. This paper exploits the insight that the full generality of vector clocks is unnecessary in most cases. That is, we can replace heavyweight vector clocks with an adaptive lightweight representation that, for almost all operations of the target program, requires only constant space and supports constant-time operations. This representation change significantly improves time and space performance, with no loss in precision. Experimental results on Java benchmarks including the Eclipse development environment show that our FastTrack race detector is an order of magnitude faster than a traditional vector-clock race detector, and roughly twice as fast as the high-performance DJIT+ algorithm. FastTrack is even comparable in speed to Eraser on our Java benchmarks, while never reporting false alarms.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 30th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Flanagan, Cormac and Freund, Stephen N.},
	year = {2009},
	keywords = {concurrency, dynamic analysis, race conditions},
	pages = {121--133},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/XN94VAUL/Flanagan and Freund - 2009 - FastTrack Efficient and Precise Dynamic Race Dete.pdf:application/pdf}
}

@inproceedings{richards_analysis_2010,
	address = {New York, NY, USA},
	series = {{PLDI} '10},
	title = {An {Analysis} of the {Dynamic} {Behavior} of {JavaScript} {Programs}},
	isbn = {978-1-4503-0019-3},
	url = {http://doi.acm.org/10.1145/1806596.1806598},
	doi = {10.1145/1806596.1806598},
	abstract = {The JavaScript programming language is widely used for web programming and, increasingly, for general purpose computing. As such, improving the correctness, security and performance of JavaScript applications has been the driving force for research in type systems, static analysis and compiler techniques for this language. Many of these techniques aim to reign in some of the most dynamic features of the language, yet little seems to be known about how programmers actually utilize the language or these features. In this paper we perform an empirical study of the dynamic behavior of a corpus of widely-used JavaScript programs, and analyze how and why the dynamic features are used. We report on the degree of dynamism that is exhibited by these JavaScript programs and compare that with assumptions commonly made in the literature and accepted industry benchmark suites.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 31st {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Richards, Gregor and Lebresne, Sylvain and Burg, Brian and Vitek, Jan},
	year = {2010},
	keywords = {program analysis, dynamic metrics, dynamic behavior, execution tracing, javascript},
	pages = {1--12},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/PT4IYUIL/Richards et al. - 2010 - An Analysis of the Dynamic Behavior of JavaScript .pdf:application/pdf}
}

@article{korland_noninvasive_2010,
	title = {Noninvasive concurrency with {Java} {STM}},
	abstract = {In this paper we present a complete Java STM framework, called Deuce, intended as a platform for developing scalable concurrent applications and as a research tool for designing new STM algorithms. It was not clear if one could build an ecient Java STM without compiler support. Deuce provides several benets over existing Java STM frameworks: it avoids any changes or additions to the JVM, it does not require language extensions or intrusive APIs, and it does not impose any memory footprint or GC overhead. To support legacy libraries, Deuce dynamically instruments classes at load time and uses an original eld-based locking strategy to improve concur-rency. Deuce also provides a simple internal API allowing dierent STMs algorithms to be plugged in. We show empirical results that highlight the scalability of our framework running benchmarks with hundreds of concur-rent threads. This paper shows for the rst time that one can actually design a Java STM with reasonable performance without compiler support.},
	author = {Korland, Guy and Shavit, Nir and Felber, Pascal},
	month = jan,
	year = {2010},
	file = {e023f5543ad1b1128f84e463cc00d3e7775a.pdf:/Volumes/Data/work/zotero/storage/E7ND7BU7/e023f5543ad1b1128f84e463cc00d3e7775a.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/F8S48DQY/267398972_Noninvasive_concurrency_with_Java_STM.html:text/html}
}

@inproceedings{flanagan_roadrunner_2010,
	address = {New York, NY, USA},
	series = {{PASTE} '10},
	title = {The {RoadRunner} {Dynamic} {Analysis} {Framework} for {Concurrent} {Programs}},
	isbn = {978-1-4503-0082-7},
	url = {http://doi.acm.org/10.1145/1806672.1806674},
	doi = {10.1145/1806672.1806674},
	abstract = {RoadRunner is a dynamic analysis framework designed to facilitate rapid prototyping and experimentation with dynamic analyses for concurrent Java programs. It provides a clean API for communicating an event stream to back-end analyses, where each event describes some operation of interest performed by the target program, such as accessing memory, synchronizing on a lock, forking a new thread, and so on. This API enables the developer to focus on the essential algorithmic issues of the dynamic analysis, rather than on orthogonal infrastructure complexities. Each back-end analysis tool is expressed as a filter over the event stream, allowing easy composition of analyses into tool chains. This tool-chain architecture permits complex analyses to be described and implemented as a sequence of more simple, modular steps, and it facilitates experimentation with different tool compositions. Moreover, the ability to insert various monitoring tools into the tool chain facilitates debugging and performance tuning. Despite RoadRunner's flexibility, careful implementation and optimization choices enable RoadRunner-based analyses to offer comparable performance to traditional, monolithic analysis prototypes, while being up to an order of magnitude smaller in code size. We have used RoadRunner to develop several dozen tools and have successfully applied them to programs as large as the Eclipse programming environment.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 9th {ACM} {SIGPLAN}-{SIGSOFT} {Workshop} on {Program} {Analysis} for {Software} {Tools} and {Engineering}},
	publisher = {ACM},
	author = {Flanagan, Cormac and Freund, Stephen N.},
	year = {2010},
	keywords = {concurrency, dynamic analysis},
	pages = {1--8},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/62KZXRZW/Flanagan and Freund - 2010 - The RoadRunner Dynamic Analysis Framework for Conc.pdf:application/pdf}
}

@article{stone_opencl:_2010,
	title = {{OpenCL}: {A} {Parallel} {Programming} {Standard} for {Heterogeneous} {Computing} {Systems}},
	volume = {12},
	issn = {1521-9615},
	shorttitle = {{OpenCL}},
	doi = {10.1109/MCSE.2010.69},
	abstract = {The OpenCL standard offers a common API for program execution on systems composed of different types of computational devices such as multicore CPUs, GPUs, or other accelerators.},
	number = {3},
	journal = {Computing in Science Engineering},
	author = {Stone, J. E. and Gohara, D. and Shi, G.},
	month = may,
	year = {2010},
	keywords = {Runtime, Concurrent computing, Computer architecture, Kernel, Microprocessors, parallel programming, API, application program interfaces, computational devices, computer graphic equipment, Computer interfaces, coprocessors, GPU, Hardware, heterogeneous computing systems, High performance computing, multicore CPU, OpenCL standard, Parallel programming, parallel programming standard, program execution, Software standards},
	pages = {66--73},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/8M6598NZ/5457293.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/PNLEY8EW/Stone et al. - 2010 - OpenCL A Parallel Programming Standard for Hetero.pdf:application/pdf}
}

@inproceedings{tempero_qualitas_2010,
	title = {The {Qualitas} {Corpus}: {A} {Curated} {Collection} of {Java} {Code} for {Empirical} {Studies}},
	shorttitle = {The {Qualitas} {Corpus}},
	doi = {10.1109/APSEC.2010.46},
	abstract = {In order to increase our ability to use measurement to support software development practise we need to do more analysis of code. However, empirical studies of code are expensive and their results are difficult to compare. We describe the Qualitas Corpus, a large curated collection of open source Java systems. The corpus reduces the cost of performing large empirical studies of code and supports comparison of measurements of the same artifacts. We discuss its design, organisation, and issues associated with its development.},
	booktitle = {2010 {Asia} {Pacific} {Software} {Engineering} {Conference}},
	author = {Tempero, E. and Anslow, C. and Dietrich, J. and Han, T. and Li, J. and Lumpe, M. and Melton, H. and Noble, J.},
	month = nov,
	year = {2010},
	keywords = {Java, Libraries, Benchmark testing, software development, codes, curated code corpus, curated collection, Empirical studies, experimental infrastructure, Java code, open source Java systems, Pragmatics, Qualitas Corpus, Software, software engineering, Software engineering},
	pages = {336--345},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/2T9DTH3U/5693210.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/Z3DLRYSK/Tempero et al. - 2010 - The Qualitas Corpus A Curated Collection of Java .pdf:application/pdf}
}

@inproceedings{counsell_is_2010,
	address = {New York, NY, USA},
	series = {{WETSoM} '10},
	title = {Is a {Strategy} for {Code} {Smell} {Assessment} {Long} {Overdue}?},
	isbn = {978-1-60558-976-3},
	url = {http://doi.acm.org/10.1145/1809223.1809228},
	doi = {10.1145/1809223.1809228},
	abstract = {Code smells reflect code decay and, as such, developers should seek to eradicate such smells through application of 'deodorant' in the form of one or more refactorings. However, a dearth of studies exploring code smells either theoretically or empirically suggests that there are reasons why smell eradication is neither being applied in anger, nor the subject of significant research. In this paper, we present three studies as supporting evidence for this claim. The first is an analysis of a set of five, open-source Java systems, the second an empirical study of a sub-system of a proprietary, C\# web-based application and the third, a theoretical enumeration of smell-related refactorings. Key findings of the study were first, that developers seemed to avoid eradicating superficially 'simple' smells in favor of more 'obscure' ones; second, a wide range of conflicts and anomalies soon emerged when trying to identify smelly code. Finally, perceived effort to eradicate a smell may be a key factor. The study highlights the need for a clearer research strategy on the issue of code smells and all aspects of their identification and measurement.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2010 {ICSE} {Workshop} on {Emerging} {Trends} in {Software} {Metrics}},
	publisher = {ACM},
	author = {Counsell, S. and Hierons, R. M. and Hamza, H. and Black, S. and Durrand, M.},
	year = {2010},
	keywords = {Java, C\#, code smells, empirical studies, refactoring},
	pages = {32--38},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/M2SJU7SP/Counsell et al. - 2010 - Is a Strategy for Code Smell Assessment Long Overd.pdf:application/pdf}
}

@inproceedings{jonsson_taming_2011,
	address = {New York, NY, USA},
	series = {{PEPM} '11},
	title = {Taming {Code} {Explosion} in {Supercompilation}},
	isbn = {978-1-4503-0485-6},
	url = {http://doi.acm.org/10.1145/1929501.1929507},
	doi = {10.1145/1929501.1929507},
	abstract = {Supercompilation algorithms can perform great optimizations but sometimes suffer from the problem of code explosion. This results in huge binaries which might hurt the performance on a modern processor. We present a supercompilation algorithm that is fast enough to speculatively supercompile expressions and discard the result if it turned out bad. This allows us to supercompile large parts of the imaginary and spectral parts of nofib in a matter of seconds while keeping the binary size increase below 5\%.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 20th {ACM} {SIGPLAN} {Workshop} on {Partial} {Evaluation} and {Program} {Manipulation}},
	publisher = {ACM},
	author = {Jonsson, Peter A. and Nordlander, Johan},
	year = {2011},
	keywords = {supercompilation, haskell, deforestation},
	pages = {33--42},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/TFWSKD9T/Jonsson and Nordlander - 2011 - Taming Code Explosion in Supercompilation.pdf:application/pdf}
}

@inproceedings{winther_guarded_2011,
	address = {New York, NY, USA},
	series = {{FTfJP} '11},
	title = {Guarded {Type} {Promotion}: {Eliminating} {Redundant} {Casts} in {Java}},
	isbn = {978-1-4503-0893-9},
	shorttitle = {Guarded {Type} {Promotion}},
	url = {http://doi.acm.org/10.1145/2076674.2076680},
	doi = {10.1145/2076674.2076680},
	abstract = {In Java, explicit casts are ubiquitous since they bridge the gap between compile-time and runtime type safety. Since casts potentially throw a ClassCastException, many programmers use a defensive programming style of guarded casts. In this programming style casts are protected by a preceding conditional using the instanceof operator and thus the cast type is redundantly mentioned twice. We propose a new typing rule for Java called Guarded Type Promotion aimed at eliminating the need for the explicit casts when guarded. This new typing rule is backward compatible and has been fully implemented in a Java 6 compiler. Through our extensive testing of real-life code we show that guarded casts account for approximately one fourth of all casts and that Guarded Type Promotion can eliminate the need for 95 percent of these guarded casts.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 13th {Workshop} on {Formal} {Techniques} for {Java}-{Like} {Programs}},
	publisher = {ACM},
	author = {Winther, Johnni},
	year = {2011},
	keywords = {Java, type cast, type checking},
	pages = {6:1--6:8},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/2LVFNFIF/Winther - 2011 - Guarded Type Promotion Eliminating Redundant Cast.pdf:application/pdf}
}

@inproceedings{moret_polymorphic_2011,
	address = {New York, NY, USA},
	series = {{AOSD} '11},
	title = {Polymorphic {Bytecode} {Instrumentation}},
	isbn = {978-1-4503-0605-8},
	url = {http://doi.acm.org/10.1145/1960275.1960292},
	doi = {10.1145/1960275.1960292},
	abstract = {Bytecode instrumentation is a widely used technique to implement aspect weaving and dynamic analyses in virtual machines such as the Java Virtual Machine. Aspect weavers and other instrumentations are usually developed independently and combining them often requires significant engineering effort, if at all possible. In this paper we introduce polymorphic bytecode instrumentation (PBI), a simple but effective technique that allows dynamic dispatch amongst several, possibly independent instrumentations. PBI enables complete bytecode coverage, that is, any method with a bytecode representation can be instrumented. We illustrate further benefits of PBI with three case studies. First, we provide an implementation of execution levels for AspectJ, which avoid infinite regression and unwanted interference between aspects. Second, we present a framework for adaptive dynamic analysis, where the analysis to be performed can be changed at runtime by the user. Third, we describe how PBI can be used to support a form of dynamic mixin layers. We provide thorough performance evaluations with dynamic analysis aspects applied to standard benchmarks. We show that PBI-based execution levels are much faster than control flow pointcuts to avoid interference between aspects, and that their efficient integration in a practical aspect language is possible. We also demonstrate that PBI enables adaptive dynamic analysis tools that are more reactive to user inputs than existing tools that rely on dynamic aspect-oriented programming with runtime weaving.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {Tenth} {International} {Conference} on {Aspect}-oriented {Software} {Development}},
	publisher = {ACM},
	author = {Moret, Philippe and Binder, Walter and Tanter, {\'E}ric},
	year = {2011},
	keywords = {bytecode instrumentation, aspect-oriented programming, dynamic program analysis, java virtual machine, mixin layers, modularity constructs},
	pages = {129--140},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/AYI4M7ZN/Moret et al. - 2011 - Polymorphic Bytecode Instrumentation.pdf:application/pdf}
}

@inproceedings{gligoric_codese:_2011,
	address = {New York, NY, USA},
	series = {{ISSTA} '11},
	title = {{CoDeSe}: {Fast} {Deserialization} via {Code} {Generation}},
	isbn = {978-1-4503-0562-4},
	shorttitle = {{CoDeSe}},
	url = {http://doi.acm.org/10.1145/2001420.2001456},
	doi = {10.1145/2001420.2001456},
	abstract = {Many tools for automated testing, model checking, and debugging store and restore program states multiple times. Storing/restoring a program state is commonly done with serialization/deserialization. Traditionally, the format for stored states is based on data: serialization generates the data that encodes the state, and deserialization interprets this data to restore the state. We propose a new approach, called CoDeSe, where the format for stored states is based on code: serialization generates code whose execution restores the state, and deserialization simply executes the code. We implemented CoDeSe in Java and performed a number of experiments on deserialization of states. CoDeSe provides on average more than 6X speedup over the highly optimized deserialization from the standard Java library. Our new format also allows simple parallel deserialization that can provide additional speedup on top of the sequential CoDeSe but only for larger states.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2011 {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM},
	author = {Gligoric, Milos and Marinov, Darko and Kamin, Sam},
	year = {2011},
	keywords = {code generation, deserialization},
	pages = {298--308},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/TZAETHML/Gligoric et al. - 2011 - CoDeSe Fast Deserialization via Code Generation.pdf:application/pdf}
}

@inproceedings{parnin_java_2011,
	address = {New York, NY, USA},
	series = {{MSR} '11},
	title = {Java {Generics} {Adoption}: {How} {New} {Features} {Are} {Introduced}, {Championed}, or {Ignored}},
	isbn = {978-1-4503-0574-7},
	shorttitle = {Java {Generics} {Adoption}},
	url = {http://doi.acm.org/10.1145/1985441.1985446},
	doi = {10.1145/1985441.1985446},
	abstract = {Support for generic programming was added to the Java language in 2004, representing perhaps the most significant change to one of the most widely used programming languages today. Researchers and language designers anticipated this addition would relieve many long-standing problems plaguing developers, but surprisingly, no one has yet measured whether generics actually provide such relief. In this paper, we report on the first empirical investigation into how Java generics have been integrated into open source software by automatically mining the history of 20 popular open source Java programs, traversing more than 500 million lines of code in the process. We evaluate five hypotheses, each based on assertions made by prior researchers, about how Java developers use generics. For example, our results suggest that generics do not significantly reduce the number of type casts and that generics are usually adopted by a single champion in a project, rather than all committers.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 8th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Parnin, Chris and Bird, Christian and Murphy-Hill, Emerson},
	year = {2011},
	keywords = {generics, java, languages, post-mortem analysis},
	pages = {3--12},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/IPUEDD6G/Parnin et al. - 2011 - Java Generics Adoption How New Features Are Intro.pdf:application/pdf}
}

@inproceedings{richards_eval_2011,
	address = {Berlin, Heidelberg},
	series = {{ECOOP}'11},
	title = {The {Eval} {That} {Men} {Do}: {A} {Large}-scale {Study} of the {Use} of {Eval} in {Javascript} {Applications}},
	isbn = {978-3-642-22654-0},
	shorttitle = {The {Eval} {That} {Men} {Do}},
	url = {http://dl.acm.org/citation.cfm?id=2032497.2032503},
	abstract = {Transforming text into executable code with a function such as Java-Script's eval endows programmers with the ability to extend applications, at any time, and in almost any way they choose. But, this expressive power comes at a price: reasoning about the dynamic behavior of programs that use this feature becomes challenging. Any ahead-of-time analysis, to remain sound, is forced to make pessimistic assumptions about the impact of dynamically created code. This pessimism affects the optimizations that can be applied to programs and significantly limits the kinds of errors that can be caught statically and the security guarantees that can be enforced. A better understanding of how eval is used could lead to increased performance and security. This paper presents a large-scale study of the use of eval in JavaScript-based web applications. We have recorded the behavior of 337 MB of strings given as arguments to 550,358 calls to the eval function exercised in over 10,000 web sites. We provide statistics on the nature and content of strings used in eval expressions, as well as their provenance and data obtained by observing their dynamic behavior.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 25th {European} {Conference} on {Object}-oriented {Programming}},
	publisher = {Springer-Verlag},
	author = {Richards, Gregor and Hammer, Christian and Burg, Brian and Vitek, Jan},
	year = {2011},
	pages = {52--78},
	file = {10.1007%2F978-3-642-22655-7_4.pdf:/Volumes/Data/work/zotero/storage/YVZCQDBG/10.1007%2F978-3-642-22655-7_4.pdf:application/pdf}
}

@inproceedings{bacchelli_extracting_2011,
	title = {Extracting structured data from natural language documents with island parsing},
	doi = {10.1109/ASE.2011.6100103},
	abstract = {The design and evolution of a software system leave traces in various kinds of artifacts. In software, produced by humans for humans, many artifacts are written in natural language by people involved in the project. Such entities contain structured information which constitute a valuable source of knowledge for analyzing and comprehending a system's design and evolution. However, the ambiguous and informal nature of narrative is a serious challenge in gathering such information, which is scattered throughout natural language text. We present an approach-based on island parsing-to recognize and enable the parsing of structured information that occur in natural language artifacts. We evaluate our approach by applying it to mailing lists pertaining to three software systems. We show that this approach allows us to extract structured data from emails with high precision and recall.},
	booktitle = {2011 26th {IEEE}/{ACM} {International} {Conference} on {Automated} {Software} {Engineering} ({ASE} 2011)},
	author = {Bacchelli, A. and Cleve, A. and Lanza, M. and Mocci, A.},
	month = nov,
	year = {2011},
	keywords = {Java, Data mining, grammars, History, data mining, Electronic mail, Grammar, island parsing, natural language document, natural language processing, Natural languages, Production, structured information},
	pages = {476--479},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/5BKB8IXM/6100103.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/UZCFXMZC/Bacchelli et al. - 2011 - Extracting structured data from natural language d.pdf:application/pdf}
}

@inproceedings{stuchlik_static_2011,
	address = {New York, NY, USA},
	series = {{DLS} '11},
	title = {Static vs. {Dynamic} {Type} {Systems}: {An} {Empirical} {Study} {About} the {Relationship} {Between} {Type} {Casts} and {Development} {Time}},
	isbn = {978-1-4503-0939-4},
	shorttitle = {Static vs. {Dynamic} {Type} {Systems}},
	url = {http://doi.acm.org/10.1145/2047849.2047861},
	doi = {10.1145/2047849.2047861},
	abstract = {Static type systems are essential in computer science. However, there is hardly any knowledge about the impact of type systems on the resulting piece of software. While there are authors that state that static types increase the development speed, other authors argue the other way around. A previous experiment suggests that there are multiple factors that play a role for a comparison of statically and dynamically typed language. As a follow-up, this paper presents an empirical study with 21 subjects that compares programming tasks performed in Java and Groovy - programming tasks where the number of expected type casts vary in the statically typed language. The result of the study is, that the dynamically typed group solved the complete programming tasks significantly faster for most tasks - but that for larger tasks with a higher number of type casts no significant difference could be found.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 7th {Symposium} on {Dynamic} {Languages}},
	publisher = {ACM},
	author = {Stuchlik, Andreas and Hanenberg, Stefan},
	year = {2011},
	keywords = {software engineering, empirical research, programming language research, type systems},
	pages = {97--106},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/65LVDU64/Stuchlik and Hanenberg - 2011 - Static vs. Dynamic Type Systems An Empirical Stud.pdf:application/pdf}
}

@inproceedings{zheng_turbo_2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Turbo {DiSL}: {Partial} {Evaluation} for {High}-{Level} {Bytecode} {Instrumentation}},
	isbn = {978-3-642-30560-3 978-3-642-30561-0},
	shorttitle = {Turbo {DiSL}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-30561-0_24},
	doi = {10.1007/978-3-642-30561-0_24},
	abstract = {Bytecode instrumentation is a key technique for the implementation of dynamic program analysis tools such as profilers and debuggers. Traditionally, bytecode instrumentation has been supported by low-level bytecode engineering libraries that are difficult to use. Recently, the domain-specific aspect language DiSL has been proposed to provide high-level abstractions for the rapid development of efficient bytecode instrumentations. While DiSL supports user-defined expressions that are evaluated at weave-time, the DiSL programming model requires these expressions to be implemented in separate classes, thus increasing code size and impairing code readability and maintenance. In addition, the DiSL weaver may produce a significant amount of dead code, which may impair some optimizations performed by the runtime. In this paper we introduce Turbo, a novel partial evaluator for DiSL, which processes the generated instrumentation code, performs constant propagation, conditional reduction, and pattern-based code simplification, and executes pure methods at weave-time. With Turbo, it is often unnecessary to wrap expressions for evaluation at weave-time in separate classes, thus simplifying the programming model. We present Turbo{\textquoteright}s partial evaluation algorithm and illustrate its benefits with several case studies. We evaluate the impact of Turbo on weave-time performance and on runtime performance of the instrumented application.},
	language = {en},
	urldate = {2017-11-11},
	booktitle = {Objects, {Models}, {Components}, {Patterns}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Zheng, Yudi and Ansaloni, Danilo and Marek, Lukas and Sewe, Andreas and Binder, Walter and Villaz{\'o}n, Alex and Tuma, Petr and Qi, Zhengwei and Mezini, Mira},
	month = may,
	year = {2012},
	pages = {353--368},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/AIXMU4U5/Zheng et al. - 2012 - Turbo DiSL Partial Evaluation for High-Level Byte.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/LWD86U3M/978-3-642-30561-0_24.html:text/html}
}

@inproceedings{jensen_remedying_2012,
	address = {New York, NY, USA},
	series = {{ISSTA} 2012},
	title = {Remedying the {Eval} {That} {Men} {Do}},
	isbn = {978-1-4503-1454-1},
	url = {http://doi.acm.org/10.1145/2338965.2336758},
	doi = {10.1145/2338965.2336758},
	abstract = {A range of static analysis tools and techniques have been developed in recent years with the aim of helping JavaScript web application programmers produce code that is more robust, safe, and efficient. However, as shown in a previous large-scale study, many web applications use the JavaScript eval function to dynamically construct code from text strings in ways that obstruct existing static analyses. As a consequence, the analyses either fail to reason about the web applications or produce unsound or useless results.   We present an approach to soundly and automatically transform many common uses of eval into other language constructs to enable sound static analysis of web applications. By eliminating calls to eval, we expand the applicability of static analysis for JavaScript web applications in general.   The transformation we propose works by incorporating a refactoring technique into a dataflow analyzer. We report on our experimental results with a small collection of programming patterns extracted from popular web sites. Although there are inevitably cases where the transformation must give up, our technique succeeds in eliminating many nontrivial occurrences of eval.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2012 {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM},
	author = {Jensen, Simon Holm and Jonsson, Peter A. and M{\o}ller, Anders},
	year = {2012},
	pages = {34--44},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/H9PRP9GC/Jensen et al. - 2012 - Remedying the Eval That Men Do.pdf:application/pdf}
}

@inproceedings{mayer_empirical_2012,
	address = {New York, NY, USA},
	series = {{OOPSLA} '12},
	title = {An {Empirical} {Study} of the {Influence} of {Static} {Type} {Systems} on the {Usability} of {Undocumented} {Software}},
	isbn = {978-1-4503-1561-6},
	url = {http://doi.acm.org/10.1145/2384616.2384666},
	doi = {10.1145/2384616.2384666},
	abstract = {Abstract Although the study of static and dynamic type systems plays a major role in research, relatively little is known about the impact of type systems on software development. Perhaps one of the more common arguments for static type systems in languages such as Java or C++ is that they require developers to annotate their code with type names, which is thus claimed to improve the documentation of software. In contrast, one common argument against static type systems is that they decrease flexibility, which may make them harder to use. While these arguments are found in the literature, rigorous empirical evidence is lacking. We report on a controlled experiment where 27 subjects performed programming tasks on an undocumented API with a static type system (requiring type annotations) as well as a dynamic type system (which does not). Our results show that for some tasks, programmers had faster completion times using a static type system, while for others, the opposite held. We conduct an exploratory study to try and theorize why.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {ACM} {International} {Conference} on {Object} {Oriented} {Programming} {Systems} {Languages} and {Applications}},
	publisher = {ACM},
	author = {Mayer, Clemens and Hanenberg, Stefan and Robbes, Romain and Tanter, {\'E}ric and Stefik, Andreas},
	year = {2012},
	keywords = {empirical research, type systems, programming languages},
	pages = {683--702},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/SPSTV566/Mayer et al. - 2012 - An Empirical Study of the Influence of Static Type.pdf:application/pdf}
}

@inproceedings{dyer_declarative_2013,
	address = {New York, NY, USA},
	series = {{GPCE} '13},
	title = {Declarative {Visitors} to {Ease} {Fine}-grained {Source} {Code} {Mining} with {Full} {History} on {Billions} of {AST} {Nodes}},
	isbn = {978-1-4503-2373-4},
	url = {http://doi.acm.org/10.1145/2517208.2517226},
	doi = {10.1145/2517208.2517226},
	abstract = {Software repositories contain a vast wealth of information about software development. Mining these repositories has proven useful for detecting patterns in software development, testing hypotheses for new software engineering approaches, etc. Specifically, mining source code has yielded significant insights into software development artifacts and processes. Unfortunately, mining source code at a large-scale remains a difficult task. Previous approaches had to either limit the scope of the projects studied, limit the scope of the mining task to be more coarse-grained, or sacrifice studying the history of the code due to both human and computational scalability issues. In this paper we address the substantial challenges of mining source code: a) at a very large scale; b) at a fine-grained level of detail; and c) with full history information. To address these challenges, we present domain-specific language features for source code mining. Our language features are inspired by object-oriented visitors and provide a default depth-first traversal strategy along with two expressions for defining custom traversals. We provide an implementation of these features in the Boa infrastructure for software repository mining and describe a code generation strategy into Java code. To show the usability of our domain-specific language features, we reproduced over 40 source code mining tasks from two large-scale previous studies in just 2 person-weeks. The resulting code for these tasks show between 2.0x--4.8x reduction in code size. Finally we perform a small controlled experiment to gain insights into how easily mining tasks written using our language features can be understood, with no prior training. We show a substantial number of tasks (77\%) were understood by study participants, in about 3 minutes per task.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Generative} {Programming}: {Concepts} \& {Experiences}},
	publisher = {ACM},
	author = {Dyer, Robert and Rajan, Hridesh and Nguyen, Tien N.},
	year = {2013},
	keywords = {boa, source code mining, visitor pattern},
	pages = {23--32},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/2SY4FFZ5/Dyer et al. - 2013 - Declarative Visitors to Ease Fine-grained Source C.pdf:application/pdf}
}

@inproceedings{gousios_ghtorent_2013,
	address = {Piscataway, NJ, USA},
	series = {{MSR} '13},
	title = {The {GHTorent} {Dataset} and {Tool} {Suite}},
	isbn = {978-1-4673-2936-1},
	url = {http://dl.acm.org/citation.cfm?id=2487085.2487132},
	abstract = {During the last few years, GitHub has emerged as a popular project hosting, mirroring and collaboration platform. GitHub provides an extensive REST API, which enables researchers to retrieve high-quality, interconnected data. The GHTorent project has been collecting data for all public projects available on Github for more than a year. In this paper, we present the dataset details and construction process and outline the challenges and research opportunities emerging from it.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 10th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {IEEE Press},
	author = {Gousios, Georgios},
	year = {2013},
	pages = {233--236},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/H84M3ICU/Gousios - 2013 - The GHTorent Dataset and Tool Suite.pdf:application/pdf}
}

@inproceedings{mohamedin_bytestm:_2013,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{ByteSTM}: {Virtual} {Machine}-{Level} {Java} {Software} {Transactional} {Memory}},
	isbn = {978-3-642-38492-9 978-3-642-38493-6},
	shorttitle = {{ByteSTM}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-38493-6_12},
	doi = {10.1007/978-3-642-38493-6_12},
	abstract = {We present ByteSTM, a virtual machine-level Java STM implementation that is built by extending the Jikes RVM. We modify Jikes RVM{\textquoteright}s optimizing compiler to transparently support implicit transactions. Being implemented at the VM-level, it accesses memory directly, avoids Java garbage collection overhead by manually managing memory for transactional metadata, and provides pluggable support for implementing different STM algorithms to the VM. Our experimental studies reveal throughput improvement over other non-VM STMs by 6{\textendash}70\% on micro-benchmarks and by 7{\textendash}60\% on macro-benchmarks.},
	language = {en},
	urldate = {2017-11-11},
	booktitle = {Coordination {Models} and {Languages}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Mohamedin, Mohamed and Ravindran, Binoy and Palmieri, Roberto},
	month = jun,
	year = {2013},
	pages = {166--180},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/BP7RVPQA/Mohamedin et al. - 2013 - ByteSTM Virtual Machine-Level Java Software Trans.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/VRHBRWK9/10.html:text/html}
}

@inproceedings{raemaekers_maven_2013,
	title = {The {Maven} repository dataset of metrics, changes, and dependencies},
	doi = {10.1109/MSR.2013.6624031},
	abstract = {We present the Maven Dependency Dataset (MDD), containing metrics, changes and dependencies of 148,253 jar files. Metrics and changes have been calculated at the level of individual methods, classes and packages of multiple library versions. A complete call graph is also presented which includes call, inheritance, containment and historical relationships between all units of the entire repository. In this paper, we describe our dataset and the methodology used to obtain it. We present different conceptual views of MDD and we also describe limitations and data quality issues that researchers using this data should be aware of.},
	booktitle = {2013 10th {Working} {Conference} on {Mining} {Software} {Repositories} ({MSR})},
	author = {Raemaekers, S. and Deursen, A. van and Visser, J.},
	month = may,
	year = {2013},
	keywords = {Java, Data mining, Libraries, software libraries, data mining, Software, complete call graph, data quality issues, Dataset, Indexes, jar file changes, jar file dependencies, jar file metrics, library version packages, Maven repository, Maven repository dataset, MDD, Measurement, software metrics, software packages, Supercomputers},
	pages = {221--224},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/G84GZZZ7/6624031.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/6IQXLTHP/Raemaekers et al. - 2013 - The Maven repository dataset of metrics, changes, .pdf:application/pdf}
}

@inproceedings{marek_disl:_2012,
	address = {New York, NY, USA},
	series = {{DSAL} '12},
	title = {{DiSL}: {An} {Extensible} {Language} for {Efficient} and {Comprehensive} {Dynamic} {Program} {Analysis}},
	isbn = {978-1-4503-1128-1},
	shorttitle = {{DiSL}},
	url = {http://doi.acm.org/10.1145/2162037.2162046},
	doi = {10.1145/2162037.2162046},
	abstract = {Dynamic program analysis tools support numerous software engineering tasks, including profiling, debugging, and reverse engineering. Prevailing techniques for building dynamic analysis tools are based on low-level abstractions that make tool development tedious, error-prone, and expensive. To simplify the development of dynamic analysis tools, some researchers promoted the use of aspect-oriented programming (AOP). However, as mainstream AOP languages have not been designed to meet the requirements of dynamic analysis, the success of using AOP in this context remains limited. For example, in AspectJ, join points that are important for dynamic program analysis (e.g., the execution of bytecodes or basic blocks of code) are missing, access to reflective dynamic join{\textasciitilde}point information is expensive, data passing between woven advice in local variables is not supported, and the mixing of low-level bytecode instrumentation and high-level AOP code is not foreseen. In this talk, we present DiSL [1], a new domain-specific aspect language for bytecode instrumentation. DiSL uses Java annotation syntax such that standard Java compilers can be used for compiling DiSL code. The language features an open join point model, novel constructs inspired by weave-time evaluation of conditional join{\textasciitilde}points and by staged execution, and access to custom static and dynamic context information. Moreover, the DiSL weaver guarantees complete bytecode coverage. We have implemented several dynamic analysis tools in DiSL, including profilers for the inter- and intra-procedural control flow, debuggers, dynamic metrics collectors integrated in the Eclipse IDE to augment the static source views with dynamic information, and tools for workload characterization. These tools are concise and perform equally well as implementations using low-level techniques. DiSL has also been conceived as an intermediate language for future domain-specific analysis languages, as well as for AOP languages.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {Seventh} {Workshop} on {Domain}-{Specific} {Aspect} {Languages}},
	publisher = {ACM},
	author = {Marek, Luk{\'a}{\v s} and Zheng, Yudi and Ansaloni, Danilo and Binder, Walter and Qi, Zhengwei and Tuma, Petr},
	year = {2012},
	keywords = {bytecode instrumentation, aspect-oriented programming, JVM, dynamic program analysis},
	pages = {27--28},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/SNUW3RAU/Marek et al. - 2012 - DiSL An Extensible Language for Efficient and Com.pdf:application/pdf}
}

@article{pukall_javadaptor-flexible_2013,
	title = {{JavAdaptor}-{Flexible} {Runtime} {Updates} of {Java} {Applications}},
	volume = {43},
	issn = {0038-0644},
	url = {http://dx.doi.org/10.1002/spe.2107},
	doi = {10.1002/spe.2107},
	abstract = {Software is changed frequently during its life cycle. New requirements come, and bugs must be fixed. To update an application, it usually must be stopped, patched, and restarted. This causes time periods of unavailability, which is always a problem for highly available applications. Even for the development of complex applications, restarts to test new program parts can be time consuming and annoying. Thus, we aim at dynamic software updates to update programs at runtime. There is a large body of research on dynamic software updates, but so far, existing approaches have shortcomings either in terms of flexibility or performance. In addition, some of them depend on specific runtime environments and dictate the program's architecture. We present JavAdaptor, the first runtime update approach based on Java that a offers flexible dynamic software updates, b is platform independent, c introduces only minimal performance overhead, and d does not dictate the program architecture. JavAdaptor combines schema changing class replacements by class renaming and caller updates with Java HotSwap using containers and proxies. It runs on top of all major standard Java virtual machines. We evaluate our approach's applicability and performance in non-trivial case studies and compare it with existing dynamic software update approaches. Copyright {\textcopyright} 2012 John Wiley \& Sons, Ltd.},
	number = {2},
	urldate = {2017-11-11},
	journal = {Softw. Pract. Exper.},
	author = {Pukall, Mario and K{\"a}stner, Christian and Cazzola, Walter and G{\"o}tz, Sebastian and Grebhahn, Alexander and Schr{\"o}ter, Reimar and Saake, Gunter},
	month = feb,
	year = {2013},
	keywords = {dynamic software updates, program evolution, state migration: tool support},
	pages = {153--185},
	file = {Pukall_et_al-2013-Software__Practice_and_Experience.pdf:/Volumes/Data/work/zotero/storage/73H4BFZ6/Pukall_et_al-2013-Software__Practice_and_Experience.pdf:application/pdf}
}

@article{callau_how_2013,
	title = {How (and why) developers use the dynamic features of programming languages: the case of smalltalk},
	volume = {18},
	issn = {1382-3256, 1573-7616},
	shorttitle = {How (and why) developers use the dynamic features of programming languages},
	url = {https://link.springer.com/article/10.1007/s10664-012-9203-2},
	doi = {10.1007/s10664-012-9203-2},
	abstract = {The dynamic and reflective features of programming languages are powerful constructs that programmers often mention as extremely useful. However, the ability to modify a program at runtime can be both a boon{\textemdash}in terms of flexibility{\textemdash}, and a curse{\textemdash}in terms of tool support. For instance, usage of these features hampers the design of type systems, the accuracy of static analysis techniques, or the introduction of optimizations by compilers. In this paper, we perform an empirical study of a large Smalltalk codebase{\textemdash}often regarded as the poster-child in terms of availability of these features{\textemdash}, in order to assess how much these features are actually used in practice, whether some are used more than others, and in which kinds of projects. In addition, we performed a qualitative analysis of a representative sample of usages of dynamic features in order to uncover (1) the principal reasons that drive people to use dynamic features, and (2) whether and how these dynamic feature usages can be removed or converted to safer usages. These results are useful to make informed decisions about which features to consider when designing language extensions or tool support.},
	language = {en},
	number = {6},
	urldate = {2017-11-11},
	journal = {Empirical Software Engineering},
	author = {Calla{\'u}, Oscar and Robbes, Romain and Tanter, {\'E}ric and R{\"o}thlisberger, David},
	month = dec,
	year = {2013},
	pages = {1156--1194},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/ZZ2WU8Y3/Calla{\'u} et al. - 2013 - How (and why) developers use the dynamic features .pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/HPIRJ2GK/10.html:text/html}
}

@inproceedings{dyer_boa:_2013,
	title = {Boa: {A} language and infrastructure for analyzing ultra-large-scale software repositories},
	shorttitle = {Boa},
	doi = {10.1109/ICSE.2013.6606588},
	abstract = {In today's software-centric world, ultra-large-scale software repositories, e.g. SourceForge (350,000+ projects), GitHub (250,000+ projects), and Google Code (250,000+ projects) are the new library of Alexandria. They contain an enormous corpus of software and information about software. Scientists and engineers alike are interested in analyzing this wealth of information both for curiosity as well as for testing important hypotheses. However, systematic extraction of relevant data from these repositories and analysis of such data for testing hypotheses is hard, and best left for mining software repository (MSR) experts! The goal of Boa, a domain-specific language and infrastructure described here, is to ease testing MSR-related hypotheses. We have implemented Boa and provide a web-based interface to Boa's infrastructure. Our evaluation demonstrates that Boa substantially reduces programming efforts, thus lowering the barrier to entry. We also see drastic improvements in scalability. Last but not least, reproducing an experiment conducted using Boa is just a matter of re-running small Boa programs provided by previous researchers.},
	booktitle = {2013 35th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Dyer, R. and Nguyen, H. A. and Rajan, H. and Nguyen, T. N.},
	month = may,
	year = {2013},
	keywords = {Java, Protocols, Runtime, Data mining, Libraries, Software, software packages, Alexandria new library, Boa, Boa infrastructure, domain specific language, ease of use, GitHub, Google code, Internet, lower barrier to entry, mining, mining software repository, MSR related hypotheses, repository, reproducible, scalable, software, software centric world, SourceForge, systematic extraction, ultra-large-scale software repositories analysis},
	pages = {422--431},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/DASN4FQY/6606588.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/27Z4QYMP/Dyer et al. - 2013 - Boa A language and infrastructure for analyzing u.pdf:application/pdf}
}

@article{parnin_adoption_2013,
	title = {Adoption and use of {Java} generics},
	volume = {18},
	issn = {1382-3256, 1573-7616},
	url = {https://link.springer.com/article/10.1007/s10664-012-9236-6},
	doi = {10.1007/s10664-012-9236-6},
	abstract = {Support for generic programming was added to the Java language in 2004, representing perhaps the most significant change to one of the most widely used programming languages today. Researchers and language designers anticipated this addition would relieve many long-standing problems plaguing developers, but surprisingly, no one has yet measured how generics have been adopted and used in practice. In this paper, we report on the first empirical investigation into how Java generics have been integrated into open source software by automatically mining the history of 40 popular open source Java programs, traversing more than 650 million lines of code in the process. We evaluate five hypotheses and research questions about how Java developers use generics. For example, our results suggest that generics sometimes reduce the number of type casts and that generics are usually adopted by a single champion in a project, rather than all committers. We also offer insights into why some features may be adopted sooner and others features may be held back.},
	language = {en},
	number = {6},
	urldate = {2017-11-11},
	journal = {Empirical Software Engineering},
	author = {Parnin, Chris and Bird, Christian and Murphy-Hill, Emerson},
	month = dec,
	year = {2013},
	pages = {1047--1089},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/3QIDK2PH/Parnin et al. - 2013 - Adoption and use of Java generics.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/J7SWD45J/10.html:text/html}
}

@article{hall_kardashian_2014,
	title = {The {Kardashian} index: a measure of discrepant social media profile for scientists},
	volume = {15},
	issn = {1474-760X},
	shorttitle = {The {Kardashian} index},
	url = {https://doi.org/10.1186/s13059-014-0424-0},
	doi = {10.1186/s13059-014-0424-0},
	abstract = {In the era of social media there are now many different ways that a scientist can build their public profile; the publication of high-quality scientific papers being just one. While social media is a valuable tool for outreach and the sharing of ideas, there is a danger that this form of communication is gaining too high a value and that we are losing sight of key metrics of scientific value, such as citation indices. To help quantify this, I propose the {\textquoteleft}Kardashian Index{\textquoteright}, a measure of discrepancy between a scientist{\textquoteright}s social media profile and publication record based on the direct comparison of numbers of citations and Twitter followers.},
	urldate = {2017-11-11},
	journal = {Genome Biology},
	author = {Hall, Neil},
	month = jul,
	year = {2014},
	pages = {424},
	annote = {Pages 424 in PDF},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/SWBETZRL/Hall - 2014 - The Kardashian index a measure of discrepant soci.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/S8BEALCR/s13059-014-0424-0.html:text/html}
}

@inproceedings{stefik_what_2014,
	address = {New York, NY, USA},
	series = {{ICPC} 2014},
	title = {What is the {Foundation} of {Evidence} of {Human} {Factors} {Decisions} in {Language} {Design}? {An} {Empirical} {Study} on {Programming} {Language} {Workshops}},
	isbn = {978-1-4503-2879-1},
	shorttitle = {What is the {Foundation} of {Evidence} of {Human} {Factors} {Decisions} in {Language} {Design}?},
	url = {http://doi.acm.org/10.1145/2597008.2597154},
	doi = {10.1145/2597008.2597154},
	abstract = {In recent years, the programming language design community has engaged in rigorous debate on the role of empirical evidence in the design of general purpose programming languages. Some scholars contend that the language community has failed to embrace a form of evidence that is non-controversial in other disciplines (e.g., medicine, biology, psychology, sociology, physics, chemistry), while others argue that a science of language design is unrealistic. While the discussion will likely persist for some time, we begin here a systematic evaluation of the use of empirical evidence with human users, documenting, paper-by-paper, the evidence provided for human factors decisions, beginning with 359 papers from the workshops PPIG, Plateau, and ESP. This preliminary work provides the following contributions: an analysis of the 1) overall quantity and quality of empirical evidence used in the workshops, and of the 2) overall significant challenges to reliably coding academic papers. We hope that, once complete, this long-term research project will serve as a practical catalog designers can use when evaluating the impact of a language feature on human users.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 22Nd {International} {Conference} on {Program} {Comprehension}},
	publisher = {ACM},
	author = {Stefik, Andreas and Hanenberg, Stefan and McKenney, Mark and Andrews, Anneliese and Yellanki, Srinivas Kalyan and Siebert, Susanna},
	year = {2014},
	keywords = {Empirical Evidence, Meta-analysis, The Programming Language Wars},
	pages = {223--231},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/4KUAXMTV/Stefik et al. - 2014 - What is the Foundation of Evidence of Human Factor.pdf:application/pdf}
}

@inproceedings{marek_shadowvm:_2013,
	address = {New York, NY, USA},
	series = {{GPCE} '13},
	title = {{ShadowVM}: {Robust} and {Comprehensive} {Dynamic} {Program} {Analysis} for the {Java} {Platform}},
	isbn = {978-1-4503-2373-4},
	shorttitle = {{ShadowVM}},
	url = {http://doi.acm.org/10.1145/2517208.2517219},
	doi = {10.1145/2517208.2517219},
	abstract = {Dynamic analysis tools are often implemented using instrumentation, particularly on managed runtimes including the Java Virtual Machine (JVM). Performing instrumentation robustly is especially complex on such runtimes: existing frameworks offer limited coverage and poor isolation, while previous work has shown that apparently innocuous instrumentation can cause deadlocks or crashes in the observed application. This paper describes ShadowVM, a system for instrumentation-based dynamic analyses on the JVM which combines a number of techniques to greatly improve both isolation and coverage. These centre on the offload of analysis to a separate process; we believe our design is the first system to enable genuinely full bytecode coverage on the JVM. We describe a working implementation, and use a case study to demonstrate its improved coverage and to evaluate its runtime overhead.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 12th {International} {Conference} on {Generative} {Programming}: {Concepts} \& {Experiences}},
	publisher = {ACM},
	author = {Marek, Luk{\'a}{\v s} and Kell, Stephen and Zheng, Yudi and Bulej, Lubom{\'i}r and Binder, Walter and T{\r u}ma, Petr and Ansaloni, Danilo and Sarimbekov, Aibek and Sewe, Andreas},
	year = {2013},
	keywords = {dynamic analysis, instrumentation, jvm},
	pages = {105--114},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/CWFCG7TE/Marek et al. - 2013 - ShadowVM Robust and Comprehensive Dynamic Program.pdf:application/pdf}
}

@inproceedings{petersen_empirical_2014,
	address = {New York, NY, USA},
	series = {{ICPC} 2014},
	title = {An {Empirical} {Comparison} of {Static} and {Dynamic} {Type} {Systems} on {API} {Usage} in the {Presence} of an {IDE}: {Java} vs. {Groovy} with {Eclipse}},
	isbn = {978-1-4503-2879-1},
	shorttitle = {An {Empirical} {Comparison} of {Static} and {Dynamic} {Type} {Systems} on {API} {Usage} in the {Presence} of an {IDE}},
	url = {http://doi.acm.org/10.1145/2597008.2597152},
	doi = {10.1145/2597008.2597152},
	abstract = {Several studies have concluded that static type systems offer an advantage over dynamic type systems for programming tasks involving the discovery of a new API. However, these studies did not take into account modern IDE features; the advanced navigation and code completion techniques available in modern IDEs could drastically alter their conclusions. This study describes an experiment that compares the usage of an unknown API using Java and Groovy using the IDE Eclipse. It turns out that the previous finding that static type systems improve the usability of an unknown API still holds, even in the presence of a modern IDE.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 22Nd {International} {Conference} on {Program} {Comprehension}},
	publisher = {ACM},
	author = {Petersen, Pujan and Hanenberg, Stefan and Robbes, Romain},
	year = {2014},
	keywords = {empirical research, type systems, programming languages},
	pages = {212--222},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/E2NHYDB3/Petersen et al. - 2014 - An Empirical Comparison of Static and Dynamic Type.pdf:application/pdf}
}

@inproceedings{dyer_mining_2014,
	address = {New York, NY, USA},
	series = {{ICSE} 2014},
	title = {Mining {Billions} of {AST} {Nodes} to {Study} {Actual} and {Potential} {Usage} of {Java} {Language} {Features}},
	isbn = {978-1-4503-2756-5},
	url = {http://doi.acm.org/10.1145/2568225.2568295},
	doi = {10.1145/2568225.2568295},
	abstract = {Programming languages evolve over time, adding additional language features to simplify common tasks and make the language easier to use. For example, the Java Language Specification has four editions and is currently drafting a fifth. While the addition of language features is driven by an assumed need by the community (often with direct requests for such features), there is little empirical evidence demonstrating how these new features are adopted by developers once released. In this paper, we analyze over 31k open-source Java projects representing over 9 million Java files, which when parsed contain over 18 billion AST nodes. We analyze this corpus to find uses of new Java language features over time. Our study gives interesting insights, such as: there are millions of places features could potentially be used but weren't; developers convert existing code to use new features; and we found thousands of instances of potential resource handling bugs.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Dyer, Robert and Rajan, Hridesh and Nguyen, Hoan Anh and Nguyen, Tien N.},
	year = {2014},
	keywords = {Java, empirical study, language feature use, software mining},
	pages = {779--790},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/BTC3S8VE/Dyer et al. - 2014 - Mining Billions of AST Nodes to Study Actual and P.pdf:application/pdf}
}

@inproceedings{gorla_checking_2014,
	address = {New York, NY, USA},
	series = {{ICSE} 2014},
	title = {Checking {App} {Behavior} {Against} {App} {Descriptions}},
	isbn = {978-1-4503-2756-5},
	url = {http://doi.acm.org/10.1145/2568225.2568276},
	doi = {10.1145/2568225.2568276},
	abstract = {How do we know a program does what it claims to do? After clustering Android apps by their description topics, we identify outliers in each cluster with respect to their API usage. A "weather" app that sends messages thus becomes an anomaly; likewise, a "messaging" app would typically not be expected to access the current location. Applied on a set of 22,500+ Android applications, our CHABADA prototype identified several anomalies; additionally, it flagged 56\% of novel malware as such, without requiring any known malware patterns.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 36th {International} {Conference} on {Software} {Engineering}},
	publisher = {ACM},
	author = {Gorla, Alessandra and Tavecchia, Ilaria and Gross, Florian and Zeller, Andreas},
	year = {2014},
	keywords = {Android, clustering, description analysis, malware detection},
	pages = {1025--1035},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/N63DCL4D/Gorla et al. - 2014 - Checking App Behavior Against App Descriptions.pdf:application/pdf}
}

@inproceedings{gousios_lean_2014,
	address = {New York, NY, USA},
	series = {{MSR} 2014},
	title = {Lean {GHTorrent}: {GitHub} {Data} on {Demand}},
	isbn = {978-1-4503-2863-0},
	shorttitle = {Lean {GHTorrent}},
	url = {http://doi.acm.org/10.1145/2597073.2597126},
	doi = {10.1145/2597073.2597126},
	abstract = {In recent years, GitHub has become the largest code host in the world, with more than 5M developers collaborating across 10M repositories. Numerous popular open source projects (such as Ruby on Rails, Homebrew, Bootstrap, Django or jQuery) have chosen GitHub as their host and have migrated their code base to it. GitHub offers a tremendous research potential. For instance, it is a flagship for current open source development, a place for developers to showcase their expertise to peers or potential recruiters, and the platform where social coding features or pull requests emerged. However, GitHub data is, to date, largely underexplored. To facilitate studies of GitHub, we have created GHTorrent, a scalable, queriable, offline mirror of the data offered through the GitHub REST API. In this paper we present a novel feature of GHTorrent designed to offer customisable data dumps on demand. The new GHTorrent data-on-demand service offers users the possibility to request via a web form up-to-date GHTorrent data dumps for any collection of GitHub repositories. We hope that by offering customisable GHTorrent data dumps we will not only lower the "barrier for entry" even further for researchers interested in mining GitHub data (thus encourage researchers to intensify their mining efforts), but also enhance the replicability of GitHub studies (since a snapshot of the data on which the results were obtained can now easily accompany each study).},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 11th {Working} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Gousios, Georgios and Vasilescu, Bogdan and Serebrenik, Alexander and Zaidman, Andy},
	year = {2014},
	keywords = {GitHub, data on demand, dataset},
	pages = {384--387},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/HP67IK6T/Gousios et al. - 2014 - Lean GHTorrent GitHub Data on Demand.pdf:application/pdf}
}

@inproceedings{ponzanelli_stormed:_2015,
	title = {{StORMeD}: {Stack} {Overflow} {Ready} {Made} {Data}},
	shorttitle = {{StORMeD}},
	doi = {10.1109/MSR.2015.67},
	abstract = {Stack Overflow is the de facto Question and Answer (Q\&A) website for developers, and it has been used in many approaches by software engineering researchers to mine useful data. However, the contents of a Stack Overflow discussion are inherently heterogeneous, mixing natural language, source code, stack traces and configuration files in XML or JSON format. We constructed a full island grammar capable of modeling the set of 700,000 Stack Overflow discussions talking about Java, building a heterogeneous abstract syntax tree (H-AST) of each post (question, answer or comment) in a discussion. The resulting dataset models every Stack Overflow discussion, providing a full H-AST for each type of structured fragment (i.e., JSON, XML, Java, Stack traces), and complementing this information with a set of basic meta-information like term frequency to enable natural language analyses. Our dataset allows the end-user to perform combined analyses of the Stack Overflow by visiting the H-AST of a discussion.},
	booktitle = {2015 {IEEE}/{ACM} 12th {Working} {Conference} on {Mining} {Software} {Repositories}},
	author = {Ponzanelli, L. and Mocci, A. and Lanza, M.},
	month = may,
	year = {2015},
	keywords = {Java, Data mining, source code, Software, software engineering, Grammar, island parsing, Natural languages, configuration files, Data models, h-ast, heterogeneous abstract syntax tree, JSON format, natural language, question and answer Website, question answering (information retrieval), software engineering researchers, stack overflow ready made data, stack traces, StORMeD, term frequency, unstructured data, Web sites, XML},
	pages = {474--477},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/ZAFQEIGF/7180121.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/GSDBBEKF/Ponzanelli et al. - 2015 - StORMeD Stack Overflow Ready Made Data.pdf:application/pdf}
}

@inproceedings{sawant_dataset_2015,
	title = {A {Dataset} for {API} {Usage}},
	doi = {10.1109/MSR.2015.75},
	abstract = {An Application Programming Interface (API) provides a specific set of functionalities to a developer. The main aim of an API is to encourage the reuse of already existing functionality. There has been some work done into API popularity trends, API evolution and API usage. For all the aforementioned research avenues there has been a need to mine the usage of an API in order to perform any kind of analysis. Each one of the approaches that has been employed in the past involved a certain degree of inaccuracy as there was no type check that takes place. We introduce an approach that takes type information into account while mining API method invocations and annotation usages. This approach accurately makes a connection between a method invocation and the class of the API to which the method belongs to. We try collecting as many usages of an API as possible, this is achieved by targeting projects hosted on GitHub. Additionally, we look at the history of every project to collect the usage of an API from earliest version onwards. By making such a large and rich dataset public, we hope to stimulate some more research in the field of APIs with the aid of accurate API usage samples.},
	booktitle = {2015 {IEEE}/{ACM} 12th {Working} {Conference} on {Mining} {Software} {Repositories}},
	author = {Sawant, A. A. and Bacchelli, A.},
	month = may,
	year = {2015},
	keywords = {Java, Data mining, Libraries, History, application program interfaces, Software, GitHub, dataset, API evolution, API method annotation usage mining, API method invocationusage mining, API popularity trends, API usage, application programming interface, Databases, functionality reuse, Market research, public dataset, software reusability},
	pages = {506--509},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/VSFRDBNM/7180129.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/8FXAQWVX/Sawant and Bacchelli - 2015 - A Dataset for API Usage.pdf:application/pdf}
}

@article{livshits_defense_2015,
	title = {In {Defense} of {Soundiness}: {A} {Manifesto}},
	volume = {58},
	issn = {0001-0782},
	shorttitle = {In {Defense} of {Soundiness}},
	url = {http://doi.acm.org/10.1145/2644805},
	doi = {10.1145/2644805},
	abstract = {Soundy is the new sound.},
	number = {2},
	urldate = {2017-11-11},
	journal = {Commun. ACM},
	author = {Livshits, Benjamin and Sridharan, Manu and Smaragdakis, Yannis and Lhot{\'a}k, Ond{\v r}ej and Amaral, J. Nelson and Chang, Bor-Yuh Evan and Guyer, Samuel Z. and Khedker, Uday P. and M{\o}ller, Anders and Vardoulakis, Dimitrios},
	month = jan,
	year = {2015},
	pages = {44--46},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/K2DFZ9IK/Livshits et al. - 2015 - In Defense of Soundiness A Manifesto.pdf:application/pdf}
}

@inproceedings{stefanescu_semantics-based_2016,
	address = {New York, NY, USA},
	series = {{OOPSLA} 2016},
	title = {Semantics-based {Program} {Verifiers} for {All} {Languages}},
	isbn = {978-1-4503-4444-9},
	url = {http://doi.acm.org/10.1145/2983990.2984027},
	doi = {10.1145/2983990.2984027},
	abstract = {We present a language-independent verification framework that can be instantiated with an operational semantics to automatically generate a program verifier. The framework treats both the operational semantics and the program correctness specifications as reachability rules between matching logic patterns, and uses the sound and relatively complete reachability logic proof system to prove the specifications using the semantics. We instantiate the framework with the semantics of one academic language, KernelC, as well as with three recent semantics of real-world languages, C, Java, and JavaScript, developed independently of our verification infrastructure. We evaluate our approach empirically and show that the generated program verifiers can check automatically the full functional correctness of challenging heap-manipulating programs implementing operations on list and tree data structures, like AVL trees. This is the first approach that can turn the operational semantics of real-world languages into correct-by-construction automatic verifiers.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2016 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Stef{\u a}nescu, Andrei and Park, Daejun and Yuwen, Shijiao and Li, Yilong and Ro{\c s}u, Grigore},
	year = {2016},
	keywords = {K framework, matching logic, reachability logic},
	pages = {74--91},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/EHPB7J75/Stef{\u a}nescu et al. - 2016 - Semantics-based Program Verifiers for All Language.pdf:application/pdf}
}

@inproceedings{nakshatri_analysis_2016,
	address = {New York, NY, USA},
	series = {{MSR} '16},
	title = {Analysis of {Exception} {Handling} {Patterns} in {Java} {Projects}: {An} {Empirical} {Study}},
	isbn = {978-1-4503-4186-8},
	shorttitle = {Analysis of {Exception} {Handling} {Patterns} in {Java} {Projects}},
	url = {http://doi.acm.org/10.1145/2901739.2903499},
	doi = {10.1145/2901739.2903499},
	abstract = {Exception handling is a powerful tool provided by many programming languages to help developers deal with unforeseen conditions. Java is one of the few programming languages to enforce an additional compilation check on certain subclasses of the Exception class through checked exceptions. As part of this study, empirical data was extracted from software projects developed in Java. The intent is to explore how developers respond to checked exceptions and identify common patterns used by them to deal with exceptions, checked or otherwise. Bloch's book - "Effective Java" [1] was used as reference for best practices in exception handling - these recommendations were compared against results from the empirical data. Results of this study indicate that most programmers ignore checked exceptions and leave them unnoticed. Additionally, it is observed that classes higher in the exception class hierarchy are more frequently used as compared to specific exception subclasses.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Nakshatri, Suman and Hegde, Maithri and Thandra, Sahithi},
	year = {2016},
	keywords = {Boa, best practices, Github, Java exception handling},
	pages = {500--503},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/5IMZFABG/Nakshatri et al. - 2016 - Analysis of Exception Handling Patterns in Java Pr.pdf:application/pdf}
}

@article{avgustinov_ql:_2016,
	title = {{QL}: {Object}-oriented {Queries} on {Relational} {Data}.},
	shorttitle = {{QL}},
	doi = {10.4230/LIPIcs.ECOOP.2016.2},
	author = {Avgustinov, Pavel},
	year = {2016},
	pages = {2:1--2:25},
	file = {dblp\: record conf/ecoop/AvgustinovMJS16:/Volumes/Data/work/zotero/storage/ZS6QCMBF/AvgustinovMJS16.html:text/html}
}

@inproceedings{asaduzzaman_how_2016,
	address = {New York, NY, USA},
	series = {{MSR} '16},
	title = {How {Developers} {Use} {Exception} {Handling} in {Java}?},
	isbn = {978-1-4503-4186-8},
	url = {http://doi.acm.org/10.1145/2901739.2903500},
	doi = {10.1145/2901739.2903500},
	abstract = {Exception handling is a technique that addresses exceptional conditions in applications, allowing the normal flow of execution to continue in the event of an exception and/or to report on such events. Although exception handling techniques, features and bad coding practices have been discussed both in developer communities and in the literature, there is a marked lack of empirical evidence on how developers use exception handling in practice. In this paper we use the Boa language and infrastructure to analyze 274k open source Java projects in GitHub to discover how developers use exception handling. We not only consider various exception handling features but also explore bad coding practices and their relation to the experience of developers. Our results provide some interesting insights. For example, we found that bad exception handling coding practices are common in open source Java projects and regardless of experience all developers use bad exception handling coding practices.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Asaduzzaman, Muhammad and Ahasanuzzaman, Muhammad and Roy, Chanchal K. and Schneider, Kevin A.},
	year = {2016},
	keywords = {Java, source code mining, exception, language feature},
	pages = {516--519},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/JD8WHSL5/Asaduzzaman et al. - 2016 - How Developers Use Exception Handling in Java.pdf:application/pdf}
}

@inproceedings{kery_examining_2016,
	address = {New York, NY, USA},
	series = {{MSR} '16},
	title = {Examining {Programmer} {Practices} for {Locally} {Handling} {Exceptions}},
	isbn = {978-1-4503-4186-8},
	url = {http://doi.acm.org/10.1145/2901739.2903497},
	doi = {10.1145/2901739.2903497},
	abstract = {Many have argued that the current try/catch mechanism for handling exceptions in Java is flawed. A major complaint is that programmers often write minimal and low quality handlers. We used the Boa tool to examine a large number of Java projects on GitHub to provide empirical evidence about how programmers currently deal with exceptions. We found that programmers handle exceptions locally in catch blocks much of the time, rather than propagating by throwing an Exception. Programmers make heavy use of actions like Log, Print, Return, or Throw in catch blocks, and also frequently copy code between handlers. We found bad practices like empty catch blocks or catching Exception are indeed widespread. We discuss evidence that programmers may misjudge risk when catching Exception, and face a tension between handlers that directly address local program statement failure and handlers that consider the program-wide implications of an exception. Some of these issues might be addressed by future tools which autocomplete more complete handlers.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Kery, Mary Beth and Le Goues, Claire and Myers, Brad A.},
	year = {2016},
	keywords = {Boa, GitHub, error handlers, Java exceptions},
	pages = {484--487},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/2H8HKBJF/Kery et al. - 2016 - Examining Programmer Practices for Locally Handlin.pdf:application/pdf}
}

@article{hafiz_growing_2016,
	title = {Growing a language: {An} empirical study on how (and why) developers use some recently-introduced and/or recently-evolving {JavaScript} features},
	volume = {121},
	issn = {0164-1212},
	shorttitle = {Growing a language},
	url = {http://www.sciencedirect.com/science/article/pii/S0164121216300309},
	doi = {10.1016/j.jss.2016.04.045},
	abstract = {We describe an empirical study to understand how different language features in JavaScript are used by developers, with the goal of using this information to assist future extensions of JavaScript. We inspected more than one million unique scripts (over 80 MLOC) from various sources: JavaScript programs in the wild collected by a spider, (supposedly) better JavaScript programs collected from the top 100 URLs from the Alexa list, JavaScript programs with new language features used in Firefox Add-ons, widely used JavaScript libraries, and Node.js applications. Our corpus is larger and more diversified than those in prior studies. We also performed two explanatory studies to understand the reasons behind some of the language feature choices. One study was conducted on 107 JavaScript developers; the other was conducted on 45 developers of Node.js applications. Our study shows that there is a widespread confusion about newly introduced JavaScript features, a continuing misuse of existing problematic features, and a surprising lack of adoption of object-oriented features. It also hints at why developers choose to use language features this way. This information is valuable to the language designers and the stakeholders, e.g., IDE and tool builders, all of whom are responsible for growing a language.},
	number = {Supplement C},
	urldate = {2017-11-11},
	journal = {Journal of Systems and Software},
	author = {Hafiz, Munawar and Hasan, Samir and King, Zachary and Wirfs-Brock, Allen},
	month = nov,
	year = {2016},
	keywords = {Empirical study, JavaScript, Language evolution},
	pages = {191--208},
	file = {ScienceDirect Snapshot:/Volumes/Data/work/zotero/storage/6TR47N8L/S0164121216300309.html:text/html}
}

@inproceedings{sena_understanding_2016,
	address = {New York, NY, USA},
	series = {{MSR} '16},
	title = {Understanding the {Exception} {Handling} {Strategies} of {Java} {Libraries}: {An} {Empirical} {Study}},
	isbn = {978-1-4503-4186-8},
	shorttitle = {Understanding the {Exception} {Handling} {Strategies} of {Java} {Libraries}},
	url = {http://doi.acm.org/10.1145/2901739.2901757},
	doi = {10.1145/2901739.2901757},
	abstract = {This paper presents an empirical study whose goal was to investigate the exception handling strategies adopted by Java libraries and their potential impact on the client applications. In this study, exception flow analysis was used in combination with manual inspections in order: (i) to characterize the exception handling strategies of existing Java libraries from the perspective of their users; and (ii) to identify exception handling anti-patterns. We extended an existing static analysis tool to reason about exception flows and handler actions of 656 Java libraries selected from 145 categories in the Maven Central Repository. The study findings suggest a current trend of a high number of undocumented API runtime exceptions (i.e., @throws in Javadoc) and Unintended Handler problem. Moreover, we could also identify a considerable number of occurrences of exception handling anti-patterns (e.g. Catch and Ignore). Finally, we have also analyzed 647 bug issues of the 7 most popular libraries and identified that 20.71\% of the reports are defects related to the problems of the exception strategies and anti-patterns identified in our study. The results of this study point to the need of tools to better understand and document the exception handling behavior of libraries.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Mining} {Software} {Repositories}},
	publisher = {ACM},
	author = {Sena, Dem{\'o}stenes and Coelho, Roberta and Kulesza, Uir{\'a} and Bonif{\'a}cio, Rodrigo},
	year = {2016},
	keywords = {software libraries, empirical study, exception flows analysis, exception handling, exception handling anti-patterns, static analysis tool},
	pages = {212--222},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/HSRBLDIX/Sena et al. - 2016 - Understanding the Exception Handling Strategies of.pdf:application/pdf}
}

@article{lopes_dejavu:_2017,
	title = {D{{\'e}J{\`a}Vu}: {A} {Map} of {Code} {Duplicates} on {GitHub}},
	volume = {1},
	issn = {2475-1421},
	shorttitle = {D{{\'e}J{\`a}Vu}},
	url = {http://doi.acm.org/10.1145/3133908},
	doi = {10.1145/3133908},
	abstract = {Previous studies have shown that there is a non-trivial amount of duplication in source code. This paper analyzes a corpus of 4.5 million non-fork projects hosted on GitHub representing over 428 million files written in Java, C++, Python, and JavaScript. We found that this corpus has a mere 85 million unique files. In other words, 70\% of the code on GitHub consists of clones of previously created files. There is considerable variation between language ecosystems. JavaScript has the highest rate of file duplication, only 6\% of the files are distinct. Java, on the other hand, has the least duplication, 60\% of files are distinct. Lastly, a project-level analysis shows that between 9\% and 31\% of the projects contain at least 80\% of files that can be found elsewhere. These rates of duplication have implications for systems built on open source software as well as for researchers interested in analyzing large code bases. As a concrete artifact of this study, we have created D{\'e}j{\`a}Vu, a publicly available map of code duplicates in GitHub repositories.},
	number = {OOPSLA},
	urldate = {2017-11-11},
	journal = {Proc. ACM Program. Lang.},
	author = {Lopes, Cristina V. and Maj, Petr and Martins, Pedro and Saini, Vaibhav and Yang, Di and Zitny, Jakub and Sajnani, Hitesh and Vitek, Jan},
	month = oct,
	year = {2017},
	keywords = {Clone Detection, Source Code Analysis},
	pages = {84:1--84:28},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/P84LN2ED/Lopes et al. - 2017 - D{\'e}J{\`a}Vu A Map of Code Duplicates on GitHub.pdf:application/pdf}
}

@inproceedings{harlin_impact_2017,
	title = {Impact of {Using} a {Static}-{Type} {System} in {Computer} {Programming}},
	doi = {10.1109/HASE.2017.17},
	abstract = {Static-type systems are a major topic in programming language research and the software industry because they should reduce the development time and increase the code quality. Additionally, they are predicted to decrease the number of defects in a code due to early error detection. However, only a few empirical experiments exist on the potential benefits of static-type systems in programming activities. This paper describes an experiment that tests whether static-type systems help developers create solutions for certain programming tasks. The results indicate that although the existence of a static-type system has no positive impact when subjects code a program from scratch, it does allow more errors in program debugging to be fixed.},
	booktitle = {2017 {IEEE} 18th {International} {Symposium} on {High} {Assurance} {Systems} {Engineering} ({HASE})},
	author = {Harlin, I. R. and Washizaki, H. and Fukazawa, Y.},
	month = jan,
	year = {2017},
	keywords = {Debugging, Computer languages, Programming, empirical study, Software, Encryption, Measurement uncertainty, program debugging, programming language, static-type systems},
	pages = {116--119},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/M5GFH7LE/7911881.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/2VQI6AB3/Harlin et al. - 2017 - Impact of Using a Static-Type System in Computer P.pdf:application/pdf}
}

@inproceedings{dilorenzo_incremental_2016,
	address = {New York, NY, USA},
	series = {{OOPSLA} 2016},
	title = {Incremental {Forest}: {A} {DSL} for {Efficiently} {Managing} {Filestores}},
	isbn = {978-1-4503-4444-9},
	shorttitle = {Incremental {Forest}},
	url = {http://doi.acm.org/10.1145/2983990.2984034},
	doi = {10.1145/2983990.2984034},
	abstract = {File systems are often used to store persistent application data, but manipulating file systems using standard APIs can be difficult for programmers. Forest is a domain-specific language that bridges the gap between the on-disk and in-memory representations of file system data. Given a high-level specification of the structure, contents, and properties of a collection of directories, files, and symbolic links, the Forest compiler generates tools for loading, storing, and validating that data. Unfortunately, the initial implementation of Forest offered few mechanisms for controlling cost{\^a}??e.g., the run-time system could load gigabytes of data, even if only a few bytes were needed. This paper introduces Incremental Forest (iForest), an extension to Forest with an explicit delay construct that programmers can use to precisely control costs. We describe the design of iForest using a series of running examples, present a formal semantics in a core calculus, and define a simple cost model that accurately characterizes the resources needed to use a given specification. We propose skins, which allow programmers to modify the delay structure of a specification in a compositional way, and develop a static type system for ensuring compatibility between specifications and skins. We prove the soundness and completeness of the type system and a variety of algebraic properties of skins. We describe an OCaml implementation and evaluate its performance on applications developed in collaboration with watershed hydrologists.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2016 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {DiLorenzo, Jonathan and Zhang, Richard and Menzies, Erin and Fisher, Kathleen and Foster, Nate},
	year = {2016},
	keywords = {ad hoc data, Data description languages, domain-specific languages, file systems, filestores, laziness},
	pages = {252--271},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/U2TGPEQE/DiLorenzo et al. - 2016 - Incremental Forest A DSL for Efficiently Managing.pdf:application/pdf}
}

@article{arnold_survey_2005,
	title = {A {Survey} of {Adaptive} {Optimization} in {Virtual} {Machines}},
	volume = {93},
	issn = {0018-9219},
	doi = {10.1109/JPROC.2004.840305},
	abstract = {Virtual machines face significant performance challenges beyond those confronted by traditional static optimizers. First, portable program representations and dynamic language features, such as dynamic class loading, force the deferral of most optimizations until runtime, inducing runtime optimization overhead. Second, modular program representations preclude many forms of whole-program interprocedural optimization. Third, virtual machines incur additional costs for runtime services such as security guarantees and automatic memory management. To address these challenges, vendors have invested considerable resources into adaptive optimization systems in production virtual machines. Today, mainstream virtual machine implementations include substantial infrastructure for online monitoring and profiling, runtime compilation, and feedback-directed optimization. As a result, adaptive optimization has begun to mature as a widespread production-level technology. This paper surveys the evolution and current state of adaptive optimization technology in virtual machines.},
	number = {2},
	journal = {Proceedings of the IEEE},
	author = {Arnold, M. and Fink, S. J. and Grove, D. and Hind, M. and Sweeney, P. F.},
	month = feb,
	year = {2005},
	keywords = {Runtime, virtual machines, optimisation, Adaptive optimization, adaptive optimization systems, Adaptive systems, automatic memory management, Condition monitoring, Costs, dynamic optimization, feedback directed optimization, feedback-directed optimization (FDO), Memory management, modular program representations, online monitoring, online profiling, optimising compilers, Optimized production technology, production level technology, Production systems, runtime compilation, Security, software performance evaluation, static optimizers, Virtual machine monitors, Virtual machining},
	pages = {449--466},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/K9ZEXRL4/1386662.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/DNPCDW47/Arnold et al. - 2005 - A Survey of Adaptive Optimization in Virtual Machi.pdf:application/pdf}
}

@inproceedings{ancona_semantic_2016,
	address = {New York, NY, USA},
	series = {{OOPSLA} 2016},
	title = {Semantic {Subtyping} for {Imperative} {Object}-oriented {Languages}},
	isbn = {978-1-4503-4444-9},
	url = {http://doi.acm.org/10.1145/2983990.2983992},
	doi = {10.1145/2983990.2983992},
	abstract = {Semantic subtyping is an approach for defining sound and complete procedures to decide subtyping for expressive types, including union and intersection types; although it has been exploited especially in functional languages for XML based programming, recently it has been partially investigated in the context of object-oriented languages, and a sound and complete subtyping algorithm has been proposed for record types, but restricted to immutable fields, with union and recursive types interpreted coinductively to support cyclic objects. In this work we address the problem of studying semantic subtyping for imperative object-oriented languages, where fields can be mutable; in particular, we add read/write field annotations to record types, and, besides union, we consider intersection types as well, while maintaining coinductive interpretation of recursive types. In this way, we get a richer notion of type with a flexible subtyping relation, able to express a variety of type invariants useful for enforcing static guarantees for mutable objects. The addition of these features radically changes the defi- nition of subtyping, and, hence, the corresponding decision procedure, and surprisingly invalidates some subtyping laws that hold in the functional setting. We propose an intuitive model where mutable record val- ues contain type information to specify the values that can be correctly stored in fields. Such a model, and the correspond- ing subtyping rules, require particular care to avoid circularity between coinductive judgments and their negations which, by duality, have to be interpreted inductively. A sound and complete subtyping algorithm is provided, together with a prototype implementation.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2016 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Ancona, Davide and Corradi, Andrea},
	year = {2016},
	keywords = {Read/Write Field Annotations, Semantic Subtyp- ing, Structural Types for Objects},
	pages = {568--587},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/SS9HNA3A/Ancona and Corradi - 2016 - Semantic Subtyping for Imperative Object-oriented .pdf:application/pdf}
}

@inproceedings{landman_challenges_2017,
	title = {Challenges for {Static} {Analysis} of {Java} {Reflection} - {Literature} {Review} and {Empirical} {Study}},
	doi = {10.1109/ICSE.2017.53},
	abstract = {The behavior of software that uses the Java Reflection API is fundamentally hard to predict by analyzing code. Only recent static analysis approaches can resolve reflection under unsound yet pragmatic assumptions. We survey what approaches exist and what their limitations are. We then analyze how real-world Java code uses the Reflection API, and how many Java projects contain code challenging state-of-the-art static analysis. Using a systematic literature review we collected and categorized all known methods of statically approximating reflective Java code. Next to this we constructed a representative corpus of Java systems and collected descriptive statistics of the usage of the Reflection API. We then applied an analysis on the abstract syntax trees of all source code to count code idioms which go beyond the limitation boundaries of static analysis approaches. The resulting data answers the research questions. The corpus, the tool and the results are openly available. We conclude that the need for unsound assumptions to resolve reflection is widely supported. In our corpus, reflection can not be ignored for 78\% of the projects. Common challenges for analysis tools such as non-exceptional exceptions, programmatic filtering meta objects, semantics of collections, and dynamic proxies, widely occur in the corpus. For Java software engineers prioritizing on robustness, we list tactics to obtain more easy to analyze reflection code, and for static analysis tool builders we provide a list of opportunities to have significant impact on real Java code.},
	booktitle = {2017 {IEEE}/{ACM} 39th {International} {Conference} on {Software} {Engineering} ({ICSE})},
	author = {Landman, D. and Serebrenik, A. and Vinju, J. J.},
	month = may,
	year = {2017},
	keywords = {Java, computational linguistics, program diagnostics, source code, application program interfaces, Software, Grammar, static analysis tool, abstract syntax trees, Bibliographies, code idioms, collected descriptive statistics, collections semantics, dynamic proxies, Empirical Study, Java projects, Java Reflection API, Java systems, literature review, nonexceptional exceptions, programmatic filtering meta objects, public domain software, real-world Java code analysis, Reflection, reflection code analysis, reflective Java code, Semantics, software behavior, software tools, source code (software), Static Analysis, Systematic Literature Review, Systematics, Tools, trees (mathematics)},
	pages = {507--518},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/XSVPXWLC/7985689.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/64TAFNJG/Landman et al. - 2017 - Challenges for Static Analysis of Java Reflection .pdf:application/pdf}
}

@article{ray_large-scale_2017,
	title = {A {Large}-scale {Study} of {Programming} {Languages} and {Code} {Quality} in {GitHub}},
	volume = {60},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/3126905},
	doi = {10.1145/3126905},
	abstract = {What is the effect of programming languages on software quality? This question has been a topic of much debate for a very long time. In this study, we gather a very large data set from GitHub (728 projects, 63 million SLOC, 29,000 authors, 1.5 million commits, in 17 languages) in an attempt to shed some empirical light on this question. This reasonably large sample size allows us to use a mixed-methods approach, combining multiple regression modeling with visualization and text analytics, to study the effect of language features such as static versus dynamic typing and allowing versus disallowing type confusion on software quality. By triangulating findings from different methods, and controlling for confounding effects such as team size, project size, and project history, we report that language design does have a significant, but modest effect on software quality. Most notably, it does appear that disallowing type confusion is modestly better than allowing it, and among functional languages, static typing is also somewhat better than dynamic typing. We also find that functional languages are somewhat better than procedural languages. It is worth noting that these modest effects arising from language design are overwhelmingly dominated by the process factors such as project size, team size, and commit size. However, we caution the reader that even these modest effects might quite possibly be due to other, intangible process factors, for example, the preference of certain personality types for functional, static languages that disallow type confusion.},
	number = {10},
	urldate = {2017-11-11},
	journal = {Commun. ACM},
	author = {Ray, Baishakhi and Posnett, Daryl and Devanbu, Premkumar and Filkov, Vladimir},
	month = sep,
	year = {2017},
	pages = {91--100},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/WME4ZMHT/Ray et al. - 2017 - A Large-scale Study of Programming Languages and C.pdf:application/pdf}
}

@inproceedings{nystrom_scala_2017,
	address = {New York, NY, USA},
	series = {{SCALA} 2017},
	title = {A {Scala} {Framework} for {Supercompilation}},
	isbn = {978-1-4503-5529-2},
	url = {http://doi.acm.org/10.1145/3136000.3136011},
	doi = {10.1145/3136000.3136011},
	abstract = {Supercompilation is a program transformation technique that attempts to evaluate programs as much as possible at compile time. Supercompilation has been used for theorem proving, function inversion, and most notably optimization, especially of functional programs. However, the technique has numerous practical problems that prevent it from being applied in mainstream compilers. In this paper, we describe a framework that can be used for experimenting with supercompilation techniques. Our framework allows supercompilers to be constructed directly from an interpreter. The user specifies the interpreter using rewrite rules and the framework handles termination checking, generalization, and residualization. We demonstrate the approach by implementing a supercompiler for JavaScript.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 8th {ACM} {SIGPLAN} {International} {Symposium} on {Scala}},
	publisher = {ACM},
	author = {Nystrom, Nathaniel},
	year = {2017},
	keywords = {supercompilation, abstract machines, language frameworks, partial evaluation},
	pages = {18--28},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/J4X53MU6/Nystrom - 2017 - A Scala Framework for Supercompilation.pdf:application/pdf}
}

@article{wu_how_2017,
	title = {How {Type} {Errors} {Were} {Fixed} and {What} {Students} {Did}?},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3133929},
	doi = {10.1145/3133929},
	abstract = {Providing better supports for debugging type errors has been an active research area in the last three decades. Numerous approaches from different perspectives have been developed. Most approaches work well under certain conditions only, for example, when type errors are caused by single leaves and when type annotations are correct. However, the research community is still unaware of which conditions hold in practice and what the real debugging situations look like. We address this problem with a study of 3 program data sets, which were written in different years, using different compilers, and were of diverse sizes. They include more than 55,000 programs, among which more than 2,700 are ill typed. We investigated all the ill-typed programs, and our results indicate that current error debugging support is far from sufficient in practice since only about 35\% of all type errors were caused by single leaves. In addition, type annotations cannot always be trusted in error debuggers since about 30\% of the time type errors were caused by wrong type annotations. Our study also provides many insights about the debugging behaviors of students in functional programming, which could be exploited for developing more effective error debuggers.},
	number = {OOPSLA},
	urldate = {2017-11-11},
	journal = {Proc. ACM Program. Lang.},
	author = {Wu, Baijun and Chen, Sheng},
	month = oct,
	year = {2017},
	keywords = {empirical study, type inference, Type-error debugging},
	pages = {105:1--105:27},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/RDJHMS2I/Wu and Chen - 2017 - How Type Errors Were Fixed and What Students Did.pdf:application/pdf}
}

@article{dietrich_contracts_2017,
	title = {Contracts in the {Wild}: {A} {Study} of {Java} {Programs} ({Artifact})},
	volume = {3},
	issn = {2509-8195},
	shorttitle = {Contracts in the {Wild}},
	url = {http://drops.dagstuhl.de/opus/volltexte/2017/7287},
	doi = {10.4230/DARTS.3.2.6},
	number = {1},
	urldate = {2017-11-11},
	journal = {Dagstuhl Artifacts Series},
	author = {Dietrich, Jens and Pearce, David J. and Jezek, Kamil and Brada, Premek},
	year = {2017},
	keywords = {verification, java, assertions, design-by-contract, input validation, postconditions, preconditions, runtime checking},
	pages = {6:1--6:4},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/GAC558CJ/Dietrich et al. - 2017 - Contracts in the Wild A Study of Java Programs (A.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/R668MBWW/7287.html:text/html}
}

@inproceedings{brandauer_spencer:_2017,
	title = {Spencer: {Interactive} {Heap} {Analysis} for the {Masses}},
	shorttitle = {Spencer},
	doi = {10.1109/MSR.2017.35},
	abstract = {Programming language-design and run-time-implementation require detailed knowledge about the programs that users want to implement. Acquiring this knowledge is hard, and there is little tool support to effectively estimate whether a proposed tradeoff actually makes sense in the context of real world applications. Ideally, knowledge about behaviour of "typical" programs is 1) easily obtainable, 2) easily reproducible, and 3) easily sharable. We present Spencer, an open source web service and APIframework for dynamic analysis of a continuously growing set of traces of standard program corpora. Users do not obtain traces on their own, but can instead send queries to the web service that will be executed on a set of program traces. Queries are built in terms of a set of query combinators that present a high level interface for working with trace data. Since the framework is high level, and there is a hosted collection of recorded traces, queries are easy to implement. Since the data sets are shared by the research community, results are reproducible. Since the actual queries run on one (or many) servers that provide analysis as a service, obtaining results is possible on commodity hardware. Data in Spencer is meant to be obtained once, and analysed often, making the overhead of data collection mostly irrelevant. This allows Spencer to collect more data than traditional tracing tools can afford within their performance budget. Results in Spencer are cached, making complicated analyses that build on cached primitive queries speedy.},
	booktitle = {2017 {IEEE}/{ACM} 14th {International} {Conference} on {Mining} {Software} {Repositories} ({MSR})},
	author = {Brandauer, S. and Wrigstad, T.},
	month = may,
	year = {2017},
	keywords = {Optimization, Computer languages, Performance analysis, program diagnostics, dynamic analysis, public domain software, Tools, APIframework, data analysis, Data visualization, heap analysis, interactive heap analysis, masses, open source Web service, program knowledge, program traces, programming language-design, query combinators, query processing, Resource management, run-time-implementation, Spencer, tracing, Web services},
	pages = {113--123},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/FZDGWGCB/7962361.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/9MELSS2W/Brandauer and Wrigstad - 2017 - Spencer Interactive Heap Analysis for the Masses.pdf:application/pdf}
}

@inproceedings{costa_empirical_2017,
	address = {New York, NY, USA},
	series = {{ICPE} '17},
	title = {Empirical {Study} of {Usage} and {Performance} of {Java} {Collections}},
	isbn = {978-1-4503-4404-3},
	url = {http://doi.acm.org/10.1145/3030207.3030221},
	doi = {10.1145/3030207.3030221},
	abstract = {Collection data structures have a major impact on the performance of applications, especially in languages such as Java, C\#, or C++. This requires a developer to select an appropriate collection from a large set of possibilities, including different abstractions (e.g. list, map, set, queue), and multiple implementations. In Java, the default implementation of collections is provided by the standard Java Collection Framework (JCF). However, there exist a large variety of less known third-party collection libraries which can provide substantial performance benefits with minimal code changes. In this paper, we first study the popularity and usage patterns of collection implementations by mining a code corpus comprised of 10,986 Java projects. We use the results to evaluate and compare the performance of the six most popular alternative collection libraries in a large variety of scenarios. We found that for almost every scenario and JCF collection type there is an alternative implementation that greatly decreases memory consumption while offering comparable or even better execution time. Memory savings range from 60\% to 88\% thanks to reduced overhead and some operations execute 1.5x to 50x faster. We present our results as a comprehensive guideline to help developers in identifying the scenarios in which an alternative implementation can provide a substantial performance improvement. Finally, we discuss how some coding patterns result in substantial performance differences of collections.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 8th {ACM}/{SPEC} on {International} {Conference} on {Performance} {Engineering}},
	publisher = {ACM},
	author = {Costa, Diego and Andrzejak, Artur and Seboek, Janos and Lo, David},
	year = {2017},
	keywords = {empirical study, java, collections, execution time, memory, performance},
	pages = {389--400},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/SIKHR6LM/Costa et al. - 2017 - Empirical Study of Usage and Performance of Java C.pdf:application/pdf}
}

@inproceedings{dietrich_contracts_2017-1,
	address = {Dagstuhl, Germany},
	series = {Leibniz {International} {Proceedings} in {Informatics} ({LIPIcs})},
	title = {Contracts in the {Wild}: {A} {Study} of {Java} {Programs}},
	volume = {74},
	isbn = {978-3-95977-035-4},
	shorttitle = {Contracts in the {Wild}},
	url = {http://drops.dagstuhl.de/opus/volltexte/2017/7259},
	doi = {10.4230/LIPIcs.ECOOP.2017.9},
	urldate = {2017-11-11},
	booktitle = {31st {European} {Conference} on {Object}-{Oriented} {Programming} ({ECOOP} 2017)},
	publisher = {Schloss Dagstuhl{\textendash}Leibniz-Zentrum fuer Informatik},
	author = {Dietrich, Jens and Pearce, David J. and Jezek, Kamil and Brada, Premek},
	editor = {M{\"u}ller, Peter},
	year = {2017},
	keywords = {verification, java, assertions, design-by-contract, input validation, postconditions, preconditions, runtime checking},
	pages = {9:1--9:29},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/MA2KGGVP/Dietrich et al. - 2017 - Contracts in the Wild A Study of Java Programs.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/Y2BVGBRZ/7259.html:text/html}
}

@inproceedings{tiwari_candoia:_2017,
	title = {Candoia: {A} {Platform} for {Building} and {Sharing} {Mining} {Software} {Repositories} {Tools} as {Apps}},
	shorttitle = {Candoia},
	doi = {10.1109/MSR.2017.56},
	abstract = {We propose Candoia, a novel platform and ecosystemfor building and sharing Mining Software Repositories(MSR) tools. Using Candoia, MSR tools are built as apps, and Candoia ecosystem, acting as an appstore, allows effective sharing. Candoia platform provides, data extraction tools for curating custom datasets for user projects, and data abstractions for enabling uniform access to MSR artifacts from disparate sources, which makes apps portable and adoptable across diverse software project settings of MSR researchers and practitioners. The structured design of a Candoia app and the languages selected for building various components of a Candoia app promotes easy customization. To evaluate Candoia we have built over two dozen MSR apps for analyzing bugs, software evolution, project management aspects, and source code and programming practices showing the applicability of the platform for buildinga variety of MSR apps. For testing portability of apps acrossdiverse project settings, we tested the apps using ten popularproject repositories, such as Apache Tomcat, JUnit, Node.js, etc, and found that apps required no changes to be portable. We performed a user study to test customizability and we found that five of eight Candoia users found it very easy to customize an existing app. Candoia is available for download.},
	booktitle = {2017 {IEEE}/{ACM} 14th {International} {Conference} on {Mining} {Software} {Repositories} ({MSR})},
	author = {Tiwari, N. M. and Upadhyaya, G. and Nguyen, H. A. and Rajan, H.},
	month = may,
	year = {2017},
	keywords = {Java, Data mining, Buildings, source code, Software, program debugging, software tools, Tools, app customizability, apps sharing, appstore, Candioa ecosystem, Candoia, Candoia app, Candoia exchange, Computer bugs, data abstractions, data extraction tools, Ecosystems, mining software repositories tools, MSR, MSR apps, MSR data, MSR tools, programming practices, project management, software bugs, software evolution, software project settings},
	pages = {53--63},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/WY37L35S/7962355.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/A2BL7GWK/Tiwari et al. - 2017 - Candoia A Platform for Building and Sharing Minin.pdf:application/pdf}
}

@article{wu_learning_2017,
	title = {Learning {User} {Friendly} {Type}-error {Messages}},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3133930},
	doi = {10.1145/3133930},
	abstract = {Type inference is convenient by allowing programmers to elide type annotations, but this comes at the cost of often generating very confusing and opaque type error messages that are of little help to fix type errors. Though there have been many successful attempts at making type error messages better in the past thirty years, many classes of errors are still difficult to fix. In particular, current approaches still generate imprecise and uninformative error messages for type errors arising from errors in grouping constructs like parentheses and brackets. Worse, a recent study shows that these errors usually take more than 10 steps to fix and occur quite frequently (around 45\% to 60\% of all type errors) in programs written by students learning functional programming. We call this class of errors, nonstructural errors. We solve this problem by developing Learnskell, a type error debugger that uses machine learning to help diagnose and deliver high quality error messages, for programs that contain nonstructural errors. While previous approaches usually report type errors on typing constraints or on the type level, Learnskell generates suggestions on the expression level. We have performed an evaluation on more than 1,500 type errors, and the result shows that Learnskell is quite precise. It can correctly capture 86\% of all nonstructural errors and locate the error cause with a precision of 63\%/87\% with the first 1/3 messages, respectively. This is several times more than the precision of state-of-the-art compilers and debuggers. We have also studied the performance of Learnskell and found out that it scales to large programs.},
	number = {OOPSLA},
	urldate = {2017-11-11},
	journal = {Proc. ACM Program. Lang.},
	author = {Wu, Baijun and Campora III, John Peter and Chen, Sheng},
	month = oct,
	year = {2017},
	keywords = {concrete messages, machine learning, structure- changing errors, Type error debugging},
	pages = {106:1--106:29},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/8IEJVW23/Wu et al. - 2017 - Learning User Friendly Type-error Messages.pdf:application/pdf}
}

@inproceedings{avgustinov_tracking_2015,
	title = {Tracking {Static} {Analysis} {Violations} over {Time} to {Capture} {Developer} {Characteristics}},
	volume = {1},
	doi = {10.1109/ICSE.2015.62},
	abstract = {Many interesting questions about the software quality of a code base can only be answered adequately if fine-grained information about the evolution of quality metrics over time and the contributions of individual developers is known. We present an approach for tracking static analysis violations (which are often indicative of defects) over the revision history of a program, and for precisely attributing the introduction and elimination of these violations to individual developers. As one application, we demonstrate how this information can be used to compute {\textquotedblleft}fingerprints{\textquotedblright} of developers that reflect which kinds of violations they tend to introduce or to fix. We have performed an experimental study on several large open-source projects written in different languages, providing evidence that these fingerprints are well-defined and capture characteristic information about the coding habits of individual developers.},
	booktitle = {2015 {IEEE}/{ACM} 37th {IEEE} {International} {Conference} on {Software} {Engineering}},
	author = {Avgustinov, P. and Baars, A. I. and Henriksen, A. S. and Lavender, G. and Menzel, G. and Moor, O. d and Sch{\"a}fer, M. and Tibble, J.},
	month = may,
	year = {2015},
	keywords = {Java, Libraries, History, program diagnostics, software quality, Software quality, public domain software, coding habits, fine-grained information, Open source software, open-source projects, Position measurement, program revision history, quality metrics, static analysis violations tracking},
	pages = {437--447},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/38QVG2IW/7194595.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/7WFT9HDY/Avgustinov et al. - 2015 - Tracking Static Analysis Violations over Time to C.pdf:application/pdf}
}

@article{mazinanian_understanding_2017,
	title = {Understanding the {Use} of {Lambda} {Expressions} in {Java}},
	volume = {1},
	issn = {2475-1421},
	url = {http://doi.acm.org/10.1145/3133909},
	doi = {10.1145/3133909},
	abstract = {Java 8 retrofitted lambda expressions, a core feature of functional programming, into a mainstream object-oriented language with an imperative paradigm. However, we do not know how Java developers have adapted to the functional style of thinking, and more importantly, what are the reasons motivating Java developers to adopt functional programming. Without such knowledge, researchers miss opportunities to improve the state of the art, tool builders use unrealistic assumptions, language designers fail to improve upon their designs, and developers are unable to explore efficient and effective use of lambdas.   We present the first large-scale, quantitative and qualitative empirical study to shed light on how imperative programmers use lambda expressions as a gateway into functional thinking. Particularly, we statically scrutinize the source code of 241 open-source projects with 19,770 contributors, to study the characteristics of 100,540 lambda expressions. Moreover, we investigate the historical trends and adoption rates of lambdas in the studied projects. To get a complementary perspective, we seek the underlying reasons on why developers introduce lambda expressions, by surveying 97 developers who are introducing lambdas in their projects, using the firehouse interview method.   Among others, our findings revealed an increasing trend in the adoption of lambdas in Java: in 2016, the ratio of lambdas introduced per added line of code increased by 54\% compared to 2015. Lambdas were used for various reasons, including but not limited to (i) making existing code more succinct and readable, (ii) avoiding code duplication, and (iii) simulating lazy evaluation of functions. Interestingly, we found out that developers are using Java's built-in functional interfaces inefficiently, i.e., they prefer to use general functional interfaces over the specialized ones, overlooking the performance overheads that might be imposed. Furthermore, developers are not adopting techniques from functional programming, e.g., currying. Finally, we present the implications of our findings for researchers, tool builders, language designers, and developers.},
	number = {OOPSLA},
	urldate = {2017-11-11},
	journal = {Proc. ACM Program. Lang.},
	author = {Mazinanian, Davood and Ketkar, Ameya and Tsantalis, Nikolaos and Dig, Danny},
	month = oct,
	year = {2017},
	keywords = {Empirical Studies, Functional Programming, Java 8, Lambda Expressions, Multi-paradigm Programming, The Firehouse Interview Method},
	pages = {85:1--85:31},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/Q8CU569X/Mazinanian et al. - 2017 - Understanding the Use of Lambda Expressions in Jav.pdf:application/pdf}
}

@inproceedings{mastrangelo_use_2015,
	address = {New York, NY, USA},
	series = {{OOPSLA} 2015},
	title = {Use at {Your} {Own} {Risk}: {The} {Java} {Unsafe} {API} in the {Wild}},
	isbn = {978-1-4503-3689-5},
	shorttitle = {Use at {Your} {Own} {Risk}},
	url = {http://doi.acm.org/10.1145/2814270.2814313},
	doi = {10.1145/2814270.2814313},
	abstract = {Java is a safe language. Its runtime environment provides strong safety guarantees that any Java application can rely on. Or so we think. We show that the runtime actually does not provide these guarantees---for a large fraction of today's Java code. Unbeknownst to many application developers, the Java runtime includes a "backdoor" that allows expert library and framework developers to circumvent Java's safety guarantees. This backdoor is there by design, and is well known to experts, as it enables them to write high-performance "systems-level" code in Java. For much the same reasons that safe languages are preferred over unsafe languages, these powerful---but unsafe---capabilities in Java should be restricted. They should be made safe by changing the language, the runtime system, or the libraries. At the very least, their use should be restricted. This paper is a step in that direction. We analyzed 74 GB of compiled Java code, spread over 86,479 Java archives, to determine how Java's unsafe capabilities are used in real-world libraries and applications. We found that 25\% of Java bytecode archives depend on unsafe third-party Java code, and thus Java's safety guarantees cannot be trusted. We identify 14 different usage patterns of Java's unsafe capabilities, and we provide supporting evidence for why real-world code needs these capabilities. Our long-term goal is to provide a foundation for the design of new language features to regain safety in Java.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2015 {ACM} {SIGPLAN} {International} {Conference} on {Object}-{Oriented} {Programming}, {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Mastrangelo, Luis and Ponzanelli, Luca and Mocci, Andrea and Lanza, Michele and Hauswirth, Matthias and Nystrom, Nathaniel},
	year = {2015},
	keywords = {Java, patterns, mining, Maven Central, Stack Overflow, unsafe},
	pages = {695--710},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/SKY5CYFY/Mastrangelo et al. - 2015 - Use at Your Own Risk The Java Unsafe API in the W.pdf:application/pdf}
}

@article{shen_empirical_1990,
	title = {An empirical study of {Fortran} programs for parallelizing compilers},
	volume = {1},
	issn = {1045-9219},
	doi = {10.1109/71.80162},
	abstract = {Some results are reported from an empirical study of program characteristics, that are important in parallelizing compiler writers, especially in the area of data dependence analysis and program transformations. The state of the art in data dependence analysis and some parallel execution techniques are examined. The major findings are included. Many subscripts contain symbolic terms with unknown values. A few methods of determining their values at compile time are evaluated. Array references with coupled subscripts appear quite frequently; these subscripts must be handled simultaneously in a dependence test, rather than being handled separately as in current test algorithms. Nonzero coefficients of loop indexes in most subscripts are found to be simple: they are either 1 or -1. This allows an exact real-valued test to be as accurate as an exact integer-valued test for one-dimensional or two-dimensional arrays. Dependencies with uncertain distance are found to be rather common, and one of the main reasons is the frequent appearance of symbolic terms with unknown values},
	number = {3},
	journal = {IEEE Transactions on Parallel and Distributed Systems},
	author = {Shen, Z. and Li, Z. and Yew, P. C.},
	month = jul,
	year = {1990},
	keywords = {FORTRAN, program compilers, program transformations, array references, Councils, Data analysis, data dependence analysis, Fortran programs, Helium, integer-valued test, NASA, parallelizing compilers, program characteristics, Program processors, Scheduling, Space technology, Statistics, Testing, US Department of Energy},
	pages = {356--364},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/EAI25Q9Z/80162.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/EFFFV5FN/Shen et al. - 1990 - An empirical study of Fortran programs for paralle.pdf:application/pdf}
}

@article{chevance_static_1978,
	title = {Static {Profile} and {Dynamic} {Behavior} of {COBOL} {Programs}},
	volume = {13},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/953411.953414},
	doi = {10.1145/953411.953414},
	abstract = {A measurement system for gathering a static profile and dynamic characteristics of COBOL programs at the source language level is described. Static and dynamic results are presented and discussed.},
	number = {4},
	urldate = {2017-11-11},
	journal = {SIGPLAN Not.},
	author = {Chevance, R. J. and Heidet, T.},
	month = apr,
	year = {1978},
	pages = {44--57},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/YZUTQ85D/Chevance and Heidet - 1978 - Static Profile and Dynamic Behavior of COBOL Progr.pdf:application/pdf}
}

@article{salvadori_static_1975,
	title = {Static {Profile} of {COBOL} {Programs}},
	volume = {10},
	issn = {0362-1340},
	url = {http://doi.acm.org/10.1145/956028.956031},
	doi = {10.1145/956028.956031},
	number = {8},
	urldate = {2017-11-11},
	journal = {SIGPLAN Not.},
	author = {Salvadori, A and Gordon, J. and Capstick, C.},
	month = aug,
	year = {1975},
	pages = {20--33},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/QLJAPQNC/Salvadori et al. - 1975 - Static Profile of COBOL Programs.pdf:application/pdf}
}

@inproceedings{saal_properties_1975,
	address = {New York, NY, USA},
	series = {{APL} '75},
	title = {Some {Properties} of {APL} {Programs}},
	url = {http://doi.acm.org/10.1145/800117.803819},
	doi = {10.1145/800117.803819},
	abstract = {Some results of a study of the static usage of features of the APL language is presented. We compare several characterizations of APL programs with previously measured FORTRAN data, and discuss the significant differences observed. The verity of popular rumors and intuitions about APL programs is also examined. APL users appear to take advantage of the unique matrix features inherent in APL, but in general, use extremely heavily only a small fraction of the available features. The distribution of use agrees well with the so-called {\textquotedblleft}80-20 rule{\textquotedblright}.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of {Seventh} {International} {Conference} on {APL}},
	publisher = {ACM},
	author = {Saal, Harry J. and Weiss, Zvi},
	year = {1975},
	pages = {292--297},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/L2NLKES5/Saal and Weiss - 1975 - Some Properties of APL Programs.pdf:application/pdf}
}

@article{cook_contextual_1982,
	title = {A contextual analysis of {Pascal} programs},
	volume = {12},
	issn = {1097-024X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/spe.4380120209/abstract},
	doi = {10.1002/spe.4380120209},
	abstract = {More than 120,000 lines of Pascal programs, written by graduate students and faculty members, have been statically analysed to provide a better understanding of how the language is {\textquoteleft}really{\textquoteright} used. The analysis was done within twelve distinct contexts to discover differences in usage patterns among the various contexts. For example, it was found that 47 per cent of the operands in arguments lists were constants. The results are displayed as tables of frequency counts which show how often each construct is used within a context. Also, we have compared our findings to the results from studies of other languages, such as FORTRAN, SAL and XPL.},
	language = {en},
	number = {2},
	urldate = {2017-11-11},
	journal = {Software: Practice and Experience},
	author = {Cook, Robert P. and Lee, Insup},
	month = feb,
	year = {1982},
	keywords = {Contextual analysis, Pascal, Static analysis},
	pages = {195--203},
	file = {Snapshot:/Volumes/Data/work/zotero/storage/T2FVEF3Y/abstract.html:text/html}
}

@article{saal_empirical_1977,
	title = {An empirical study of {APL} programs},
	volume = {2},
	issn = {0096-0551},
	url = {http://www.sciencedirect.com/science/article/pii/0096055177900078},
	doi = {10.1016/0096-0551(77)90007-8},
	abstract = {The statistical results of a study of the static usage of features of the APL language is presented. The distributions of the appearance of the APL primitive functions and the functions derived from the APL operators are presented. APL users appear to use extremely heavily only a small fraction of the available features. The paper compares several characterizations of APL programs with previously measured FORTRAN data, and discusses the significant differences observed.},
	number = {3},
	urldate = {2017-11-11},
	journal = {Computer Languages},
	author = {Saal, Harry J. and Weiss, Zvi},
	month = jan,
	year = {1977},
	keywords = {80-20 rule, APL, a programming language, Programming style, Static measurements, Usage statistics, Very high level languages},
	pages = {47--59},
	file = {ScienceDirect Snapshot:/Volumes/Data/work/zotero/storage/EFI525BJ/0096055177900078.html:text/html}
}

@article{bohm_automatic_1985,
	series = {Third {Conference} on {Foundations} of {Software} {Technology} and {Theoretical} {Computer} {Science}},
	title = {Automatic synthesis of typed $\Lambda$-programs on term algebras},
	volume = {39},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/0304397585901355},
	doi = {10.1016/0304-3975(85)90135-5},
	abstract = {The notion of iteratively defined functions from and to heterogeneous term algebras is introduced as the solution of a finite set of equations of a special shape. Such a notion has remarkable consequences: (1) Choosing the second-order typed lamdda-calculus ($\Lambda$ for short) as a programming language enables one to represent algebra elements and iterative functions by automatic uniform synthesis paradigms, using neither conditional nor recursive constructs. (2) A completeness theorem for $\Lambda$-terms with type of degree at most two and a companion corollary for $\Lambda$-programs have been proved. (3) A new congruence relation for the last-mentioned $\Lambda$-terms which is stronger than $\Lambda$-convertibility is introduced and proved to have the meaning of a $\Lambda$-program equivalence. Moreover, an extension of the paradigms to the synthesis of functions of higher complexity is considered and exemplified. All the concepts are explained and motivated by examples over integers, list- and tree-structures.},
	number = {Supplement C},
	urldate = {2017-11-11},
	journal = {Theoretical Computer Science},
	author = {B{\"o}hm, Corrado and Berarducci, Alessandro},
	month = jan,
	year = {1985},
	pages = {135--154},
	file = {ScienceDirect Full Text PDF:/Volumes/Data/work/zotero/storage/HKM388G4/B{\"o}hm and Berarducci - 1985 - Automatic synthesis of typed $\Lambda$-programs on term al.pdf:application/pdf;ScienceDirect Snapshot:/Volumes/Data/work/zotero/storage/5DEDNES5/0304397585901355.html:text/html}
}

@article{cook_empirical_1989,
	title = {An empirical analysis of the {Lilith} instruction set},
	volume = {38},
	issn = {0018-9340},
	doi = {10.1109/12.8740},
	abstract = {A static analysis of the instructions used to implement all of the system software on the Lilith computer is described. The results are compared to those of a similar analysis performed on the Mesa instruction set architecture. The data provide a good illustration of how code generation strategies and language usage can affect opcode statistics, even for machines with similar architectures},
	number = {1},
	journal = {IEEE Transactions on Computers},
	author = {Cook, R. P.},
	month = jan,
	year = {1989},
	keywords = {Operating systems, Performance analysis, Computer architecture, Hardware, Statistics, code generation strategies, Computer aided instruction, High level languages, instruction sets, language usage, Lilith instruction set, Lilith software environment, Mesa instruction set architecture, Modula, opcode statistics, Packaging machines, Software packages, static analysis, system software, System software, systems software},
	pages = {156--158},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/SFFJIB9S/8740.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/6R6EB6W8/Cook - 1989 - An empirical analysis of the Lilith instruction se.pdf:application/pdf}
}

@techreport{antonioli_analysis_1998,
	title = {Analysis of the {Java} {Class} {File} {Format}},
	abstract = {this paper is to gather statistics on the Java class files, which serve in Java both as an object file for the Java Virtual Machine and as an intermediate program representation for cross-platform delivery. Such statistics are of interests to both the developers of Java tools and the designers of intermediate languages. The goal of this work is to study the properties of the Java class file format and particularly to answer these questions:},
	author = {Antonioli, Denis N. and Pilz, Markus},
	year = {1998},
	file = {Citeseer - Full Text PDF:/Volumes/Data/work/zotero/storage/EI4ZVNYI/Antonioli and Pilz - 1998 - Analysis of the Java Class File Format.pdf:application/pdf;Citeseer - Snapshot:/Volumes/Data/work/zotero/storage/7SRRLTI3/summary.html:text/html}
}

@inproceedings{odonoghue_bigram_2002,
	address = {Maynooth, County Kildare, Ireland, Ireland},
	series = {{PPPJ} '02/{IRE} '02},
	title = {Bigram {Analysis} of {Java} {Bytecode} {Sequences}},
	isbn = {978-0-901519-87-0},
	url = {http://dl.acm.org/citation.cfm?id=638476.638513},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the {Inaugural} {Conference} on the {Principles} and {Practice} of {Programming}, 2002 and {Proceedings} of the {Second} {Workshop} on {Intermediate} {Representation} {Engineering} for {Virtual} {Machines}, 2002},
	publisher = {National University of Ireland},
	author = {O'Donoghue, Diarmuid and Leddy, Aine and Power, James and Waldron, John},
	year = {2002},
	pages = {187--192},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/MNCE7CVB/O'Donoghue et al. - 2002 - Bigram Analysis of Java Bytecode Sequences.pdf:application/pdf}
}

@article{kaijanaho_evidence-based_2015,
	title = {Evidence-based programming language design : a philosophical and methodological exploration},
	issn = {1456-5390},
	shorttitle = {Evidence-based programming language design},
	url = {https://jyx.jyu.fi/dspace/handle/123456789/47698},
	abstract = {Background: Programming language design is not usually informed by empirical 
studies. In other fields similar problems have inspired an evidence-based paradigm 
of practice. Such a paradigm is practically inevitable in language design, as well. 
Aims: The content of evidence-based programming design (EB-PLD) is explored, 
as is the concept of evidence in general. Additionally, the extent of evidence 
potentially useful for EB-PLD is mapped, and the appropriateness of Cohen{\textquoteright}s 
kappa for evaluating coder agreement in a secondary study is evaluated. Method: 
Philosophical analysis and explication are used to clarify the unclear. A systematic mapping study was conducted to map out the existing body of evidence. 
Results: Evidence is a report of observations that affects the strength of an argument. There is some but not much evidence. EB-PLD is a five-step process for 
resolving uncertainty about design problems. Cohen{\textquoteright}s kappa is inappropriate for 
coder agreement evaluation in systematic secondary studies. Conclusions: Coder 
agreement evaluation should use Scott{\textquoteright}s pi, Fleiss{\textquoteright} kappa, or Krippendorff{\textquoteright}s alpha. EB-PLD is worthy of further research, although its usefulness was out of 
scope here.},
	language = {eng},
	urldate = {2017-11-11},
	journal = {Jyv{\"a}skyl{\"a} studies in computing 222.},
	author = {Kaijanaho, Antti-Juhani},
	year = {2015},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/767TLGZR/Kaijanaho - 2015 - Evidence-based programming language design  a phi.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/Q6QQ6TJ2/47698.html:text/html}
}

@inproceedings{li_accessing_2016,
	title = {Accessing {Inaccessible} {Android} {APIs}: {An} {Empirical} {Study}},
	shorttitle = {Accessing {Inaccessible} {Android} {APIs}},
	doi = {10.1109/ICSME.2016.35},
	abstract = {As Android becomes a de-facto choice of development platform for mobile apps, developers extensively leverage its accompanying Software Development Kit to quickly build their apps. This SDK comes with a set of APIs which developers may find limited in comparison to what system apps can do or what framework developers are preparing to harness capabilities of new generation devices. Thus, developers may attempt to explore in advance the normally "inaccessible" APIs for building unique API-based functionality in their app. The Android programming model is unique in its kind. Inaccessible APIs, which however are used by developers, constitute yet another specificity of Android development, and is worth investigating to understand what they are, how they evolve over time, and who uses them. To that end, in this work, we empirically investigate 17 important releases of the Android framework source code base, and we find that inaccessible APIs are commonly implemented in the Android framework, which are further neither forward nor backward compatible. Moreover, a small set of inaccessible APIs can eventually become publicly accessible, while most of them are removed during the evolution, resulting in risks for such apps that have leveraged inaccessible APIs. Finally, we show that inaccessible APIs are indeed accessed by third-party apps, and the official Google Play store has tolerated the proliferation of apps leveraging inaccessible API methods.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Software} {Maintenance} and {Evolution} ({ICSME})},
	author = {Li, L. and Bissyand{\'e}, T. F. and Traon, Y. L. and Klein, J.},
	month = oct,
	year = {2016},
	keywords = {Runtime, Libraries, application program interfaces, Software, software engineering, source code (software), Ecosystems, unsafe, Android (operating system), Android programming model, Androids, API-based functionality, application program interface, authorisation, Google, Humanoid robots, inaccessible Android API, mobile app risk, mobile computing, risk management, SDK, smart phones, software development kit, source code base},
	pages = {411--422},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/4C4Q9XKX/7816486.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/QFQSUX6L/Li et al. - 2016 - Accessing Inaccessible Android APIs An Empirical .pdf:application/pdf}
}

@inproceedings{hora_when_2016,
	address = {New York, NY, USA},
	series = {{FSE} 2016},
	title = {When {Should} {Internal} {Interfaces} {Be} {Promoted} to {Public}?},
	isbn = {978-1-4503-4218-6},
	url = {http://doi.acm.org/10.1145/2950290.2950306},
	doi = {10.1145/2950290.2950306},
	abstract = {Commonly, software systems have public (and stable) interfaces, and internal (and possibly unstable) interfaces. Despite being discouraged, client developers often use internal interfaces, which may cause their systems to fail when they evolve. To overcome this problem, API producers may promote internal interfaces to public. In practice, however, API producers have no assistance to identify public interface candidates. In this paper, we study the transition from internal to public interfaces. We aim to help API producers to deliver a better product and API clients to benefit sooner from public interfaces. Our empirical investigation on five widely adopted Java systems present the following observations. First, we identified 195 promotions from 2,722 internal interfaces. Second, we found that promoted internal interfaces have more clients. Third, we predicted internal interface promotion with precision between 50\%-80\%, recall 26\%-82\%, and AUC 74\%-85\%. Finally, by applying our predictor on the last version of the analyzed systems, we automatically detected 382 public interface candidates.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2016 24th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Hora, Andr{\'e} and Valente, Marco Tulio and Robbes, Romain and Anquetil, Nicolas},
	year = {2016},
	keywords = {unsafe, API Usage, Internal Interface Analysis, Software Evolution},
	pages = {278--289},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/5N3TT5YR/Hora et al. - 2016 - When Should Internal Interfaces Be Promoted to Pub.pdf:application/pdf}
}

@inproceedings{saied_cooperative_2016,
	title = {A cooperative approach for combining client-based and library-based {API} usage pattern mining},
	doi = {10.1109/ICPC.2016.7503717},
	abstract = {Software developers need to cope with the complexity of Application Programming Interfaces (APIs) of external libraries or frameworks. Typical APIs provide thousands of methods to their client programs, and these methods are not used independently of each other. Much existing work has provided different techniques to mine API usage patterns based on client programs in order to help developers understanding and using existing libraries. Other techniques propose to overcome the strong constraint of clients' dependency and infer API usage patterns only using the library source code. In this paper, we propose a cooperative usage pattern mining technique (COUPminer) that combines client-based and library-based usage pattern mining. We evaluated our technique through four APIs and the obtained results show that the cooperative approach allows taking advantage at the same time from the precision of client-based technique and from the generalizability of library-based techniques.},
	booktitle = {2016 {IEEE} 24th {International} {Conference} on {Program} {Comprehension} ({ICPC})},
	author = {Saied, M. A. and Sahraoui, H.},
	month = may,
	year = {2016},
	keywords = {Java, Libraries, software libraries, data mining, application program interfaces, Semantics, source code (software), unsafe, API Usage, API Documentation, application programming interfaces, client programs, client-based API usage pattern mining, client-based technique, Context, cooperative usage pattern mining technique, COUPminer, Digital signatures, Documentation, library source code, library-based API usage pattern mining, library-based techniques, Software Clustering, software developers, Usage Pattern},
	pages = {1--10},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/N2Y6FBVG/7503717.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/JDFHH96C/Saied and Sahraoui - 2016 - A cooperative approach for combining client-based .pdf:application/pdf}
}

@inproceedings{bruno_ng2c:_2017,
	address = {New York, NY, USA},
	series = {{ISMM} 2017},
	title = {{NG}2C: {Pretenuring} {Garbage} {Collection} with {Dynamic} {Generations} for {HotSpot} {Big} {Data} {Applications}},
	isbn = {978-1-4503-5044-0},
	shorttitle = {{NG}2C},
	url = {http://doi.acm.org/10.1145/3092255.3092272},
	doi = {10.1145/3092255.3092272},
	abstract = {Big Data applications suffer from unpredictable and unacceptably high pause times due to Garbage Collection (GC). This is the case in latency-sensitive applications such as on-line credit-card fraud detection, graph-based computing for analysis on social networks, etc. Such pauses compromise latency requirements of the whole application stack and result from applications' aggressive buffering/caching of data, exposing an ill-suited GC design, which assumes that most objects will die young and does not consider that applications hold large amounts of middle-lived data in memory.   To avoid such pauses, we propose NG2C, a new GC algorithm that combines pretenuring with user-defined dynamic generations. By being able to allocate objects into different generations, NG2C is able to group objects with similar lifetime profiles in the same generation. By allocating objects with similar lifetime profiles close to each other, i.e. in the same generation, we avoid object promotion (copying between generations) and heap fragmentation (which leads to heap compactions) both responsible for most of the duration of HotSpot GC pause times.   NG2C is implemented for the OpenJDK 8 HotSpot Java Virtual Machine, as an extension of the Garbage First GC. We evaluate NG2C using Cassandra, Lucene, and GraphChi with three different GCs: Garbage First (G1), Concurrent Mark Sweep (CMS), and NG2C. Results show that NG2C decreases the worst observable GC pause time by up to 94.8\% for Cassandra, 85.0\% for Lucene and 96.45\% for GraphChi, when compared to current collectors (G1 and CMS). In addition, NG2c has no negative impact on application throughput or memory usage.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2017 {ACM} {SIGPLAN} {International} {Symposium} on {Memory} {Management}},
	publisher = {ACM},
	author = {Bruno, Rodrigo and Oliveira, Lu{\'i}s Picciochi and Ferreira, Paulo},
	year = {2017},
	keywords = {unsafe, Big Data, Garbage Collection, Latency},
	pages = {2--13},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/PWDU74BA/Bruno et al. - 2017 - NG2C Pretenuring Garbage Collection with Dynamic .pdf:application/pdf}
}

@inproceedings{holzinger_-depth_2016,
	address = {New York, NY, USA},
	series = {{CCS} '16},
	title = {An {In}-{Depth} {Study} of {More} {Than} {Ten} {Years} of {Java} {Exploitation}},
	isbn = {978-1-4503-4139-4},
	url = {http://doi.acm.org/10.1145/2976749.2978361},
	doi = {10.1145/2976749.2978361},
	abstract = {When created, the Java platform was among the first runtimes designed with security in mind. Yet, numerous Java versions were shown to contain far-reaching vulnerabilities, permitting denial-of-service attacks or even worse allowing intruders to bypass the runtime's sandbox mechanisms, opening the host system up to many kinds of further attacks. This paper presents a systematic in-depth study of 87 publicly available Java exploits found in the wild. By collecting, minimizing and categorizing those exploits, we identify their commonalities and root causes, with the goal of determining the weak spots in the Java security architecture and possible countermeasures. Our findings reveal that the exploits heavily rely on a set of nine weaknesses, including unauthorized use of restricted classes and confused deputies in combination with caller-sensitive methods. We further show that all attack vectors implemented by the exploits belong to one of three categories: single-step attacks, restricted-class attacks, and information hiding attacks. The analysis allows us to propose ideas for improving the security architecture to spawn further research in this area.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 2016 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Holzinger, Philipp and Triller, Stefan and Bartel, Alexandre and Bodden, Eric},
	year = {2016},
	keywords = {unsafe, access control, exploits, java security, security analysis},
	pages = {779--790},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/VDLLXUBH/Holzinger et al. - 2016 - An In-Depth Study of More Than Ten Years of Java E.pdf:application/pdf}
}

@inproceedings{reboucas_empirical_2016,
	title = {An {Empirical} {Study} on the {Usage} of the {Swift} {Programming} {Language}},
	volume = {1},
	doi = {10.1109/SANER.2016.66},
	abstract = {Recently, Apple released Swift, a modern programming language built to be the successor of Objective-C. In less than a year and a half after its first release, Swift became one of the most popular programming languages in the world, considering different popularity measures. A significant part of this success is due to Apple's strict control over its ecosystem, and the clear message that it will replace Objective-C in a near future. According to Apple, "Swift is a powerful and intuitive programming language[...]. Writing Swift code is interactive and fun, the syntax is concise yet expressive." However, little is known about how Swift developers perceive these benefits. In this paper, we conducted two studies aimed at uncovering the questions and strains that arise from this early adoption. First, we perform a thorough analysis on 59,156 questions asked about Swift on StackOverflow. Second, we interviewed 12 Swift developers to cross-validate the initial results. Our study reveals that developers do seem to find the language easy to understand and adopt, although 17.5\% of the questions are about basic elements of the language. Still, there are many questions about problems in the toolset (compiler, Xcode, libraries). Some of our interviewees reinforced these problems.},
	booktitle = {2016 {IEEE} 23rd {International} {Conference} on {Software} {Analysis}, {Evolution}, and {Reengineering} ({SANER})},
	author = {Rebou{\c c}as, M. and Pinto, G. and Ebert, F. and Torres, W. and Serebrenik, A. and Castor, F.},
	month = mar,
	year = {2016},
	keywords = {computational linguistics, Computer languages, Libraries, Programming, Software, programming languages, unsafe, Testing, compiler, Interviews, libraries, StackOverflow, Standards, Swift developers, Swift programming languages, Xcode},
	pages = {634--638},
	file = {IEEE Xplore Abstract Record:/Volumes/Data/work/zotero/storage/JY8EQ5RC/7476687.html:text/html;IEEE Xplore Full Text PDF:/Volumes/Data/work/zotero/storage/8WTKH9YQ/Rebou{\c c}as et al. - 2016 - An Empirical Study on the Usage of the Swift Progr.pdf:application/pdf}
}

@inproceedings{zhang_accepting_2016,
	address = {New York, NY, USA},
	series = {{PLDI} '16},
	title = {Accepting {Blame} for {Safe} {Tunneled} {Exceptions}},
	isbn = {978-1-4503-4261-2},
	url = {http://doi.acm.org/10.1145/2908080.2908086},
	doi = {10.1145/2908080.2908086},
	abstract = {Unhandled exceptions crash programs, so a compile-time check that exceptions are handled should in principle make software more reliable. But designers of some recent languages have argued that the benefits of statically checked exceptions are not worth the costs. We introduce a new statically checked exception mechanism that addresses the problems with existing checked-exception mechanisms. In particular, it interacts well with higher-order functions and other design patterns. The key insight is that whether an exception should be treated as a "checked" exception is not a property of its type but rather of the context in which the exception propagates. Statically checked exceptions can "tunnel" through code that is oblivious to their presence, but the type system nevertheless checks that these exceptions are handled. Further, exceptions can be tunneled without being accidentally caught, by expanding the space of exception identifiers to identify the exception-handling context. The resulting mechanism is expressive and syntactically light, and can be implemented efficiently. We demonstrate the expressiveness of the mechanism using significant codebases and evaluate its performance. We have implemented this new exception mechanism as part of the new Genus programming language, but the mechanism could equally well be applied to other programming languages.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Zhang, Yizhou and Salvaneschi, Guido and Beightol, Quinn and Liskov, Barbara and Myers, Andrew C.},
	year = {2016},
	keywords = {exception handling, unsafe, Exception tunneling, Genus},
	pages = {281--295},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/JQTY67XV/Zhang et al. - 2016 - Accepting Blame for Safe Tunneled Exceptions.pdf:application/pdf}
}

@inproceedings{jiang_unsupervised_2017,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '17},
	title = {An {Unsupervised} {Approach} for {Discovering} {Relevant} {Tutorial} {Fragments} for {APIs}},
	isbn = {978-1-5386-3868-2},
	url = {https://doi.org/10.1109/ICSE.2017.12},
	doi = {10.1109/ICSE.2017.12},
	abstract = {Developers increasingly rely on API tutorials to facilitate software development. However, it remains a challenging task for them to discover relevant API tutorial fragments explaining unfamiliar APIs. Existing supervised approaches suffer from the heavy burden of manually preparing corpus-specific annotated data and features. In this study, we propose a novel unsupervised approach, namely {\textless}u{\textgreater}F{\textless}/u{\textgreater}ragment {\textless}u{\textgreater}R{\textless}/u{\textgreater}ecommender for {\textless}u{\textgreater}A{\textless}/u{\textgreater}PIs with {\textless}u{\textgreater}P{\textless}/u{\textgreater}ageRank and {\textless}u{\textgreater}T{\textless}/u{\textgreater}opic model (FRAPT). FRAPT can well address two main challenges lying in the task and effectively determine relevant tutorial fragments for APIs. In FRAPT, a Fragment Parser is proposed to identify APIs in tutorial fragments and replace ambiguous pronouns and variables with related ontologies and API names, so as to address the pronoun and variable resolution challenge. Then, a Fragment Filter employs a set of non-explanatory detection rules to remove non-explanatory fragments, thus address the non-explanatory fragment identification challenge. Finally, two correlation scores are achieved and aggregated to determine relevant fragments for APIs, by applying both topic model and PageRank algorithm to the retained fragments. Extensive experiments over two publicly open tutorial corpora show that, FRAPT improves the state-of-the-art approach by 8.77\% and 12.32\% respectively in terms of F-Measure. The effectiveness of key components of FRAPT is also validated.},
	urldate = {2017-11-11},
	booktitle = {Proceedings of the 39th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Jiang, He and Zhang, Jingxuan and Ren, Zhilei and Zhang, Tao},
	year = {2017},
	keywords = {application programming interface, unsafe, pagerank algorithm, topic model, unsupervised approaches},
	pages = {38--48},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/DK8GYWNG/Jiang et al. - 2017 - An Unsupervised Approach for Discovering Relevant .pdf:application/pdf}
}

@article{staicu_understanding_2017,
	title = {Understanding and {Automatically} {Preventing} {Injection} {Attacks} on {Node}.js},
	url = {https://www.microsoft.com/en-us/research/publication/understanding-automatically-preventing-injection-attacks-node-js/},
	abstract = {The NODE.JS ecosystem has lead to the creation of many modern applications, such as server-side web applications and desktop applications. Unlike client-side JavaScript code, NODE.JS applications can interact freely with the operating system without the benefits of a security sandbox. The complex interplay between NODE.JS modules leads to subtle injection vulnerabilities being introduced across module {\textellipsis}},
	urldate = {2017-11-11},
	journal = {Microsoft Research},
	author = {Staicu, Cristian-Alexandru and Pradel, Michael and Livshits, Ben},
	month = jan,
	year = {2017},
	keywords = {unsafe},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/GLMVIEMT/Staicu et al. - 2017 - Understanding and Automatically Preventing Injecti.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/JFUQJN4L/understanding-automatically-preventing-injection-attacks-node-js.html:text/html}
}

@article{diaconescu_logical_2002,
	series = {Rewriting {Logic} and its {Applications}},
	title = {Logical foundations of {CafeOBJ}},
	volume = {285},
	issn = {0304-3975},
	url = {http://www.sciencedirect.com/science/article/pii/S0304397501003619},
	doi = {10.1016/S0304-3975(01)00361-9},
	abstract = {This paper surveys the logical and mathematical foundations of CafeOBJ, which is a successor of the famous algebraic specification language OBJ but adds to it several new primitive paradigms such as behavioural concurrent specification and rewriting logic. We first give a concise overview of CafeOBJ. Then we focus on the actual logical foundations of the language at two different levels: basic specification and structured specification, including also the definition of the CafeOBJ institution. We survey some novel or more classical theoretical concepts supporting the logical foundations of CafeOBJ, pointing out the main results but without giving proofs and without discussing all mathematical details. Novel theoretical concepts include the coherent hidden algebra formalism and its combination with rewriting logic, and Grothendieck (or fibred) institutions. However, for proofs and for some of the mathematical details not discussed here we give pointers to relevant publications. The logical foundations of CafeOBJ are structured by the concept of institution. Moreover, the design of CafeOBJ emerged from its logical foundations, and institution concepts played a crucial r{\^o}le in structuring the language design.},
	number = {2},
	urldate = {2017-11-12},
	journal = {Theoretical Computer Science},
	author = {Diaconescu, R{\u a}zvan and Futatsugi, Kokichi},
	month = aug,
	year = {2002},
	keywords = {Algebraic specification, Behavioural specification, Institutions},
	pages = {289--318},
	file = {ScienceDirect Full Text PDF:/Volumes/Data/work/zotero/storage/57XXM964/Diaconescu and Futatsugi - 2002 - Logical foundations of CafeOBJ.pdf:application/pdf;ScienceDirect Snapshot:/Volumes/Data/work/zotero/storage/DZSU2EG9/S0304397501003619.html:text/html}
}

@article{fruhwirth_theory_1998,
	title = {Theory and practice of constraint handling rules},
	volume = {37},
	issn = {0743-1066},
	url = {http://www.sciencedirect.com/science/article/pii/S0743106698100055},
	doi = {10.1016/S0743-1066(98)10005-5},
	abstract = {Constraint Handling Rules (CHR) are our proposal to allow more flexibility and application-oriented customization of constraint systems. CHR are a declarative language extension especially designed for writing user-defined constraints. CHR are essentially a committed-choice language consisting of multi-headed guarded rules that rewrite constraints into simpler ones until they are solved. In this broad survey we aim at covering all aspects of CHR as they currently present themselves. Going from theory to practice, we will define syntax and semantics for CHR, introduce an important decidable property, confluence, of CHR programs and define a tight integration of CHR with constraint logic programming languages. This survey then describes implementations of the language before we review several constraint solvers {\textendash} both traditional and nonstandard ones {\textendash} written in the CHR language. Finally we introduce two innovative applications that benefited from using CHR.},
	number = {1},
	urldate = {2017-11-12},
	journal = {The Journal of Logic Programming},
	author = {Fr{\"u}hwirth, Thom},
	month = oct,
	year = {1998},
	pages = {95--138},
	file = {ScienceDirect Full Text PDF:/Volumes/Data/work/zotero/storage/UCH4KIFM/Fr{\"u}hwirth - 1998 - Theory and practice of constraint handling rules.pdf:application/pdf;ScienceDirect Snapshot:/Volumes/Data/work/zotero/storage/U72YJZ6F/S0743106698100055.html:text/html}
}

@book{gluck_roadmap_1996,
	title = {A {Roadmap} to {Metacomputation} by {Supercompilation}},
	abstract = {This paper gives a gentle introduction to Turchin's supercompilation and its applications in metacomputation with an emphasis on recent developments. First, a complete supercompiler, including positive driving and generalization, is defined for a functional language and illustrated with examples. Then a taxonomy of related transformers is given and compared to the supercompiler. Finally, we put supercompilation into the larger perspective of metacomputation and consider three metacomputation tasks: specialization, composition, and inversion.},
	author = {Gl{\"u}ck, Robert and S{\o}rensen, Morten Heine},
	year = {1996},
	file = {Citeseer - Full Text PDF:/Volumes/Data/work/zotero/storage/G53PFBYS/Gl{\"u}ck and S{\o}rensen - 1996 - A Roadmap to Metacomputation by Supercompilation.pdf:application/pdf;Citeseer - Snapshot:/Volumes/Data/work/zotero/storage/EPQP6QQF/summary.html:text/html}
}

@inproceedings{coutts_stream_2007,
	address = {New York, NY, USA},
	series = {{ICFP} '07},
	title = {Stream {Fusion}: {From} {Lists} to {Streams} to {Nothing} at {All}},
	isbn = {978-1-59593-815-2},
	shorttitle = {Stream {Fusion}},
	url = {http://doi.acm.org/10.1145/1291151.1291199},
	doi = {10.1145/1291151.1291199},
	abstract = {This paper presents an automatic deforestation system, stream fusion, based on equational transformations, that fuses a wider range of functions than existing short-cut fusion systems. In particular, stream fusion is able to fuse zips, left folds and functions over nested lists, including list comprehensions. A distinguishing feature of the framework is its simplicity: by transforming list functions to expose their structure, intermediate values are eliminated by general purpose compiler optimisations. We have reimplemented the Haskell standard List library on top of our framework, providing stream fusion for Haskell lists. By allowing a wider range of functions to fuse, we see an increase in the number of occurrences of fusion in typical Haskell programs. We present benchmarks documenting time and space improvements.},
	urldate = {2017-11-12},
	booktitle = {Proceedings of the 12th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
	year = {2007},
	keywords = {program transformation, functional programming, deforestation, program fusion, program optimisation},
	pages = {315--326},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/NRDHG6ZW/Coutts et al. - 2007 - Stream Fusion From Lists to Streams to Nothing at.pdf:application/pdf}
}

@inproceedings{altenkirch_why_2005,
	title = {Why {Dependent} {Types} {Matter}},
	abstract = {We exhibit the rationale behind the design of Epigram, a dependently typed programming language and interactive program development system, using refinements of a well known program{\textemdash}merge sort{\textemdash}as a running example. We discuss its relationship with other proposals to introduce aspects of dependent types into functional programming languages and sketch some topics for further work in this area. 1.},
	booktitle = {In preparation, http://www.e-pig.org/downloads/ydtm.pdf},
	author = {Altenkirch, Thorsten and Mcbride, Conor and Mckinna, James},
	year = {2005},
	file = {Citeseer - Full Text PDF:/Volumes/Data/work/zotero/storage/F7Z66P8B/Altenkirch et al. - 2005 - Why dependent types matter.pdf:application/pdf;Citeseer - Snapshot:/Volumes/Data/work/zotero/storage/Y4KDBFCK/summary.html:text/html}
}

@inproceedings{yang_survey_2006,
	address = {New York, NY, USA},
	series = {{AST} '06},
	title = {A {Survey} of {Coverage} {Based} {Testing} {Tools}},
	isbn = {978-1-59593-408-6},
	url = {http://doi.acm.org/10.1145/1138929.1138949},
	doi = {10.1145/1138929.1138949},
	abstract = {Test coverage is sometimes used as a way to measure how thoroughly software is tested. Coverage is used by software developers and sometimes by vendors to indicate their confidence in the readiness of their software. This survey studies and compares 17 coverage-based testing tools focusing on, but not restricted to coverage measurement. We also survey additional features, including program prioritization for testing, assistance in debugging, automatic generation of test cases, and customization of test reports. Such features make tools more useful and practical, especially for large-scale, real-life commercial software applications. Our initial motivations were both to understand the available test coverage tools and to compare them to a tool that we have developed, called eXVantage1 (a tool suite that includes code coverage testing, debugging, performance profiling, and reporting). Our study shows that each tool has its unique features tailored to its application domains. Therefore this study can be used to pick the right coverage testing tools depending on various requirements.},
	urldate = {2017-11-12},
	booktitle = {Proceedings of the 2006 {International} {Workshop} on {Automation} of {Software} {Test}},
	publisher = {ACM},
	author = {Yang, Qian and Li, J. Jenny and Weiss, David},
	year = {2006},
	keywords = {automate test case generation, code coverage, coverage-based testing tool, dominator analysis, eXVantage, prioritization},
	pages = {99--103},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/NQXDWMNJ/Yang et al. - 2006 - A Survey of Coverage Based Testing Tools.pdf:application/pdf}
}

@inproceedings{madsen_string_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {String {Analysis} for {Dynamic} {Field} {Access}},
	isbn = {978-3-642-54806-2 978-3-642-54807-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-54807-9_12},
	doi = {10.1007/978-3-642-54807-9_12},
	abstract = {In JavaScript, and scripting languages in general, dynamic field access is a commonly used feature. Unfortunately, current static analysis tools either completely ignore dynamic field access or use overly conservative approximations that lead to poor precision and scalability.We present new string domains to reason about dynamic field access in a static analysis tool. A key feature of the domains is that the equal, concatenate and join operations take ?O{\textbackslash}mathcal\{O\}(1) time.Experimental evaluation on four common JavaScript libraries, including jQuery and Prototype, shows that traditional string domains are insufficient. For instance, the commonly used constant string domain can only ensure that at most 21\% dynamic field accesses are without false positives. In contrast, our string domain ?H{\textbackslash}mathcal\{H\} ensures no false positives for up to 90\% of all dynamic field accesses.We demonstrate that a dataflow analysis equipped with the ?H{\textbackslash}mathcal\{H\} domain gains significant precision resulting in an analysis speedup of more than 1.5x for 7 out of 10 benchmark programs.},
	language = {en},
	urldate = {2017-11-12},
	booktitle = {Compiler {Construction}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Madsen, Magnus and Andreasen, Esben},
	month = apr,
	year = {2014},
	pages = {197--217},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/I28CW7EC/Madsen and Andreasen - 2014 - String Analysis for Dynamic Field Access.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/LT2L58YF/978-3-642-54807-9_12.html:text/html}
}

@inproceedings{blackburn_dacapo_2006,
	address = {New York, NY, USA},
	series = {{OOPSLA} '06},
	title = {The {DaCapo} {Benchmarks}: {Java} {Benchmarking} {Development} and {Analysis}},
	isbn = {978-1-59593-348-5},
	shorttitle = {The {DaCapo} {Benchmarks}},
	url = {http://doi.acm.org/10.1145/1167473.1167488},
	doi = {10.1145/1167473.1167488},
	abstract = {Since benchmarks drive computer science research and industry product development, which ones we use and how we evaluate them are key questions for the community. Despite complex runtime tradeoffs due to dynamic compilation and garbage collection required for Java programs, many evaluations still use methodologies developed for C, C++, and Fortran. SPEC, the dominant purveyor of benchmarks, compounded this problem by institutionalizing these methodologies for their Java benchmark suite. This paper recommends benchmarking selection and evaluation methodologies, and introduces the DaCapo benchmarks, a set of open source, client-side Java benchmarks. We demonstrate that the complex interactions of (1) architecture, (2) compiler, (3) virtual machine, (4) memory management, and (5) application require more extensive evaluation than C, C++, and Fortran which stress (4) much less, and do not require (3). We use and introduce new value, time-series, and statistical metrics for static and dynamic properties such as code complexity, code size, heap composition, and pointer mutations. No benchmark suite is definitive, but these metrics show that DaCapo improves over SPEC Java in a variety of ways, including more complex code, richer object behaviors, and more demanding memory system requirements. This paper takes a step towards improving methodologies for choosing and evaluating benchmarks to foster innovation in system design and implementation for Java and other managed languages.},
	urldate = {2017-11-12},
	booktitle = {Proceedings of the 21st {Annual} {ACM} {SIGPLAN} {Conference} on {Object}-oriented {Programming} {Systems}, {Languages}, and {Applications}},
	publisher = {ACM},
	author = {Blackburn, Stephen M. and Garner, Robin and Hoffmann, Chris and Khang, Asjad M. and McKinley, Kathryn S. and Bentzur, Rotem and Diwan, Amer and Feinberg, Daniel and Frampton, Daniel and Guyer, Samuel Z. and Hirzel, Martin and Hosking, Antony and Jump, Maria and Lee, Han and Moss, J. Eliot B. and Phansalkar, Aashish and Stefanovi{\'c}, Darko and VanDrunen, Thomas and von Dincklage, Daniel and Wiedermann, Ben},
	year = {2006},
	keywords = {Java, benchmark, DaCapo, methodology, SPEC},
	pages = {169--190},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/GCUIDM8X/Blackburn et al. - 2006 - The DaCapo Benchmarks Java Benchmarking Developme.pdf:application/pdf}
}

@article{brady_hints_1977,
	title = {Hints on proofs by recursion induction},
	volume = {20},
	issn = {0010-4620},
	url = {https://academic.oup.com/comjnl/article/20/4/353/393896},
	doi = {10.1093/comjnl/20.4.353},
	abstract = {In 1963 John McCarthy proposed a formalism based on conditional expression and recursion for use in the emergent theory of computation. Included in his proposals was a proof technique, known as recursive induction, which could be used to establish the equivalence of recursively defined functions. This paper shows that the discovery of an equations to serve in a proof by recursive induction does not have to rely on luck or inspiration, but can be developed rationally hand in hand with the development of the proof.},
	number = {4},
	urldate = {2017-11-12},
	journal = {The Computer Journal},
	author = {Brady, J. M.},
	month = jan,
	year = {1977},
	pages = {353--355},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/CZ7CGRRC/Brady - 1977 - Hints on proofs by recursion induction.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/7KNADDWH/Hints-on-proofs-by-recursion-induction.html:text/html}
}

@inproceedings{jhala_structural_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Structural {Invariants}},
	isbn = {978-3-540-37756-6 978-3-540-37758-0},
	url = {https://link.springer.com/chapter/10.1007/11823230_6},
	doi = {10.1007/11823230_6},
	abstract = {We present structural invariants (SI), a new technique for incrementally overapproximating the verification condition of a program in static single assignment form by making a linear pass over the dominator tree of the program. The 1-level SI at a program location is the conjunction of all dominating program statements viewed as constraints. For any k, we define a k-level SI by recursively strengthening the dominating join points of the 1-level SI with the (k {\textendash} 1)-level SI of the predecessors of the join point, thereby providing a tunable selector to add path-sensitivity incrementally. By ignoring program paths, the size of the SI and correspondingly the time to discharge the validity query remains small, allowing the technique to scale to large programs. We show experimentally that even with k <=2, for a set of open-source programs totaling 570K lines and properties for which specialized analyses have been previously devised, our method provides an automatic and scalable algorithm with a low false positive rate.},
	language = {en},
	urldate = {2017-11-12},
	booktitle = {Static {Analysis}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Jhala, Ranjit and Majumdar, Rupak and Xu, Ru-Gang},
	month = aug,
	year = {2006},
	pages = {71--87},
	file = {Full Text PDF:/Volumes/Data/work/zotero/storage/HZ9JIP9B/Jhala et al. - 2006 - Structural Invariants.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/IQKXKB4E/11823230_6.html:text/html}
}

@article{lamport_state_1978,
	title = {State the {Problem} {Before} {Describing} the {Solution}},
	volume = {3},
	issn = {0163-5948},
	url = {http://doi.acm.org/10.1145/1010734.1010737},
	doi = {10.1145/1010734.1010737},
	number = {1},
	urldate = {2017-11-12},
	journal = {SIGSOFT Softw. Eng. Notes},
	author = {Lamport, Leslie},
	month = jan,
	year = {1978},
	pages = {26--26},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/5D2JKFWN/Lamport - 1978 - State the Problem Before Describing the Solution.pdf:application/pdf}
}

@inproceedings{weiser_program_1981,
	address = {Piscataway, NJ, USA},
	series = {{ICSE} '81},
	title = {Program {Slicing}},
	isbn = {978-0-89791-146-7},
	url = {http://dl.acm.org/citation.cfm?id=800078.802557},
	abstract = {Program slicing is a method used by experienced computer programmers for abstracting from programs. Starting from a subset of a program's behavior, slicing reduces that program to a minimal form which still produces that behavior. The reduced program, called a {\textquotedblleft}slice{\textquotedblright}, is an independent program guaranteed to faithfully represent the original program within the domain of the specified subset of behavior. Finding a slice is in general unsolvable. A dataflow algorithm is presented for approximating slices when the behavior subset is specified as the values of a set of variables at a statement. Experimental evidence is presented that these slices are used by programmers during debugging. Experience with two automatic slicing tools is summarized. New measures of program complexity are suggested based on the organization of a program's slices.},
	urldate = {2017-11-12},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Software} {Engineering}},
	publisher = {IEEE Press},
	author = {Weiser, Mark},
	year = {1981},
	keywords = {Debugging, Data flow analysis, Human factors, Program maintenance, Program metrics, Software tools},
	pages = {439--449},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/YY44SUIU/Weiser - 1981 - Program Slicing.pdf:application/pdf}
}

@article{tip_survey_1995,
	title = {A {Survey} of {Program} {Slicing} {Techniques}},
	volume = {3},
	abstract = {A program slice consists of the parts of a program that (potentially) affect the  values computed at some point of interest, referred to as a slicing criterion. The task  of computing program slices is called program slicing. The original definition of a  program slice was presented by Weiser in 1979. Since then, various slightly different  notions of program slices have been proposed, as well as a number of methods to  compute them. An important distinction is that between a static and a dynamic slice.  The former notion is computed without making assumptions regarding a program's  input, whereas the latter relies on some specific test case.  Procedures, arbitrary control flow, composite datatypes and pointers, and interprocess  communication each require a specific solution. We classify static and dynamic  slicing methods for each of these features, and compare their accuracy and efficiency.  Moreover, the possibilities for combining solutions for different features are investigated....},
	journal = {Journal of Programming Languages},
	author = {Tip, F.},
	year = {1995},
	pages = {121--189},
	file = {Citeseer - Full Text PDF:/Volumes/Data/work/zotero/storage/D9S2386I/Tip - 1995 - A Survey of Program Slicing Techniques.pdf:application/pdf;Citeseer - Snapshot:/Volumes/Data/work/zotero/storage/E8HSKQXM/summary.html:text/html}
}

@inproceedings{hu_dynamic_2008,
	title = {Dynamic {Analysis} and {Design} {Pattern} {Detection} in {Java} {Programs}.},
	abstract = {Identifying design patterns within an existing software system can support understandability and reuse of the system's core functionality. In this context, incorporating behavioral features into the design pattern recovery would enhance the scalability of the process. The main advantage of the new approach in this paper over the existing approaches is incorporating dynamic analysis and feature localization in source code. This allows us to perform a goal-driven design pattern detection and focus ourselves on patterns that implement specific software functionality, as opposed to conducting a general pattern detection which is susceptible to high complexity problem. Using a new pattern description language and a matching process we identify the instances of these patterns within the obtained classes and interactions. We use a two-phase matching process: i) an approximate matching of class attributes generates a list of candidate patterns; and ii) a structural matching of classes identifies exact matched patterns. One target application domain can be software product line which emphasizes on reusing core software artifacts to construct a reference architecture for several similar products. Finally, we present the result of a case study.},
	booktitle = {20th {International} {Conference} on {Software} {Engineering} and {Knowledge} {Engineering}, {SEKE} 2008},
	author = {Hu, Lei and Sartipi, Kamran},
	month = jan,
	year = {2008},
	pages = {842--846},
	file = {Citeseer - Full Text PDF:/Volumes/Data/work/zotero/storage/J7BRZ7SC/Hu and Sartipi - Dynamic Analysis and Design Pattern Detection in J.pdf:application/pdf;Snapshot:/Volumes/Data/work/zotero/storage/3UVHHRUH/221391328_Dynamic_Analysis_and_Design_Pattern_Detection_in_Java_Programs.html:text/html}
}

@inproceedings{arcelli_design_2008,
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Design {Pattern} {Detection} in {Java} {Systems}: {A} {Dynamic} {Analysis} {Based} {Approach}},
	isbn = {978-3-642-14818-7 978-3-642-14819-4},
	shorttitle = {Design {Pattern} {Detection} in {Java} {Systems}},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-14819-4_12},
	doi = {10.1007/978-3-642-14819-4_12},
	abstract = {In the context of reverse engineering, the recognition of design patterns provides additional information related to the rationale behind the design. This paper presents our approach to the recognition of the behavioral design patterns based on dynamic analysis of Java software systems. The idea behind our solution is to identify a set of rules capturing information necessary to identify a design pattern instance. Rules are characterized by weights indicating their importance in the detection of a specific design pattern. The core behavior of each design pattern may be described through a subset of these rules forming a macrorule. Macrorules define the main traits of a pattern. JADEPT (JAva DEsign Pattern deTector) is our software for design pattern identification based on this idea. It captures static and dynamic aspects through a dynamic analysis of the software by exploiting the JPDA (Java Platform Debugger Architecture). The extracted information is stored in a database. Queries to the database implement the rules defined to recognize the design patterns. The tool has been validated with positive results on different implementations of design patterns and on systems such as JADEPT itself.},
	language = {en},
	urldate = {2017-11-12},
	booktitle = {Evaluation of {Novel} {Approaches} to {Software} {Engineering}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Arcelli, Francesca and Perin, Fabrizio and Raibulet, Claudia and Ravani, Stefano},
	month = may,
	year = {2008},
	pages = {163--179},
	file = {Snapshot:/Volumes/Data/work/zotero/storage/KS9GYNA3/978-3-642-14819-4_12.html:text/html}
}

@inproceedings{jang_empirical_2010,
	address = {New York, NY, USA},
	series = {{CCS} '10},
	title = {An {Empirical} {Study} of {Privacy}-violating {Information} {Flows} in {JavaScript} {Web} {Applications}},
	isbn = {978-1-4503-0245-6},
	url = {http://doi.acm.org/10.1145/1866307.1866339},
	doi = {10.1145/1866307.1866339},
	abstract = {The dynamic nature of JavaScript web applications has given rise to the possibility of privacy violating information flows. We present an empirical study of the prevalence of such flows on a large number of popular websites. We have (1) designed an expressive, fine-grained information flow policy language that allows us to specify and detect different kinds of privacy-violating flows in JavaScript code,(2) implemented a new rewriting-based JavaScript information flow engine within the Chrome browser, and (3) used the enhanced browser to conduct a large-scale empirical study over the Alexa global top 50,000 websites of four privacy-violating flows: cookie stealing, location hijacking, history sniffing, and behavior tracking. Our survey shows that several popular sites, including Alexa global top-100 sites, use privacy-violating flows to exfiltrate information about users' browsing behavior. Our findings show that steps must be taken to mitigate the privacy threat from covert flows in browsers.},
	urldate = {2017-11-13},
	booktitle = {Proceedings of the 17th {ACM} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Jang, Dongseok and Jhala, Ranjit and Lerner, Sorin and Shacham, Hovav},
	year = {2010},
	keywords = {dynamic analysis, history sniffing, information flow, JavaScript, privacy, rewriting, web application, web security},
	pages = {270--283},
	file = {ACM Full Text PDF:/Volumes/Data/work/zotero/storage/G2QBZDRK/Jang et al. - 2010 - An Empirical Study of Privacy-violating Informatio.pdf:application/pdf}
}