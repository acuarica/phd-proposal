
#+STARTUP: logdrawer
#+TODO: TODO(t) DRAFT(f@/!) IN-THE-BOOK(i!) | DONE(d!) CANCELED(c)

#+BEGIN_SRC emacs-lisp :results silent :exports none
  (setq org-latex-pdf-process
      '("latexmk -pdflatex='pdflatex -interaction nonstopmode -synctex=1' -pdf -bibtex -f %f"))

      (add-to-list 'org-latex-classes
               '("usiinfdocprop"
                  "\\documentclass{usiinfdocprop}
                  [NO-DEFAULT-PACKAGES]
                  [EXTRA]"
                  ("\\chapter{%s}" . "\\chapter*{%s}")
                  ("\\section{%s}" . "\\section*{%s}")
                  ("\\subsection{%s}" . "\\subsection*{%s}")
                  ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
                  ("\\paragraph{%s}" . "\\paragraph*{%s}")
                  ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
    (setq org-latex-listings t)
#+END_SRC

#+TITLE: What Do We Write?
#+LATEX_CLASS: usiinfdocprop
#+LATEX_HEADER: \subtitle{Discovering Unexpected Language Features Usages at Large-Scale by Empirical-based Patterns}
#+AUTHOR: Luis Mastrangelo
#+LATEX_HEADER: \include{prelude}
#+OPTIONS: toc:nil
#+OPTIONS: todo:nil
#+OPTIONS: tags:nil

\frontmatter
#+TOC: headlines 1
\mainmatter

* DRAFT Introduction                                               :patterns:
:LOGBOOK:
- State "DRAFT"      from "DRAFT"      [2017-12-13 Wed 15:54] \\
  Added patterns tag
- State "DRAFT"      from "DRAFT"      [2017-12-10 Sun 21:52] \\
  Prev \subtitle{Understanding How Developers Make Use of Language Features at Large-scale by Empirical-based Patterns}
- State "DRAFT"      from "IN-THE-BOOK" [2017-12-04 Mon 16:59] \\
  Come back to draft
- State "IN-THE-BOOK" from "DRAFT"      [2017-12-04 Mon 16:07]
- State "DRAFT"      from "TODO"       [2017-12-04 Mon 16:07] \\
  Begining importing from old proposal
:END:

Programming language design has been always a hot topic in computer science literature.
It has been extensively studied in the past decades.
For instance, there is a trend in incorporating functional programming features into mainstream object-oriented languages, \eg, lambdas in \java{} 8[fn::https://docs.oracle.com/javase/specs/jls/se8/html/jls-15.html#jls-15.27], \cpp{}11[fn::http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n1968.pdf] and \cs{} 3.0[fn::https://msdn.microsoft.com/en-us/library/bb308966.aspx#csharp3.0overview_topic7]; or parametric polymorphism --- \ie{}, generics --- in \java{} 5[fn::https://docs.oracle.com/javase/1.5.0/docs/guide/language/generics.html]$^{,}$[fn::http://www.oracle.com/technetwork/java/javase/generics-tutorial-159168.pdf].

Adding new features to a language should --- /in theory/ --- increase programmers productivity.
But once a language feature is released, little is known about how it is actually used by the developer community.
Therefore, it is extremely difficult to assess how features in a programming language impact on programmers productivity.
We argue that this information is of great value, because can give many insights to drive the future of any programming language.

On the other hand, cite:hanenberg_faith_2010,hanenberg_why_2014 argue that human behavior, \ie{}, controlled experiments, should be applied to programming language usage and design.
With this approach, it should be possible --- in principle --- to understand to what degree a language feature impacts on programming productivity.
However, for any kind of controlled experiment to be valid, it must reflect reality.
Otherwise, any conjecture derived from a controlled experiment can be considered truthful but useless.

Finally, understanding what developers write is not only useful in the field of language design and controlled experiments.
For instance, cite:livshits_defense_2015 argue that most software analysis tools exclude certain dynamic features, \eg{}, reflection, \setjmp{}/\longjmp{}, \jni [fn::https://docs.oracle.com/javase/8/docs/technotes/guides/jni/spec/jniTOC.html], \eval{}, \etc{}, from their analyses.
They claim that in order to understand how the limits of analysis tools impact software, we also need to understand what kind of code is being written in the real world.

Looking at the aforementioned examples, cite:mazinanian_understanding_2017 and cite:uesbeck_empirical_2016 studied how developers use lambdas in \java{} and \cpp{} respectively; while cite:parnin_java_2011,parnin_adoption_2013 did the same for generics in \java{}.
This kind of studies give an insight of the adoption of lambdas and generics; which can drive future direction for language designers and tool builders, while providing developers with best practices.

** DRAFT Research Question
:LOGBOOK:
- State "DRAFT"      from "DRAFT"      [2017-12-10 Sun 18:25] \\
  Prev RQ: How --- and why --- statically-typed languages constraints circumvent the static type system?
- State "DRAFT"      from "TODO"       [2017-12-10 Sun 17:56] \\
  Changing RQ
:END:

Understanding how language features are used can give many insights to language designers, tools builders, researchers and developers.
This triggers our research question:

#+BEGIN_EXPORT latex
\rquestion{Are there \emph{unexpected usages of language features} in-the-wild that can give new insights to language designers, tools builders, researchers and developers?}
#+END_EXPORT

We believe that we --- as a research community --- should understand what kinds of programs are written in real codebases.
We can use this information to improve several aspects of the software development process and supporting informed decisions for the driving forces mentioned above.
This fact opens the door for empirical studies about language features, and their use in source code repositories, \eg{}, \github{}, \gitlab{} or \bitbucket{}, and package managers repositories, \eg{}, \mavencentral [fn::http:/central.sonatype.org/] or \npm [fn::https://www.npmjs.com/]. 
Since any kind of language study must be language-specific, our plan is to focus on \java{} given its wide usage and relevance for both research and industry.

In this proposal, we plan to target four specific \java{} features, namely, /casting/, /reflection/, /exception handling/, and the /unsafe \api{}/.
We have divised --- for the /unsafe \api{}/ --- and we plan to divise language and \api{} usage patterns.
We believe that having usage patterns can help us to better categorize features and thus understanding how the feature is actually used.

** DRAFT Proposal Outline
:LOGBOOK:
- State "DRAFT"      from "TODO"       [2017-12-19 Tue 16:38] \\
  Old start: Understanding what programmers write is a broad topic involving several sub-fields. To cover what has been already done,
:END:

The rest of this proposal is organized as follows:
Chapter\nbsp{}[[cha:literature-review]] gives a review of the literature in the /state-of-the-art/ of the different aspects related to our goal.
More specifically, Chapter\nbsp{}[[cha:patterns]] presents already existing code patterns related to the language features we plan to analyze.
The following four chapters introduce our proposal plan for the selected features:
Chapters\nbsp{}[[cha:casts]], [[cha:reflection]], [[cha:exceptions]] presents our /casting/, /reflection/ and /exception handling/ study respectively.
Finally, Chapter\nbsp{}[[cha:unsafe]] shows the study we already made on the unsafe \api{} in \java{}.

While the literature review gives a broad overview in the field, each of the following chapters have their own ``Related Work'' section. 
The rationale behind this organization is that we prefer to show how we improve over the /state-of-the-art/ after having presented our plan for each feature.

# Understanding the Use of Language Features in Java.
# To understand patterns.Mining language features thesis.
# Research Question: Is Java Safe?
# Methodological Contribution, to evolve your language.
# Motivate the umbrella that put together those 3 pillars.
# In our research proposal we investigate the feasibility of

* DRAFT Introduction                                                 :noexport:
:LOGBOOK:
- State "DRAFT"      from "DRAFT"      [2017-12-14 Thu 20:13] \\
  Disco
- State "DRAFT"      from "TODO"       [2017-12-13 Wed 15:55] \\
  New headline for safety/unsafe
:END:

Static type systems were added to improve programmers productivity.
But --- given the growing complexity of applications --- sometimes developers need to circumvent the \static\ type systems to satisfy todays systems needs.
Usually --- but not neccesarly --- those needs are related to the dynamic features of a language.

Thus we believe that by understanding how developers use these dynamic or extra features we can regain safety in the language.

We argue that using or abusing reflection can lead to less efficient software.
Some languages use reflection in a unsafe way

Study what are the implications of using reflection.

When using a cast can 

* DRAFT Literature Review <<cha:literature-review>> :patterns:
:LOGBOOK:
- State "DRAFT"      from              [2017-12-10 Sun 17:33] \\
  let's start
:END:

Understanding how language features and \api{}s are being used is a broad topic.
There is plenty of research in computer science literature about empirical studies of programs; which involves several directions directly or indirecly related.
Along the last decades, researchers always has been interested in understanding what kind of programs programmers write.
The motivation behind these studies is quite broad and --- together with the evolution of computer science itself --- has shifted to the needs of researchers.

The organization of this chapter is as follows:
In \S{}[[sec:compilers-writers]] we present empirical studies regarding compilers writers.
How benchmarks and corpuses relate to this kind of studies is presented in \S{}[[sec:benchmarks]].
\S[[sec:large-scale]] gives an overview of other large-scale studies either in \java{} or in other languages.
Related to our cast study, in \S{}[[sec:controlled-experiments]] we show studies on how static type systems impact on programmers productivity.
Code Patterns discovery is presented in \S{}[[sec:pattern-discovery]].
Finally, \S{}[[sec:msr]] gives an overview of what tools are available to extract information from a software repository, while \S{}[[sec:selection]] of how to select good candidates projects.

** Compilers Writers <<sec:compilers-writers>>

Already cite:knuth_empirical_1971 started to study \fortran{} programs.
By knowing what kind of programs arise in practice, a compiler optimizer can focus in those cases, and therefore can be more effective.
Alternatively, to measure the advantages between compilation and interpretation in \basic{}, cite:hammond_basic_1977 has studied a representative dataset of programs.
Adding to Knuth's work, cite:shen_empirical_1990 made an empirical study for parallelizing compilers.
Similar works have been done for \cobol{}\nbsp{}cite:salvadori_static_1975,chevance_static_1978, \pascal{}\nbsp{}cite:cook_contextual_1982, and \apl{}\nbsp{}cite:saal_properties_1975,saal_empirical_1977 programs.

But there is more than empirical studies at the source code level.
A machine instruction set is effectively another kind of language.
Therefore, its design can be affected by how compilers generate machine code.
Several studies targeted the \jvm{}\nbsp{}cite:collberg_empirical_2007,odonoghue_bigram_2002,antonioli_analysis_1998; while\nbsp{}cite:cook_empirical_1989 did a similar study for \lilith{} in the past.

** Benchmarks and Corpuses <<sec:benchmarks>>

Benchmarks are crucial to properly evaluate and measure product developement.
This is key for both research and industry.
One popular benchmark suite for \java{} is DaCapo\nbsp{}cite:blackburn_dacapo_2006.
This suite has been already cited in more than thousand publications, showing how important is to have reliable benchmark suites.

Another suite is given in\nbsp{}cite:tempero_qualitas_2010.
They provide a corpus of curated open source systems to facilitate empirical studies on source code.

For any benchmark or corpus to be useful and reliable, it must faithfully represent real world code.
Therefore, we argue how important it is to make empirical studies about what programmers write.

** Large-scale Codebase Empirical Studies <<sec:large-scale>>

In the same direction to our plan, cite:callau_how_2013 perform a study of the dynamic features of \smalltalk{}.
Analogously, cite:richards_analysis_2010,richards_eval_2011 made a similar study, but in this case targeting \javascript{}'s dynamic behavior and in particular the \eval{} function.
Also for \javascript{}, cite:madsen_string_2014 analyzed how fields are accessed via strings, while\nbsp{}cite:jang_empirical_2010 analyzed privacy violations.
Similar empirical studies were done for \php{}\nbsp{}cite:hills_empirical_2013,dahse_experience_2015,doyle_empirical_2011 and \swift{}\nbsp{}cite:reboucas_empirical_2016. 

Going one step forward, cite:ray_large-scale_2017 studied the correlation between programming languages and defects.
One important note is that they choose relevant project by popularity, measured \emph{stars} in \github{}.
We argue that it is more important to analyse projects that are /representative/, not /popular/.

For \java{}, cite:dietrich_contracts_2017-1 made a study about how programmers use contracts in \mavencentral{}.
cite:landman_challenges_2017 have analyzed the relevance of static analysis tools with respect to reflection.
They made an empirical study to check how often the reflection \api{} is used in real-world code.
They argue, as we do, that controlled experiments on subjects need to be correlated with real-world use cases, \eg{}, \github{} or \mavencentral{}.
cite:winther_guarded_2011 \nbsp{}have implemented a flow-sensitive analysis that allows to avoid manually casting once a guarded \instanceof{} is provided.
cite:dietrich_broken_2014 have studied how changes in \api{} library impact in \java{} programs.
Notice that they have used the Qualitas Corpus\nbsp{}cite:tempero_qualitas_2010 mentioned above for their study.

*** Exceptions
:PROPERTIES:
:UNNUMBERED: t
:END:

cite:kery_examining_2016,asaduzzaman_how_2016 focus on exceptions.
They made empirical studies on how programmers handle exceptions in \java{} code.
The work done by\nbsp{}cite:nakshatri_analysis_2016 categorized them in patterns.
Whether\nbsp{}cite:coelho_unveiling_2015 used a more dynamic approach by analysing stack traces and code issues in \github{}.

*** Collections and Generics
:PROPERTIES:
:UNNUMBERED: t
:END:

The inclusion of generics in \java{} is closely related to collections.
cite:parnin_java_2011,parnin_adoption_2013 studied how generics were adopted by \java{} developers.
They found that the use of generics do not significantly reduce the number of type casts.

cite:costa_empirical_2017 have mined \github{} corpus to study the use and performance of collections, and how these usages can be improved.
They have found out that in most cases there is an alternative usage that improves performance.

** DRAFT Controlled Experiments on Subjects <<sec:controlled-experiments>>
:LOGBOOK:
- State "DRAFT"      from "TODO"       [2017-12-15 Fri 16:58] \\
  Removed "Impact of using Static Type systems" sub-headline
:END:

There is an extensive literature \perse{} in controlled experiments on subjects to understand several aspects in programming, and programming languages.
For instance, cite:soloway_empirical_1984 tried to understand the how expert programmers face problem solving.
cite:budd_theoretical_1980 made a empirical study on how effective is mutation testing.
cite:prechelt_empirical_2000 compared how a given --- fixed --- task was implemented in several programming languages.

cite:latoza_developers_2010 realize that, in essence, programmers need to answer reachability questions to understand large codebases.

Several authors\nbsp{}cite:stuchlik_static_2011,mayer_empirical_2012,harlin_impact_2017 measure whether using a static-type system improves programmers productivity.
They compare how a static and a dynamic type system impact on productivity.
The common setting for these studies is to have a set of programming problems.
Then, let a group of developers solve them in both a static and dynamic languages.

For these kind of studies to reflect reality, the problems to be solved need to be representative of the real-world code.
Having artificial problems may lead to invalid conclusions.

The work by\nbsp{}cite:wu_how_2017,wu_learning_2017 goes towards this direction.
They have examined programs written by students to understand real debugging conditions.
Their focus is on ill-typed programs written in \haskell{}.
Unfortunately, these dataset does not correspond to real-world code.
Our focus is to analyze code by experienced programmers.

Therefore, it is important to study how casts are used in real-world code.
Having a deep understanding of actual usage of casts can led to
Informed decisions when designing these kind of experiments.

** DRAFT Code Patterns Discovery <<sec:pattern-discovery>>
:LOGBOOK:
- State "DRAFT"      from "DRAFT"      [2017-12-06 Wed 16:12] \\
  Rascal implements backtracking & fixed point (used by dataflow analysis)
- State "DRAFT"      from "DRAFT"      [2017-12-05 Tue 15:18] \\
  How the pattern discovery relate to static analysis, how powerful they are?
- State "DRAFT"      from "TODO"       [2017-12-05 Tue 15:17] \\
  Need to add Rascal
:END:

cite:posnett_thex:_2010 have extended \asm{}\nbsp{}cite:bruneton_asm:_2002,kuleshov_using_2007 to implement symbolic execution and recognize call sites.
However, this is only a meta-pattern detector, and not a pattern discovery.
cite:hu_dynamic_2008 used both dynamic and static analysis to discover design patterns, while cite:arcelli_design_2008 used only dynamic.

Trying to unify analysis and transformation tools\nbsp{}cite:vinju_how_2006, cite:klint_rascal:_2009 built \rascal, a DSL that aims to bring them together. 

** DRAFT Tools for Mining Software Repositories <<sec:msr>> :boa:lgtm:candoia:
:LOGBOOK:
- State "DRAFT"      from "TODO"       [2017-12-15 Fri 17:02] \\
  Removed title ``A Platform for Building and Sharing Mining Software Repositories Tools as Apps'' (already in the citation)
:END:

When talking about mining software repositories, we refer to extracting any kind of information from large-scale codebase repositories.
Usually doing so requires several engineering but challenging tasks.
The most common being downloading, storing, parsing, analyzing and properly extracting different kinds of artifacts.
In this scenario, there are several tools that allows a researcher or developer to query information about software repositories.

cite:dyer_boa:_2013,dyer_declarative_2013 built \boa{}, both a domain-specific language and an online platform[fn::http://boa.cs.iastate.edu/].
It is used to query software repositories on two popular hosting services, \github [fn::https://github.com/] and \sourceforge [fn::https://sourceforge.net/].
The same authors of \boa{} made a study on how new features in \java{} were adopted by developers\nbsp{}cite:dyer_mining_2014.
This study is based \sourceforge{} data.
The current problem with \sourceforge{} is that is outdated.

To this end, cite:gousios_ghtorent_2013 provides an offline mirror of \github{} that allows researchers to query any kind of that data.
Later on, cite:gousios_lean_2014 published the dataset construction process of \github{}.

Similar to \boa{}, \lgtm [fn::https://lgtm.com/] is a platform to query software projects properties.
It works by querying repositories from \github{}.
But it does not work at a large-scale, \ie{}, \lgtm{} allows the user to query just a few projects.
Unlike \boa{}, \lgtm{} is based on \ql{}, an object-oriented domain-specific language to query recursive data structures\nbsp{}cite:avgustinov_ql:_2016.

On top of \boa{}, cite:tiwari_candoia:_2017 built \candoia [fn::http://candoia.github.io/].
Although it is not a mining software repository \perse{}, it eases the creation of mining applications.

Another tool to analyze large software repositories is presented in\nbsp{}cite:brandauer_spencer:_2017.
In this case, the analysis is dynamic, based on program traces.
At the time of this writing, the service[fn::http://www.spencer-t.racing/datasets] was unavailable for testing.

** DRAFT Selecting Good Representatives <<sec:selection>>
:LOGBOOK:
- State "DRAFT"      from "TODO"       [2017-12-06 Wed 17:42] \\
  Added SPS for project sampling, and promote good representatives selection to section.
:END:

Another dimension to consider when analyzing large codebases, is how relevant the repositories are.
cite:lopes_dejavu:_2017 made a study to measure code duplication in \github{}.
They found out that much of the code there is actually duplicated.
This raises a flag when consider which projects analyze when doing mining software repositories. 

cite:nagappan_diversity_2013 have developed the Software Projects Sampling (SPS) tool.
SPS tries to find a maximal set of projects based on representativeness and diversity.
Diversity dimensions considered include total lines of code, project age, activity, and of the last 12 months, number of contributors, total code churn, and number of commits.

# Implicits in Scala
# Users/Compilers Java/Scala generated bytecode
# Jurgen Vinju paper: http://homepages.cwi.nl/~storm/publications/visitor.pdf

** DRAFT Code Recommenders Systems :noexport:
:LOGBOOK:
- State "DRAFT"      from "TODO"       [2017-12-15 Fri 16:08] \\
  Shall I add this Code Recommenders systems section?
:END:

* DRAFT Existing Code Patterns <<cha:patterns>>
:PROPERTIES:
:COLUMNS:  %ITEM(Name) %Citation %10Found-In
:END:
:LOGBOOK:
- State "DRAFT"      from "TODO"       [2017-12-10 Sun 17:47] \\
  Demote patterns into literature review
:END:

#+BEGIN_SRC emacs-lisp :results silent :exports none
(org-entry-properties)
#+END_SRC

#+CAPTION: hola q tal
# #+ATTR_LATEX: :caption \bicaption{HeadingA}{HeadingB}
#+BEGIN: columnview :hlines 1 :maxlevel 3 :id local :skip-empty-rows t
| Name                                       | Citation                     | Found-In                     |
|--------------------------------------------+------------------------------+------------------------------|
| Specifying Application Extensions          | cite:livshits_improving_2006 | =columba=, =jedit=, =tomcat= |
| Custom-made Object Serialization Scheme    | cite:livshits_improving_2006 | =jgap=                       |
| Improving Portability Using Reflection     | cite:livshits_improving_2006 | =gruntspud=, =jfreechart=    |
| Code Unavailable Until Deployment          | cite:livshits_improving_2006 | =columba=                    |
| Using ~Class.forName~ for its Side-effects | cite:livshits_improving_2006 | =jfreechart=                 |
| Getting Around Static Type Checking        | cite:livshits_improving_2006 | =columba=                    |
| Providing a Built-in Interpreter           | cite:livshits_improving_2006 | =jedit=                      |
| Guarded Casts                              | cite:winther_guarded_2011    | -                            |
| Semi-guarded Casts                         | cite:winther_guarded_2011    | -                            |
| Unguarded Casts                            | cite:winther_guarded_2011    | -                            |
| Safe Casts                                 | cite:winther_guarded_2011    | -                            |
| CorrectCasts                               | cite:landman_challenges_2017 |                              |
| WellBehavedClassLoaders                    | cite:landman_challenges_2017 |                              |
| IgnoringExceptions1                        | cite:landman_challenges_2017 |                              |
| IgnoringExceptions2                        | cite:landman_challenges_2017 |                              |
| IndexedCollections                         | cite:landman_challenges_2017 |                              |
| MetaObjectsInTables                        | cite:landman_challenges_2017 |                              |
| MultipleMetaObjects                        | cite:landman_challenges_2017 |                              |
| EnvironmentStrings                         | cite:landman_challenges_2017 |                              |
| UndecidableFiltering                       | cite:landman_challenges_2017 |                              |
| NoProxy                                    | cite:landman_challenges_2017 |                              |
 #+END:

*** Specifying Application Extensions
:PROPERTIES:
:Description: Unclear pattern
:Citation: cite:livshits_improving_2006
:Found-In: =columba=, =jedit=, =tomcat=
:Category: reflection
:END:
**** Snippet

#+BEGIN_SRC java
public void addHandlers(String path) {
        XmlIO xmlFile = new XmlIO(DiskIO.getResourceURL(path));
        xmlFile.load();
        XmlElement list = xmlFile.getRoot().getElement("handlerlist");
        Iterator it = list.getElements().iterator();
        while (it.hasNext()) {
            XmlElement child = (XmlElement) it.next();
            String id = child.getAttribute("id");
            String clazz = child.getAttribute("class");
            AbstractPluginHandler handler = null;
            try {
                Class c = Class.forName(clazz);
                handler = (AbstractPluginHandler) c.newInstance();
                registerHandler(handler);
            } catch (ClassNotFoundException e) {
                if (Main.DEBUG) e.printStackTrace();
            } catch (InstantiationException e1) {
                if (Main.DEBUG) e1.printStackTrace();
            } catch (IllegalAccessException e1) {
                if (Main.DEBUG) e1.printStackTrace();
        }
    }
}
#+END_SRC

**** Discussion

This pattern is not clear.
It would be interesting to see how these extensions are used,
and what is the rationale of being of using these extensions as plug-ins.

*** Custom-made Object Serialization Scheme
:PROPERTIES:
:Description: Using reflection to serialize/deserialize objects.
:Citation: cite:livshits_improving_2006
:Found-In: =jgap=
:Category: reflection
:END:
**** Snippet

#+BEGIN_SRC java
String geneClassName = thisGeneElement.
           getAttribute(CLASS_ATTRIBUTE);
Gene thisGeneObject = (Gene) Class.forName(
             geneClassName).newInstance();
#+END_SRC

**** Discussion

~Unsafe~ can be used to serialize/deserialze objects as well.
Actually, some unsafe implementations have a fallback to reflection in case
unsafe is not available.

*** Improving Portability Using Reflection   
:PROPERTIES:
:Description: Sometimes reflection is used as a mechanism to dead with incompatibility issues across different platforms.
:Citation: cite:livshits_improving_2006
:Found-In: =gruntspud=, =jfreechart=
:Category: reflection
:END:
**** Snippet

#+BEGIN_SRC java
try {
            Class macOS  = Class.forName("gruntspud.standalone.os.MacOSX");
            Class argC[] = {ViewManager.class};
            Object arg[] = {context.getViewManager()};
            Method init = macOS.getMethod("init", argC);
            Object obj  = macOS.newInstance();
            init.invoke(obj, arg);
        } catch (Throwable t) {
            // not on macos
}
#+END_SRC

#+BEGIN_SRC java
Method m = c.getMethod("clone", null);
if (Modifier.isPublic(m.getModifiers())) {
    try {
        result = m.invoke(object, null);
    }
    catch (Exception e) {
        e.printStackTrace();
    }
}
#+END_SRC

#+BEGIN_SRC java
try {
    //  Test for being run under JDK 1.4+
    Class.forName("javax.imageio.ImageIO");
    //  Test for JFreeChart being compiled
    //  under JDK 1.4+
    Class.forName("org.jfree.chart.encoders.SunPNGEncoderAdapter");
} catch (ClassNotFoundException e) {
    // ...
}
#+END_SRC
**** Discussion

What can we say?

*** Code Unavailable Until Deployment        
:PROPERTIES:
:Description: This pattern uses reflection to load and query a class that is not available at compile-time.
:Citation: cite:livshits_improving_2006
:Found-In: =columba=
:Category: reflection
:END:
**** Snippet

#+BEGIN_SRC java
Method getVersionMethod =
    Class.forName("org.columba.core.main.ColumbaVersionInfo").
        getMethod("getVersion", new Class[0]);
return (String) getVersionMethod.invoke(null,new Object[0]);
#+END_SRC

**** Discussion

How could be solve this problem by using information available
at compile-time?

*** Using ~Class.forName~ for its Side-effects 
:PROPERTIES:
:Description: By using this pattern one can call the class constructor, which might be needed independently by a later call-site.
:Citation: cite:livshits_improving_2006
:Found-In: =jfreechart=
:Category: reflection
:END:
**** Snippet

#+BEGIN_SRC java
public JDBCCategoryDataset(String url, String driverName,
                           String user, String passwd)
    throws ClassNotFoundException, SQLException
{
    Class.forName(driverName);
    this.connection = DriverManager.getConnection(url, user, passwd);
}
#+END_SRC

**** Discussion

Commonly used by ~JDBC~ API to load database drivers.

*** Getting Around Static Type Checking      
:PROPERTIES:
:Description: This pattern allows to circumvent safety features of the language.
:Citation: cite:livshits_improving_2006
:Found-In: =columba=
:Category: reflection
:END:
**** Snippet

#+BEGIN_SRC java
fieldSysPath = ClassLoader.class.getDeclaredField("sys_paths");
fieldSysPath.setAccessible(true);
if (fieldSysPath != null) {
    fieldSysPath.set(System.class.getClassLoader(), null);
}
#+END_SRC

**** Discussion

Is it possible to achieve the same effect using =sun.misc.Unsafe=?

*** Providing a Built-in Interpreter         
:PROPERTIES:
:Description: Implementing an interpreter, scripting language as a ~Java~ extension
:Citation: cite:livshits_improving_2006
:Found-In: =jedit=
:Category: reflection
:END:
**** Snippet
**** Discussion

This pattern seems too much like a high level pattern.
Although having ~semantic~ patterns is what we want, a pattern without a ~snippet~ is too high level and application-specific.

*** Guarded Casts
:PROPERTIES:
:Description: Cast guarded
:Citation: cite:winther_guarded_2011 
:Found-In: -
:Category: cast
:END:
**** Snippet

#+BEGIN_SRC java
if (o instanceof Foo) {
    Foo foo = (Foo)o;
    // ...
}
#+END_SRC

#+BEGIN_SRC java
if (o instanceof Foo && ((Foo)o).isBar()) {
    // ...
}
#+END_SRC

#+BEGIN_SRC java
Bar bar = o instanceof Foo ? ((Foo)o).getBar() : null;
#+END_SRC

=dead-if-guarded= cast version

#+BEGIN_SRC java
if (!(o instanceof Foo)) {
    return;
}
Foo foo = (Foo)o;
#+END_SRC

=ensure-guarded= casts

#+BEGIN_SRC java
if (!(o instanceof Foo)) {
    o = new Foo();
}
Foo foo = (Foo)o; 
#+END_SRC

=while-guarded= cast

#+BEGIN_SRC java
while (o != null && !(o instanceof Foo)) {
    o = o.parent();
}
Foo foo = (Foo)o;
#+END_SRC

*** Semi-guarded Casts
:PROPERTIES:
:Description: This casts are provided at an application-level instead of with runtime information.
:Citation: cite:winther_guarded_2011 
:Found-In: -
:Category: cast
:END:
**** Snippet

#+BEGIN_SRC java
Foo foo = ...
if (foo.isBar()) {
    Bar bar = (Bar)foo;
    // ...
}
#+END_SRC

*** Unguarded Casts
:PROPERTIES:
:Description: Non guarded
:Citation: cite:winther_guarded_2011 
:Found-In: -
:Category: cast
:END:
**** Snippet

#+BEGIN_SRC java
List list = ...{ // a list of Foo elements
for (Object o : list) {
    Foo foo = (Foo)o;
    // ...
}
#+END_SRC

#+BEGIN_SRC java
Calendar copy = (Calendar)calendar.clone();
#+END_SRC

*** Safe Casts
:PROPERTIES:
:Description: Primitive conversions, just for the sake of completeness.
:Citation: cite:winther_guarded_2011 
:Found-In: -
:Category: cast
:END:
**** Snippet

#+BEGIN_SRC java
(char)42
#+END_SRC

#+BEGIN_SRC java
(Integer)42
#+END_SRC

*** CorrectCasts
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** WellBehavedClassLoaders
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** IgnoringExceptions1
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** IgnoringExceptions2
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** IndexedCollections
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** MetaObjectsInTables
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** MultipleMetaObjects
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** EnvironmentStrings
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** UndecidableFiltering
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:
*** NoProxy
:PROPERTIES:
:Citation: cite:landman_challenges_2017 
:END:

* Casts <<cha:casts>> :patterns:

cite:winther_guarded_2011 proposes a flow-sensitive analysis to eliminate
redundant casts in ~Java~.
He presents some casts patterns that he needs to deal with in his analysis.
Notice that these patterns are structural ones.

cite:staicu_understanding_2017

cite:buse_synthesizing_2012

It does not show the purpose of casts, neither the rationale.
What we are trying to understand is why developers use casts,
and how could we avoid them, if we have to.

* Reflection Patterns <<cha:reflection>> :patterns:

This list of patterns are more of semantic patterns.

* Exceptions <<cha:exceptions>> :patterns:

Here we talk about exceptions.

* The \java{} Unsafe API <<cha:unsafe>>                            :patterns:

The material in this chapter is based on our previously published paper citep:mastrangelo_use_2015.

Our study on unsafe we have divised several usage patterns.
Java is a safe language. Its runtime environment provides strong safety guarantees that any Java application can rely on. Or so we think. We show that the runtime actually does not provide these guarantees—for a large fraction of today’s Java code. Unbeknownst to many application developers, the Java runtime includes a “backdoor” that allows expert library and framework developers to circumvent Java’s safety guar- antees. This backdoor is there by design, and is well known to experts, as it enables them to write high-performance “systems-level” code in Java.

For our study on \smu{}, we needed to discover usage patterns.
Given its a singleton class, we have collected call sites, and proceed with a semi-automatic analysis.
On the other hand, our study related to casts involved a much more complex analysis.
Therefore we have decided to implement it with manual inspection.

The exceptions mechanism is orthogonal to the features we target in this proposal.
For instance, we have detected a \smu{} pattern to \throw{} undeclared exceptions.
Similarly, closely related to /casting/, \cce{} is thrown when a cast is invalid.
Therefore, we believe that these kind of studies can be complementary for our research.
They can help us to understand how programmers handle exceptions in these scenarios.

For our study on \smu{}, we first tried using \boa{} with \sourceforge{}.
We found out that only few projects were using \smu{}.
In contrast, our final study using \maven{} found that an order of magnitude more were using \smu{}.

bibliographystyle:plainnat
bibliography:proposal.bib
